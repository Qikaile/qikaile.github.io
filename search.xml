<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>PS功能精通课</title>
    <url>/PS%E5%8A%9F%E8%83%BD%E7%B2%BE%E9%80%9A%E8%AF%BE.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><!-- build time:Mon Apr 20 2020 13:02:10 GMT+0800 (GMT+08:00) --><h2 id="我用双手成就你的梦想"><a href="#我用双手成就你的梦想" class="headerlink" title="我用双手成就你的梦想"></a>我用双手成就你的梦想</h2><h3 id="课程结构"><a href="#课程结构" class="headerlink" title="课程结构"></a>课程结构</h3><p>精通14节+提升22节+实战36节</p><h3 id="交作业"><a href="#交作业" class="headerlink" title="交作业"></a>交作业</h3><p>M站：m.dapengjiaoyu.com</p><p>上传图片格式：JPG</p><p>单张作业不可大过2M、最多上传9张、9张不可大过9M</p><h3 id="认识软件"><a href="#认识软件" class="headerlink" title="认识软件"></a>认识软件</h3><p>美国Adobe公司开发 中文：奥多比</p><p>PS：位图的处理软件</p><p>位图：图片缩小拉大之后图像会失真、色彩表现力好，文件大</p><p>PS的使用方向：摄影后期、效果图的后期处理、图像合成、电影海报、电商、网页设计、UI设计、等等…很多方面，较为广泛</p><p>Ai：矢量图的处理软件</p><p>矢量图：图片缩小拉大之后图像不会失真、色彩表现不如ps细腻、层次感不强、文件小</p><p>Ai的使用方向：印刷（名片）、包装盒的设计制作、企业VI手册设计（企业形象识别系统）、LOGO设计等</p><p>ID：专业书籍排版软件</p><p>ID的使用方向：杂志、广告设计、目录、零售商设计工作室和报纸出版方案等</p><h3 id="PS基本操作"><a href="#PS基本操作" class="headerlink" title="PS基本操作"></a>PS基本操作</h3><p>1.新建画布（快捷键<strong><span style="color:red">Ctrl+N</span></strong>）</p><p>①分辨率：打印时用300分辨率(大尺寸设计稿分比率会根据具体情况变小)；屏幕显示时用72分辨率</p><p>②颜色模式：显示时用RGB RGB代表红绿蓝</p><p>​ 打印时用CMYK CMYK代表青、品红、黄、黑</p><p>2.打开（在工作区域外）</p><p>①文件——打开（快捷键<strong><span style="color:red">Ctrl+O</span></strong>）</p><p>②拖拽打开：在计算机里选中需要打开的文件点击并拖拽至<strong><span style="color:#00f">ps图标</span></strong>上，然后移动到菜单栏或属性栏</p><p>3.置入（在工作区域内）：拖拽到画布中，需确定置入命令，可直接按<strong><span style="color:#00f">回车Enter</span></strong>确定</p><p>4.保存（快捷键<strong><span style="color:red">Ctrl+S</span></strong>）：格式psd留给设计师自己的源文件可再次修改， Jpg图片格式 不可修改， png透底图 背景透明</p><p>5.另存为：快捷键<strong><span style="color:red">Ctrl+Shift+S</span></strong></p><p>6.存储为web所用格式：快捷键<strong><span style="color:red">Ctrl+Shift+Alt+S</span></strong>（可以更改素材质量大小，优化文件大小）</p><p>7.调整ps：编辑—首选项—暂存盘 快捷键<strong><span style="color:red">Ctrl+K</span></strong>勾选所有硬盘可缓解卡顿</p><h3 id="快捷键整理"><a href="#快捷键整理" class="headerlink" title="快捷键整理"></a>快捷键整理</h3><div class="table-container"><table><thead><tr><th>新建画布：Ctrl+N</th><th>打开：Ctrl+O</th></tr></thead><tbody><tr><td>保存：Ctrl+S</td><td>另存为：Ctrl+Shift+S</td></tr><tr><td>存储为web所用格式：Ctrl+Shift+Alt+S</td></tr></tbody></table></div><h2 id="揭开ps的神秘面纱"><a href="#揭开ps的神秘面纱" class="headerlink" title="揭开ps的神秘面纱"></a>揭开ps的神秘面纱</h2><h3 id="画布操作"><a href="#画布操作" class="headerlink" title="画布操作"></a>画布操作</h3><p>1.放大缩小画布：<strong><span style="color:#00f">Alt+鼠标滚轮 或 Ctrl+加减键 或缩放工具（Alt缩小）</span></strong></p><p>2.百分之百显示：Ctrl+1 根据显示器显示：Ctrl+0（零）</p><p>3.移动画板：按住空格键可临时切换为抓手工具鼠标左键拖拽即可</p><p>4.撤销一步：<strong><span style="color:red">Ctrl+Z</span></strong> 撤销多步：Ctrl+Alt+Z 还原多步：Ctrl+Shift+Z</p><p>5.自由变换：<strong><span style="color:red">Ctrl+T</span></strong></p><p>①普通变换：通过对角点拉伸，鼠标放在对角（出现弯箭头）旋转。按<strong><span style="color:#00f">Alt（中心点）和Shift（等比）以中心点等比例缩放</span></strong></p><h3 id="图层基本操作"><a href="#图层基本操作" class="headerlink" title="图层基本操作"></a>图层基本操作</h3><p>1.解锁背景图层：点击图层后方锁头解锁</p><p>2.显示隐藏图层：点击该图层前的眼睛图标</p><p>3.删除图层：选中图层按delete键删除 或选中图层后点击下方垃圾桶图标 或选中图层拖拽至垃圾桶图标上</p><p>4.创建新图层：点击垃圾桶左侧的图标（快捷键Ctrl+Alt+Shift+N）</p><p>5.上色（前景色与背景色，需要自行添加新图层）</p><p>6.恢复默认前景色和背景色（黑白）：按D</p><p>7.切换前景色与背景色：点击弯箭头或按X</p><p>填充前景色：<strong><span style="color:red">Alt+Delete</span></strong></p><p>填充背景色：<strong><span style="color:red">Ctrl+Delete</span></strong></p><h3 id="移动工具（快捷键V）"><a href="#移动工具（快捷键V）" class="headerlink" title="移动工具（快捷键V）"></a>移动工具（快捷键V）</h3><ol><li><p>移动工具可以移动，可以复制，还可以跨画布复制</p></li><li><p>对齐：必须有<strong><span style="color:#00f">两个</span></strong>及以上图层</p></li><li><p>分布：必须有<strong><span style="color:#00f">三个</span></strong>及以上图层</p></li><li><p>快速选择图层：移动工具下按住ctrl可以临时切换到自动选择模式，同时按住Shift可以进行加选或减选</p></li></ol><h3 id="画笔（快捷键B）"><a href="#画笔（快捷键B）" class="headerlink" title="画笔（快捷键B）"></a>画笔（快捷键B）</h3><p>1.画笔加号情况：可能开了大写或画笔过大</p><p>2.画笔工具用于涂抹前景色</p><p>3.画笔大小更改：P后面【】 画笔硬度更改：Shift+P后面【】</p><h3 id="快捷键整理-1"><a href="#快捷键整理-1" class="headerlink" title="快捷键整理"></a>快捷键整理</h3><div class="table-container"><table><thead><tr><th>适应显示器显示：Ctrl+0</th><th>百分百显示：Ctrl+1</th></tr></thead><tbody><tr><td>撤销：Ctrl+Z</td><td>自由变换：Ctrl+T</td></tr><tr><td>还原多步：Ctrl+Shift+Z</td><td>撤销多步：Ctrl+Alt+Z</td></tr><tr><td>画笔（快捷键：B）</td><td>新建图层：Ctrl+Alt+Shift+N</td></tr><tr><td>填充前景色：Alt+Delete</td><td>填充背景色：Ctrl+Delete</td></tr></tbody></table></div><h2 id="成为大神前的第一步"><a href="#成为大神前的第一步" class="headerlink" title="成为大神前的第一步"></a>成为大神前的第一步</h2><h3 id="图层操作"><a href="#图层操作" class="headerlink" title="图层操作"></a>图层操作</h3><p>1.复制图层</p><p>①移动工具下，按住Alt点击并拖拽可以复制，按住Shift可以控制复制的图层水平或垂直方向平移</p><p>②原位复制，快捷键<strong><span style="color:red">Ctrl+J</span></strong></p><p>2.编组：<strong><span style="color:red">Ctrl+G</span></strong> 取消编组：Ctrl+Shift+G</p><p>3.合并图层：<strong><span style="color:red">Ctrl+E</span></strong>（尽量少用）</p><p>4.分离图像：<strong><span style="color:red">Ctrl+Shift+J</span></strong>把选中的内容剪切出来并放在原位</p><h3 id="选框工具（快捷键M，切换工具Shift-M）"><a href="#选框工具（快捷键M，切换工具Shift-M）" class="headerlink" title="选框工具（快捷键M，切换工具Shift+M）"></a>选框工具（快捷键M，切换工具Shift+M）</h3><p>1.选框：流动的虚线（蚂蚁线）</p><p>2.绘制方法：点击并拖拽（点击鼠标不要松开）</p><p><strong><span style="color:#00f">按住Shift绘制正图形选区，按住Alt以鼠标为中心绘制选区，按Shift+Alt以鼠标为中心绘制正图形选区</span></strong></p><p>3.取消选区：<strong><span style="color:red">Ctrl+D</span></strong></p><p>4.羽化：制作边缘虚化的效果</p><p>属性栏处进行羽化时<strong><span style="color:#00f">选择羽化后填充</span></strong>（选框绘画之前）</p><p>羽化需要选择—修改—羽化快捷键<strong><span style="color:red">Shift+F6</span></strong>进行羽化(选框画完之后)</p><p>5.载入选区：按住Ctrl点击该图层的<strong><span style="color:#00f">图层缩览图</span></strong></p><h3 id="选区的操作"><a href="#选区的操作" class="headerlink" title="选区的操作"></a>选区的操作</h3><p>1.新选区：新绘制的选区每次都形成一个新选区</p><p>2.<strong><span style="color:red">添加到选区</span></strong>：新绘制的选区与之前绘制的选区进行相加（快捷方法先按住<strong><span style="color:red">Shift</span></strong>再绘制新选区）</p><p>3.<strong><span style="color:red">从选区减去</span></strong>：新绘制的选区与之前绘制的选区进行相减（快捷方法先按住<strong><span style="color:red">Alt</span></strong>再绘制新选区）</p><p>4.<strong><span style="color:red">与选区交叉</span></strong>：新绘制的选区与之前绘制的选区相交部分留下（快捷方法先按住<strong><span style="color:red">Shift+Alt</span></strong>再绘制新选区）</p><p>5.绘制时移动：绘制时按住空格键可以移动选区</p><h3 id="快捷键整理-2"><a href="#快捷键整理-2" class="headerlink" title="快捷键整理"></a>快捷键整理</h3><div class="table-container"><table><thead><tr><th>编组：Ctrl+G</th><th>（原位）复制：Ctrl+J</th></tr></thead><tbody><tr><td>合并图层：Ctrl+E</td><td>取消编组：Ctrl+Shift+G</td></tr><tr><td>填充背景色：Ctrl+Delete</td><td>填充前景色：Alt+Delete</td></tr><tr><td>取消选区：Ctrl+D</td><td>分离图像：Ctrl+Shift+J</td></tr><tr><td></td><td>羽化：Shift+F6</td></tr></tbody></table></div><h2 id="神奇的布尔运算"><a href="#神奇的布尔运算" class="headerlink" title="神奇的布尔运算"></a>神奇的布尔运算</h2><h3 id="矢量工具（快捷键U，切换工具Shift-U）"><a href="#矢量工具（快捷键U，切换工具Shift-U）" class="headerlink" title="矢量工具（快捷键U，切换工具Shift+U）"></a>矢量工具（快捷键U，切换工具Shift+U）</h3><p>1.<strong><span style="color:red">形状模式</span></strong>：在绘制过程中会自动新建图层，默认自动填充前景色</p><p>2.<strong><span style="color:red">颜色填充</span></strong>：纯色填充、渐变填充、图案填充</p><p>3.<strong><span style="color:red">图形描边</span></strong>：纯色填充、渐变填充、图案填充；描边大小；描边选项</p><p>4.<strong><span style="color:red">图形大小</span></strong>：属性栏处可以精确调整大小或<strong><span style="color:red">Ctrl+T</span></strong></p><p>5.<strong><span style="color:red">图形绘制</span></strong>：按住<strong><span style="color:red">Shift</span></strong>可以绘制正图形，按住<strong><span style="color:red">Alt</span></strong>键可以以鼠标为中心点绘制图形，按住<strong><span style="color:red">Shift+Alt</span></strong>可以以鼠标为中心点绘制正图形</p><p>6.<strong><span style="color:red">圆角矩形</span></strong>：绘制的时候<strong><span style="color:#00f">先设置半径</span></strong>，高版本可以在属性栏中修改(CS版本的就不好意思啦，不能在属性栏调整，因为没有这个功能，哈哈哈！！！)</p><p>7.<strong><span style="color:red">多边形</span></strong>：绘制的时候<strong><span style="color:#00f">先设置多边形的边数</span></strong>与平滑星星等</p><p>8.<strong><span style="color:red">直线</span></strong>：绘制的时候<strong><span style="color:#00f">先改变线的粗细</span></strong>，按住shift可以成角度约束</p><p>9.<strong><span style="color:red">自定形状</span></strong>：软件预设好的形状，方便使用，还可以追加。</p><p>10.<strong><span style="color:red">自定形状追加</span></strong>：设置—全部—追加</p><p>11.<strong><span style="color:red">定义自定形状</span></strong>：选择想要定义的图层右击选择定义自定形状（必须有路径的图层）</p><p>12.<strong><span style="color:#00f">布尔运算（通过形状层的加、减、交得到新的图形）：同选区操作</span></strong></p><p>13.矢量图形计算后：<strong><span style="color:#00f">必须要合并形状组件</span></strong></p><h3 id="小黑小白"><a href="#小黑小白" class="headerlink" title="小黑小白"></a>小黑小白</h3><p>1.<strong><span style="color:red">小黑（A）</span></strong>：移动和复制路径，单独选中图形</p><p>2.<strong><span style="color:red">小白（A）</span></strong>：选择和移动路径的上锚点，以及调节控制手柄，按住Shift可以加选锚点</p><h3 id="渐变工具"><a href="#渐变工具" class="headerlink" title="渐变工具"></a>渐变工具</h3><p>在属性栏处选择一种渐变类型，并设置渐变颜色和其他属性等，创建渐变</p><h3 id="快捷键整理-3"><a href="#快捷键整理-3" class="headerlink" title="快捷键整理"></a>快捷键整理</h3><div class="table-container"><table><thead><tr><th>填充前景色：Alt+Delete</th><th>填充背景色：Ctrl+Delete</th></tr></thead><tbody><tr><td>分离图像：Ctrl+Shift+J</td><td>取消选区：Ctrl+D</td></tr><tr><td></td></tr></tbody></table></div><h2 id="祖传抠图技法"><a href="#祖传抠图技法" class="headerlink" title="祖传抠图技法"></a>祖传抠图技法</h2><h3 id="套索工具"><a href="#套索工具" class="headerlink" title="套索工具"></a>套索工具</h3><p>1.套索工具：大致框选，不适合精确抠图</p><p>2.多边形套索工具：适合抠有棱角的图片，直线（回车可快速成选区）</p><p>3.磁性套索工具：具有磁性，可以识别物体边缘（边缘清晰），操作发生偏移可以通过Delete进行点的删除（回车可快速成选区）</p><p>a 宽度：该值决定了以光标中心为基准，其<strong><span style="color:#00f">周围有多少个像素</span></strong>能够被工具检测到。边界清晰时数值高</p><p>b 对比度：设置工具感应图像边缘的<strong><span style="color:#00f">灵敏度</span></strong>，图像清晰时数值高</p><p>c 频率：决定产生的<strong><span style="color:#00f">锚点数量</span></strong>。数值越高，捕捉的边界越准确</p><h3 id="快速选择工具（属于画笔类）"><a href="#快速选择工具（属于画笔类）" class="headerlink" title="快速选择工具（属于画笔类）"></a>快速选择工具（属于画笔类）</h3><p>1.调成大小：P后面的【】可以调节画笔大小</p><p>2.可以移动十字光标，快速连续选择相近的图像，会自动识别边缘（创建选框）</p><p>3.选区的反向选择：<strong><span style="color:red">Ctrl+Shift+I</span></strong></p><h3 id="魔棒工具"><a href="#魔棒工具" class="headerlink" title="魔棒工具"></a>魔棒工具</h3><p>1.可以创建选区，选择颜色相近的范围</p><p>2.<strong><span style="color:#00f">容差值</span></strong>越大，选择颜色相似的范围越大，5~35之间</p><p>3.不勾选连续时，主体物与背景颜色相近时，主体物也会选中</p><p>4.魔棒工具抠图适用情况：背景是纯色，或背景与主体物颜色差距大</p><h3 id="色彩范围"><a href="#色彩范围" class="headerlink" title="色彩范围"></a>色彩范围</h3><p>1.选择—色彩范围 选择改为<strong><span style="color:#00f">取样颜色</span></strong> 图形下面选择<strong><span style="color:#00f">选择范围</span></strong></p><p>2.根据图像的颜色范围，进行创建选区</p><p>白色为被选中的，黑色没被选中的，灰色透明的</p><h3 id="橡皮擦工具"><a href="#橡皮擦工具" class="headerlink" title="橡皮擦工具"></a>橡皮擦工具</h3><p>1.橡皮擦工具：直接擦涂，删掉不需要的图像</p><p>2.魔术橡皮擦：<strong><span style="color:#00f">直接删掉</span></strong>颜色相近的区域，容差值与魔棒相同</p><h3 id="其他辅助操作"><a href="#其他辅助操作" class="headerlink" title="其他辅助操作"></a>其他辅助操作</h3><p>1.图层顺序：下/上移一层图层 Ctrl+【】</p><p>​ 置底/置顶图层 Ctrl+Shift+【】</p><p>2.收缩（选择—修改）：在原有基础上进行缩小选区</p><h3 id="快捷键整理-4"><a href="#快捷键整理-4" class="headerlink" title="快捷键整理"></a>快捷键整理</h3><div class="table-container"><table><thead><tr><th>反向选则：Ctrl+Shift+I</th><th></th></tr></thead><tbody><tr><td>下/上移动图层：Ctrl+【】</td><td>置底/置顶：Ctrl+Shift+【】</td></tr></tbody></table></div><h2 id="高效修图法"><a href="#高效修图法" class="headerlink" title="高效修图法"></a>高效修图法</h2><h3 id="污点修复画笔"><a href="#污点修复画笔" class="headerlink" title="污点修复画笔"></a>污点修复画笔</h3><p>1.调节大小：P后面的【】进行调节</p><p>2.类型：<strong><span style="color:#00f">内容识别</span></strong>（常用）/创建纹理/近似匹配</p><p>3.内容识别：点击需要修复的区域。软件会自动在他的周围进行取样，通过计算对其进行光线和明暗的匹配，并进行<strong><span style="color:#00f">羽化融合</span></strong></p><p>4.创建纹理：可以创建纹理，纹理为ps自带不可修改</p><p>5.近似匹配：使用工具边缘的像素来修补图像 扩散数值为画笔附近几像素的范围。（可以自动调节明暗）</p><h3 id="修复画笔工具"><a href="#修复画笔工具" class="headerlink" title="修复画笔工具"></a>修复画笔工具</h3><p>1.调节大小：P后面的【】进行调节</p><p>2.取样：在需要修复的<strong><span style="color:#00f">区域四周</span></strong>，找到颜色相似的区域，按住<strong><span style="color:red">Alt键</span></strong>，鼠标点击进行取样，然后在需要修复的区域<strong><span style="color:#00f">点击</span></strong>或涂抹，（在修复时，修复画笔尽量要比修复的区域大，否则，修复效果不是很好。）</p><p>3.对齐：勾选对齐后吸取点<strong><span style="color:#00f">跟随</span></strong>修复点移动，不勾选每次单击修复都是用同一吸取点去修复</p><p>4.图案：直接涂抹即可，不需要取样，类似图案叠加</p><h3 id="修补工具"><a href="#修补工具" class="headerlink" title="修补工具"></a>修补工具</h3><p>1.源：选区位置<strong><span style="color:#00f">被</span></strong>鼠标停留位置<strong><span style="color:#00f">覆盖</span></strong></p><p>2.目标：选区位置<strong><span style="color:#00f">覆盖</span></strong>鼠标停留位置</p><h3 id="内容感知移动工具"><a href="#内容感知移动工具" class="headerlink" title="内容感知移动工具"></a>内容感知移动工具</h3><p>可以移动画面当中物体的位置，移动 之后可以自动填充。可以在需要修改的位置绘制选区，移动选区到画布外，<strong><span style="color:#00f">留一小部分</span></strong>选区再画布当中，来用于修补水印</p><h3 id="红眼工具"><a href="#红眼工具" class="headerlink" title="红眼工具"></a>红眼工具</h3><p>可以修复相机在光线昏暗的情况下，产生的红眼效果，点击红眼部位，会自动修复。（了解即可）</p><h3 id="仿制图章"><a href="#仿制图章" class="headerlink" title="仿制图章"></a>仿制图章</h3><p>1.使用方法同修复画笔一致</p><p>2.仿制图章工具与修复画笔工具的区别：</p><p>①仿制图章是<strong><span style="color:#00f">无损仿制</span></strong>，取样什么颜色/皮肤，仿制的就是什么样子</p><p>②修复画笔有一个运算过程，在涂抹当中将取样图像和目标位置<strong><span style="color:#00f">融合</span></strong>，自动适应周围环境</p><h3 id="图案图章工具"><a href="#图案图章工具" class="headerlink" title="图案图章工具"></a>图案图章工具</h3><p>选择图案可以涂背景，类似图案添加</p><h3 id="液化"><a href="#液化" class="headerlink" title="液化"></a>液化</h3><p>（快捷键：<strong><span style="color:red">Ctrl+Shift+X</span></strong>）</p><p>如果液化点不开或者灰色的，首选项-性能-使用图形处理器勾选上</p><p>1.位置：滤镜—液化</p><p>2.向前变形：可以制作瘦身瘦脸效果</p><p>3.重建工具：可以恢复之前的变形</p><p>4.顺时针旋转扭曲工具：按住alt键点击可以逆时针旋转</p><p>5.褶皱工具（挤压、褶皱效果）</p><p>6.膨胀工具（与褶皱工具相反）</p><p>7.左推工具（从上往下是往左推，从下往上是往右推）</p><p>8.冻结蒙版工具（保护图层）</p><p>9.解冻蒙版工具（取消冻结的蒙版）</p><p>10.人脸识别</p><p>11.移动工具、放大缩小</p><h3 id="内容识别（快捷键：Shift-F5）"><a href="#内容识别（快捷键：Shift-F5）" class="headerlink" title="内容识别（快捷键：Shift+F5）"></a>内容识别（快捷键：Shift+F5）</h3><p>通过绘制选区选择 需要修复的区域，软件会自动识别与画面不匹配的区域，进行修复图像</p><h3 id="快捷键整理-5"><a href="#快捷键整理-5" class="headerlink" title="快捷键整理"></a>快捷键整理</h3><div class="table-container"><table><thead><tr><th>液化 Ctrl+Shift+X</th><th>内容识别 Shift+F5</th></tr></thead><tbody><tr><td></td></tr></tbody></table></div><h2 id="玩转钢笔"><a href="#玩转钢笔" class="headerlink" title="玩转钢笔"></a>玩转钢笔</h2><h3 id="钢笔工具（快捷键P）"><a href="#钢笔工具（快捷键P）" class="headerlink" title="钢笔工具（快捷键P）"></a>钢笔工具（快捷键P）</h3><p>1.钢笔工具：</p><p>①绘制直线的方法：在起始点位置点击定点，连续<strong><span style="color:#00f">点击</span></strong>，按住<strong><span style="color:red">Shift</span></strong>键，可以绘制成角度的直线</p><p>②绘制曲线的方法：在起始点位置点击定点，在下一点处<strong><span style="color:#00f">点击并拖拽</span></strong>鼠标，拉出弧线，会出现控制手柄，再一次绘制时，需要按住<strong><span style="color:red">Alt</span></strong>键取消一侧手柄</p><p>③自动添加删除：可以直接在路径上点击添加锚点或者点击锚点删除锚点</p><p>④临时切换：按住<strong><span style="color:red">Ctrl</span></strong>键可以临时切换到小白工具进行锚点移动（自带控制手柄，可以调节弧度大小）</p><p>⑤将路径转换为选区：右击，选择建立选区、或<strong><span style="color:red">Ctrl+Enter回车</span></strong>、或在路径面板下，Ctrl+路径缩览图</p><p>⑥Delete键删除最后一个锚点的同时会结束钢笔工具这一次路径的绘制</p><p>2.自由钢笔工具：点击拖拽鼠标可以画出流畅的线条路径。右击路径，选择画笔勾选<strong><span style="color:#00f">模拟压力</span></strong>（需先设置好画笔大小、硬度等）</p><p>3.转换点工具：点击曲线位置的点，可以将其变成直线。点击直线位置的点，选中并拖拽，可以出现控制手柄，调节弧度</p><h3 id="路径面板"><a href="#路径面板" class="headerlink" title="路径面板"></a>路径面板</h3><p>1.路径面板可以实现选区与路径的互相转换</p><p>2.储存为jpg,psd时，路径面板可以储存路径，类似图层，便于抠图便于工作</p><h3 id="画笔（快捷键：B）"><a href="#画笔（快捷键：B）" class="headerlink" title="画笔（快捷键：B）"></a>画笔（快捷键：B）</h3><p>1.载入画笔：设置中找到载入画笔，找到画笔点击载入，右键可以删除画笔</p><p>2.画笔面板（快捷键F5）：形状动态、散布、颜色动态</p><p>3.定义画笔预设：编辑—定义画笔预设 画笔只认黑白灰，黑（实色颜色）、白（没有颜色）、灰（半透明）</p><h2 id="多元化的文字"><a href="#多元化的文字" class="headerlink" title="多元化的文字"></a>多元化的文字</h2><h3 id="文字工具"><a href="#文字工具" class="headerlink" title="文字工具"></a>文字工具</h3><p>（推荐：www.qiuziti.com来找字体）</p><p>1.横排文字蒙版（直排文字蒙版）工具：点击就会出现红色蒙版，输入文字确定后不会新建图层，并且文字会变为选区</p><p>2.横排文字（竖排文字）工具：点击会自动新建文字图层，可以再属性栏处更改文字属性</p><p>3.确定文字输入：属性栏的对勾 或Ctrl+Enter回车 或<strong><span style="color:#00f">小键盘</span></strong>下的Enter</p><p>4.全选：Ctrl+A或双击文字图层缩览图</p><p>5.调节字间距：Alt+左右箭头</p><p>6.调节行间距：Alt+上下箭头</p><p>7.点文字：不会自动换行，换行需要手动回车进行换行，适合做标题文字</p><p>8.段文字（区域文字）：在画布上点击并拖拽拉出文本框，会自动换行，文字溢出时下方有加号提示，适合做说明文字</p><p>9.路径文字：用钢笔或者形状工具，绘制一段路径，将文字工具的光标放在路径上，点击输入文字。用小白调节文字形态</p><h2 id="图层样式-图层混合模式"><a href="#图层样式-图层混合模式" class="headerlink" title="图层样式+图层混合模式"></a>图层样式+图层混合模式</h2><h3 id="混合模式（27个）"><a href="#混合模式（27个）" class="headerlink" title="混合模式（27个）"></a>混合模式（27个）</h3><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/clip_image002.jpg" alt="img"></p><p>1.使用要求：必须<strong><span style="color:#00f">两个或两个以上</span></strong>的图层才能进行混合</p><p>2.混合模式分组：</p><p>A.组合模式：需要降低图层的不透明度才能产生作用</p><p>B.加深混合组：可以使图像<strong><span style="color:#00f">变暗</span></strong>，将下方图层中的亮色被上方较暗的像素替代</p><p>C.减淡混合组：与加深混合组相反，可以使图像<strong><span style="color:#00f">变亮</span></strong>，将下方图层中的暗色被上方较亮的像素替代</p><p>D.对比混合组：50%的灰色完全消失，高于50%灰的像素会使底图<strong><span style="color:#00f">变亮</span></strong>，低于50%灰的像素会使底图<strong><span style="color:#00f">变暗</span></strong></p><p>E.比较混合组：相同的区域显示为黑色，不同的区域显示为灰度层次或彩色。当图层中包含白色，白色区域会使底层图像反相，而黑色不会对底层图像产生影响。</p><p>F.色彩混合组：将色彩的色相、饱和度和亮度，替换给下方图层</p><p>3.重要的混合模式选项（4个）</p><p>①加深混合组：<strong><span style="color:#00f">正片叠底</span></strong>（去白留黑）</p><p>②减淡混合组：<strong><span style="color:#00f">滤色</span></strong>（去黑留白）</p><p>③比较混合组：<strong><span style="color:#00f">叠加</span></strong>，使你的颜色跟下方图层进行有机的的叠加，同时修改下方图层的本身的亮度和明暗程度，比较柔和的效果</p><p>④<strong><span style="color:#00f">柔光</span></strong> ，效果更好，画面更融合</p><h3 id="图层样式"><a href="#图层样式" class="headerlink" title="图层样式"></a>图层样式</h3><p>1.添加图层样式：</p><p>①双击图层缩览图的后方，弹出对话框</p><p>②点击图层面板下方Fx按钮，添加图层样式</p><p>③图层菜单中选择</p><p>④在画布区域右击弹出<strong><span style="color:#00f">混合选项</span></strong> 选择（移动工具、抓手工具、放大镜工具不可）</p><p>2.复制图层样式：按住Alt键点击图层样式Fx进行拖拽到需要复制的图层</p><p>或在图层上右击鼠标选择<strong><span style="color:#00f">拷贝图层样式</span></strong> 在需要复制的图层上右击选择<strong><span style="color:#00f">粘贴图层样式</span></strong></p><p>3.填充：可以将颜色降低透明度，图层样式不变</p><h2 id="蒙版带你领略台前幕后的故事"><a href="#蒙版带你领略台前幕后的故事" class="headerlink" title="蒙版带你领略台前幕后的故事"></a>蒙版带你领略台前幕后的故事</h2><h3 id="快速蒙版（快捷键Q）"><a href="#快速蒙版（快捷键Q）" class="headerlink" title="快速蒙版（快捷键Q）"></a>快速蒙版（快捷键Q）</h3><p>快速蒙版是一种<strong><span style="color:#00f">选区工具</span></strong> 结合画笔工具使用，常用与影楼。双击快速蒙版，可以更改快速蒙版建立的选区形式</p><h3 id="剪贴蒙版（上图下形）"><a href="#剪贴蒙版（上图下形）" class="headerlink" title="剪贴蒙版（上图下形）"></a>剪贴蒙版（上图下形）</h3><p>1.原理是将上层图层置于下层图层内，他们必须是<strong><span style="color:#00f">上下层关系</span></strong></p><p>2.下方图层可以是形状、图层、画笔、文字、智能对象</p><p>3.上图层右击选择创建剪贴蒙版，或按住Alt键，在上下图层之间移动，出现方框带箭头形状，单击鼠标左键，或<strong><span style="color:red">Ctrl+Alt+G </span></strong>创建/释放</p><p>4.剪切蒙版可以<strong><span style="color:#00f">同时多个图层</span></strong> 进行剪贴蒙版</p><h3 id="图层蒙版（黑隐藏白显示灰色半透明）"><a href="#图层蒙版（黑隐藏白显示灰色半透明）" class="headerlink" title="图层蒙版（黑隐藏白显示灰色半透明）"></a>图层蒙版（黑隐藏白显示灰色半透明）</h3><p>1.蒙版颜色表示的意义：<strong><span style="color:#00f">黑色：隐藏图像、白色：显示图像、灰色半透明</span></strong> 蒙版只认黑白灰，除了黑白其他颜色都是不同程度的灰</p><p>2.可以在蒙版上添加颜色的方式：画笔、渐变、填充等</p><p>3.暂停蒙版使用：按住Shift点击图层蒙版缩览图</p><p>4.使用蒙版时容易出现的问题：</p><p>①在使用时出现涂抹颜色的情况，多数是没有添加或选择蒙版缩览图。</p><p>②在使用蒙版时，涂抹无效果，看下当前前景色是否是白色</p><p>③在使用蒙版时，涂抹无效果，看下画笔的透明度或流量是否是1%</p><h3 id="通道"><a href="#通道" class="headerlink" title="通道"></a>通道</h3><p>1.作用：用于储存颜色信息，相当于颜色银行</p><p>2.第一个通道为复合通道，不同的通道会显示不同的颜色信息</p><p>3.单色通道中黑白灰的意义：白色表示颜色值最高255，黑色0，灰色0-255</p><p>4.Alpha通道的作用：可以储存和制作选区，黑色非选区，白色选区，灰色半透明选区</p><h3 id="快捷键整理-6"><a href="#快捷键整理-6" class="headerlink" title="快捷键整理"></a>快捷键整理</h3><div class="table-container"><table><thead><tr><th>创建/释放剪贴蒙版 Ctrl+Alt+G</th><th></th></tr></thead><tbody><tr><td></td></tr></tbody></table></div><h2 id="打造滤镜下的艺术效果"><a href="#打造滤镜下的艺术效果" class="headerlink" title="打造滤镜下的艺术效果"></a>打造滤镜下的艺术效果</h2><h3 id="滤镜"><a href="#滤镜" class="headerlink" title="滤镜"></a>滤镜</h3><p>1.转换为智能滤镜：可以将普通的位图转为<strong><span style="color:#00f">智能对象</span></strong></p><p>2.滤镜使用规则：▼ RGB模式下<strong><span style="color:#00f">滤镜都可以使用</span></strong></p><p>▼ CMYK Lab 模式下有部分滤镜不能使用</p><p>▼ 索引模式下滤镜不能使用.</p><p>3.智能滤镜的优点：<strong><span style="color:#00f">自带蒙版，可编辑性强</span></strong>，可以对滤镜的效果单独进行多次修改或调整</p><p>4.上次滤镜操作：快捷键Ctrl+F可以再次执行<strong><span style="color:#00f">上次</span></strong>的滤镜操作</p><p>5.渐隐：快捷键Ctrl+Shift+F 编辑—渐隐 对普通图层滤镜效果再编辑，可以调整不透明度和混合模式（不常用）</p><p>6.图像中有选区时，滤镜效果只对<strong><span style="color:#00f">选区内有效</span></strong>，没有选区时，对整体图像有效</p><p>7.滤镜库：里面有现成的滤镜效果，可以通过<strong><span style="color:#00f">调成参数</span></strong>从而改变滤镜的效果，通过下方新建按钮可以创建多个滤镜效果</p><p>8.滤镜库—素描：<strong><span style="color:#00f">多个</span></strong>滤镜应用前/背景色，亮部应用背景色，暗部应用前景色</p><p>9.▷ 自适应广角：可较正广角导致的变形图像</p><p>▷ camera raw滤镜：可以调整图像颜色等</p><p>▷ 镜头较正：可制作鱼眼镜头拍摄产生的效果，可以对照片的畸变和暗角进行一定程度的矫正</p><p>▷ 液化：可通过平移、旋转、进行像素变形（瘦身瘦脸等）</p><p>▷ 消失点：可以通过内置透视网格、进行图像修图（透视：近大远小效果）</p><p>▷ 模糊系列：可以根据参数对图像进行各种形式整体模糊处理。局部模糊可以通过选框进行控制。</p><p>▷ 扭曲系列：根据不同方式对图像进行整体像素变形</p><p>▷ 锐化系列：对图像进行整体边缘对比强化，使图片整体更加清晰。如果参数过大图像会损坏。</p><p>▷ 杂色：添加杂色：可以添加颗粒杂色</p><p>▷ 其他滤镜：高反差保留：可以保留细节与叠加柔光一起使用</p><p>10.渲染—云彩：可以应用没有像素的区域（空白图层），应用的是前/背景色</p><h3 id="快捷键整理-7"><a href="#快捷键整理-7" class="headerlink" title="快捷键整理"></a>快捷键整理</h3><div class="table-container"><table><thead><tr><th>重复上次滤镜 Ctrl+Alt＋F</th><th>低版本重复上次滤镜 Ctrl＋F</th></tr></thead><tbody><tr><td>渐隐 Ctrl+Shift+F</td></tr></tbody></table></div><h2 id="让我们换一种颜色看世界（调色一）"><a href="#让我们换一种颜色看世界（调色一）" class="headerlink" title="让我们换一种颜色看世界（调色一）"></a>让我们换一种颜色看世界（调色一）</h2><h3 id="色彩模式"><a href="#色彩模式" class="headerlink" title="色彩模式"></a>色彩模式</h3><p>1.RGB：<strong><span style="color:#00f">光学三原色</span></strong>，也是调色运用最多的一种颜色模式</p><p>2.CMYK：印刷用的颜色 青、洋红、黄、黑</p><p>3.灰度模式：图像不包含颜色，只有黑白灰三种颜色，并影响之后的颜色使用</p><p>4.去色（<strong><span style="color:red">Ctrl+Shift+U </span></strong>）：把图像的饱和度降到最低，不影响色彩模式，对于之后的颜色使用没有影响</p><p>5.更改模式：菜单栏—图像—模式</p><h3 id="调色"><a href="#调色" class="headerlink" title="调色"></a>调色</h3><p>1.调整面板：点击效果，直接新建图层，自带图层蒙版，可以多次调解，只对下方图层起作用</p><p>2.亮度/对比度：亮度、添加/减少图像明暗程度</p><p>​ 对比度、增加/降低图像明暗对比程度</p><p>3.色相/饱和度<strong><span style="color:red">Ctrl+U </span></strong>：色相、色彩的相貌</p><p>​ 饱和度、颜色鲜艳程度</p><p>​ 明度、颜色的明暗程度</p><p>​ 单色制作时勾选着色</p><p>4.三原色：红绿蓝 间色：原色+原色=间色 黄、洋红、青</p><p>互补色（反色）：可以互相抵消的颜色、180°的颜色、相对的颜色</p><p>三对互补色：<strong><span style="color:#00f">红色与青色 蓝色与黄色 绿色与洋红</span></strong></p><p>5.色彩平衡（<strong><span style="color:red">Ctrl+B </span></strong>）：可以根据颜色的色相来调节</p><p>6.渐变映射：一般结合混合模式和不透明度来使用 通俗的说就是用你所设定的颜色，对应到原图的色彩上。用这种效果可以达到某些非常夸张的色彩搭配效果。</p><p>7.可选颜色：对单一颜色进行调整</p><p>“相对”比较柔和 “绝对”比较犀利 相对运用的较多</p><p>8.替换颜色：图像—调整—替换颜色 拾取一种颜色，选择另一种颜色替换（可以用添加吸管添加颜色）</p><h3 id="快捷键整理-8"><a href="#快捷键整理-8" class="headerlink" title="快捷键整理"></a>快捷键整理</h3><div class="table-container"><table><thead><tr><th>去色 Ctrl+Shift+U</th><th></th></tr></thead><tbody><tr><td></td></tr></tbody></table></div><h2 id="从昏暗到光明（调色二）"><a href="#从昏暗到光明（调色二）" class="headerlink" title="从昏暗到光明（调色二）"></a>从昏暗到光明（调色二）</h2><h3 id="色阶（快捷键Ctrl-L）"><a href="#色阶（快捷键Ctrl-L）" class="headerlink" title="色阶（快捷键Ctrl+L）"></a>色阶（快捷键Ctrl+L）</h3><p>1.输入色阶——<a href="https://www.baidu.com/s?wd=数字图像&amp;tn=44039180_cpr&amp;fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1YkuHTYPyfzmWc4PAwhnymd0ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EPjT4PWRLrjRs" target="_blank" rel="noopener external nofollow noreferrer">数字图像</a>本来的色阶范围，通过调节改变<strong><span style="color:#00f">黑白灰范围</span></strong></p><p>输出色阶——是指为打印机指定最小的暗调色阶和最大的<a href="https://www.baidu.com/s?wd=高光&amp;tn=44039180_cpr&amp;fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1YkuHTYPyfzmWc4PAwhnymd0ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EPjT4PWRLrjRs" target="_blank" rel="noopener external nofollow noreferrer">高光</a>色阶，调整时调整的是<strong><span style="color:#00f">整体的明暗度</span></strong></p><p>2.可以调整图像的阴影、中间调和高光的强度级别，校正色调范围和色彩平衡</p><h3 id="曲线（快捷键Ctrl-M）"><a href="#曲线（快捷键Ctrl-M）" class="headerlink" title="曲线（快捷键Ctrl+M）"></a>曲线（快捷键Ctrl+M）</h3><p>它整合了“色阶”、“亮度/对比度”等多个命令的功能。曲线上可以添加<strong><span style="color:#00f">14个</span></strong>控点，移动这些控制点可以对色彩和色调进行非常精确的调整</p><p>a 按Shift 点击可以选中并控制多个控制点</p><p>b 点击Delete键可以删掉控制点</p><h3 id="照片滤镜"><a href="#照片滤镜" class="headerlink" title="照片滤镜"></a>照片滤镜</h3><p>可用于矫正照片的颜色</p><h3 id="颜色查找"><a href="#颜色查找" class="headerlink" title="颜色查找"></a>颜色查找</h3><p>查询颜色，形成滤镜效果</p><h2 id="快捷键总结"><a href="#快捷键总结" class="headerlink" title="快捷键总结"></a>快捷键总结</h2><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/多多快捷键集锦.jpg" alt></p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/多多快捷键2.jpg" alt></p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/多多快捷键3.jpg" alt></p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>photoshop</category>
      </categories>
      <tags>
        <tag>photoshop</tag>
      </tags>
  </entry>
  <entry>
    <title>Pandas中文手册</title>
    <url>/pandas%E4%B8%AD%E6%96%87%E6%89%8B%E5%86%8C.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><!-- build time:Mon Apr 20 2020 13:02:10 GMT+0800 (GMT+08:00) --><p>如果你想学习Pandas，建议先看两个网站。</p><p>（1）官网：Python Data Analysis Library</p><p>（2）十分钟入门Pandas：10 Minutes to pandas</p><h2 id="关键缩写和包导入"><a href="#关键缩写和包导入" class="headerlink" title="关键缩写和包导入"></a><strong>关键缩写和包导入</strong></h2><p>在这个速查手册中，我们使用如下缩写：</p><div class="note info"><p>df：任意的Pandas DataFrame对象</p><p>s：任意的Pandas Series对象</p></div><p>同时我们需要做如下的引入：</p><div class="note info"><p>import pandas as pd</p><p>import numpy as np</p></div><h2 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h2><ul><li>pd.read_csv(filename)：从CSV文件导入数据</li><li>pd.read_table(filename)：从限定分隔符的文本文件导入数据</li><li>pd.read_excel(filename)：从Excel文件导入数据</li><li>pd.read_sql(query, connection_object)：从SQL表/库导入数据</li><li>pd.read_json(json_string)：从JSON格式的字符串导入数据</li><li>pd.read_html(url)：解析URL、字符串或者HTML文件，抽取其中的tables表格</li><li>pd.read_clipboard()：从你的粘贴板获取内容，并传给read_table()</li><li>pd.DataFrame(dict)：从字典对象导入数据，Key是列名，Value是数据</li></ul><h2 id="导出数据"><a href="#导出数据" class="headerlink" title="导出数据"></a>导出数据</h2><ul><li>df.to_csv(filename)：导出数据到CSV文件</li><li>df.to_excel(filename)：导出数据到Excel文件</li><li>df.to_sql(table_name, connection_object)：导出数据到SQL表</li><li>df.to_json(filename)：以Json格式导出数据到文本文件</li></ul><h2 id="创建测试对象"><a href="#创建测试对象" class="headerlink" title="创建测试对象"></a>创建测试对象</h2><ul><li>pd.DataFrame(np.random.rand(20,5))：创建20行5列的随机数组成的DataFrame对象</li><li>pd.Series(my_list)：从可迭代对象my_list创建一个Series对象</li><li>df.index = pd.date_range(‘1900/1/30’, periods=df.shape[0])：增加一个日期索引</li></ul><h2 id="查看、检查数据"><a href="#查看、检查数据" class="headerlink" title="查看、检查数据"></a>查看、检查数据</h2><ul><li>df.head(n)：查看DataFrame对象的前n行</li><li>df.tail(n)：查看DataFrame对象的最后n行</li><li>df.shape()：查看行数和列数</li><li><a href="http://df.info()：查看索引、数据类型和内存信息" rel="external nofollow noreferrer">http://df.info()：查看索引、数据类型和内存信息</a></li><li>df.describe()：查看数值型列的汇总统计</li><li>s.value_counts(dropna=False)：查看Series对象的唯一值和计数</li><li>df.apply(pd.Series.value_counts)：查看DataFrame对象中每一列的唯一值和计数</li></ul><h2 id="数据选取"><a href="#数据选取" class="headerlink" title="数据选取"></a>数据选取</h2><ul><li>df[col]：根据列名，并以Series的形式返回列</li><li>df[[col1, col2]]：以DataFrame形式返回多列</li><li>s.iloc[0]：按位置选取数据</li><li>s.loc[‘index_one’]：按索引选取数据</li><li>df.iloc[0,:]：返回第一行</li><li>df.iloc[0,0]：返回第一列的第一个元素</li></ul><h2 id="数据清理"><a href="#数据清理" class="headerlink" title="数据清理"></a>数据清理</h2><ul><li>df.columns = [‘a’,’b’,’c’]：重命名列名</li><li>pd.isnull()：检查DataFrame对象中的空值，并返回一个Boolean数组</li><li>pd.notnull()：检查DataFrame对象中的非空值，并返回一个Boolean数组</li><li>df.dropna()：删除所有包含空值的行</li><li>df.dropna(axis=1)：删除所有包含空值的列</li><li>df.dropna(axis=1,thresh=n)：删除所有小于n个非空值的行</li><li>df.fillna(x)：用x替换DataFrame对象中所有的空值</li><li>s.astype(float)：将Series中的数据类型更改为float类型</li><li>s.replace(1,’one’)：用‘one’代替所有等于1的值</li><li>s.replace([1,3],[‘one’,’three’])：用’one’代替1，用’three’代替3</li><li>df.rename(columns=lambda x: x + 1)：批量更改列名</li><li>df.rename(columns={‘old_name’: ‘new_ name’})：选择性更改列名</li><li>df.set_index(‘column_one’)：更改索引列</li><li>df.rename(index=lambda x: x + 1)：批量重命名索引</li></ul><h2 id="数据处理：Filter-、Sort-和-GroupBy"><a href="#数据处理：Filter-、Sort-和-GroupBy" class="headerlink" title="数据处理：Filter 、Sort 和 GroupBy"></a>数据处理：Filter 、Sort 和 GroupBy</h2><ul><li>df[df[col] &gt; 0.5]：选择col列的值大于0.5的行</li><li>df.sort_values(col1)：按照列col1排序数据，默认升序排列</li><li>df.sort_values(col2, ascending=False)：按照列col1降序排列数据</li><li>df.sort_values([col1,col2], ascending=[True,False])：先按列col1升序排列，后按col2降序排列数据</li><li>df.groupby(col)：返回一个按列col进行分组的Groupby对象</li><li>df.groupby([col1,col2])：返回一个按多列进行分组的Groupby对象</li><li>df.groupby(col1)[col2]：返回按列col1进行分组后，列col2的均值</li><li>df.pivot_table(index=col1, values=[col2,col3], aggfunc=max)：创建一个按列col1进行分组，并计算col2和col3的最大值的数据透视表</li><li>df.groupby(col1).agg(np.mean)：返回按列col1分组的所有列的均值</li><li>data.apply(np.mean)：对DataFrame中的每一列应用函数np.mean</li><li>data.apply(np.max,axis=1)：对DataFrame中的每一行应用函数np.max</li></ul><h2 id="数据合并"><a href="#数据合并" class="headerlink" title="数据合并"></a>数据合并</h2><ul><li>df1.append(df2)：将df2中的行添加到df1的尾部</li><li>df.concat([df1, df2],axis=1)：将df2中的列添加到df1的尾部</li><li>df1.join(df2,on=col1,how=’inner’)：对df1的列和df2的列执行SQL形式的join</li></ul><h2 id="数据统计"><a href="#数据统计" class="headerlink" title="数据统计"></a>数据统计</h2><ul><li>df.describe()：查看数据值列的汇总统计</li><li>df.mean()：返回所有列的均值</li><li>df.corr()：返回列与列之间的相关系数</li><li>df.count()：返回每一列中的非空值的个数</li><li>df.max()：返回每一列的最大值</li><li>df.min()：返回每一列的最小值</li><li>df.median()：返回每一列的中位数</li><li>df.std()：返回每一列的标准差</li></ul><!-- rebuild by neat -->]]></content>
      <categories>
        <category>Pandas</category>
      </categories>
      <tags>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>十分钟搞定 pandas</title>
    <url>/%E5%8D%81%E5%88%86%E9%92%9F%E6%90%9E%E5%AE%9Apandas.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><!-- build time:Mon Apr 20 2020 13:02:10 GMT+0800 (GMT+08:00) --><p>官方网站上《10 Minutes to pandas》的一个简单的翻译，原文在<a href="http://pandas.pydata.org/pandas-docs/stable/10min.html" target="_blank" rel="noopener external nofollow noreferrer">这里</a>。这篇文章是对 pandas 的一个简单的介绍，详细的介绍请参考：<a href="http://pandas.pydata.org/pandas-docs/stable/cookbook.html#cookbook" target="_blank" rel="noopener external nofollow noreferrer">秘籍</a> 。习惯上，我们会按下面格式引入所需要的包：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure></div><h1 id="一、-创建对象"><a href="#一、-创建对象" class="headerlink" title="一、 创建对象"></a>一、 创建对象</h1><p>可以通过 <a href="http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dsintro" target="_blank" rel="noopener external nofollow noreferrer">数据结构入门</a> 来查看有关该节内容的详细信息。</p><p>1、可以通过传递一个<code>list</code>对象来创建一个<code>Series</code>，pandas 会默认创建整型索引：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">4</span>]: s = pd.Series([<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,np.nan,<span class="number">6</span>,<span class="number">8</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">5</span>]: s</span><br><span class="line">Out[<span class="number">5</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">1.0</span></span><br><span class="line"><span class="number">1</span>    <span class="number">3.0</span></span><br><span class="line"><span class="number">2</span>    <span class="number">5.0</span></span><br><span class="line"><span class="number">3</span>    NaN</span><br><span class="line"><span class="number">4</span>    <span class="number">6.0</span></span><br><span class="line"><span class="number">5</span>    <span class="number">8.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></div><p>2、通过传递一个 numpy<code>array</code>，时间索引以及列标签来创建一个<code>DataFrame</code>：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">6</span>]: dates = pd.date_range(<span class="string">'20130101'</span>, periods=<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: dates</span><br><span class="line">Out[<span class="number">7</span>]: </span><br><span class="line">DatetimeIndex([<span class="string">'2013-01-01'</span>, <span class="string">'2013-01-02'</span>, <span class="string">'2013-01-03'</span>, <span class="string">'2013-01-04'</span>,</span><br><span class="line">               <span class="string">'2013-01-05'</span>, <span class="string">'2013-01-06'</span>],</span><br><span class="line">              dtype=<span class="string">'datetime64[ns]'</span>, freq=<span class="string">'D'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: df = pd.DataFrame(np.random.randn(<span class="number">6</span>,<span class="number">4</span>), index=dates, columns=list(<span class="string">'ABCD'</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: df</span><br><span class="line">Out[<span class="number">9</span>]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.469112</span> <span class="number">-0.282863</span> <span class="number">-1.509059</span> <span class="number">-1.135632</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span> <span class="number">-1.044236</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">1.071804</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">0.271860</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span> <span class="number">-1.087401</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span> <span class="number">-0.673690</span>  <span class="number">0.113648</span> <span class="number">-1.478427</span>  <span class="number">0.524988</span></span><br></pre></td></tr></table></figure></div><p>3、通过传递一个能够被转换成类似序列结构的字典对象来创建一个<code>DataFrame</code>：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">10</span>]: df2 = pd.DataFrame(&#123; <span class="string">'A'</span> : <span class="number">1.</span>,</span><br><span class="line">   ....:                      <span class="string">'B'</span> : pd.Timestamp(<span class="string">'20130102'</span>),</span><br><span class="line">   ....:                      <span class="string">'C'</span> : pd.Series(<span class="number">1</span>,index=list(range(<span class="number">4</span>)),dtype=<span class="string">'float32'</span>),</span><br><span class="line">   ....:                      <span class="string">'D'</span> : np.array([<span class="number">3</span>] * <span class="number">4</span>,dtype=<span class="string">'int32'</span>),</span><br><span class="line">   ....:                      <span class="string">'E'</span> : pd.Categorical([<span class="string">"test"</span>,<span class="string">"train"</span>,<span class="string">"test"</span>,<span class="string">"train"</span>]),</span><br><span class="line">   ....:                      <span class="string">'F'</span> : <span class="string">'foo'</span> &#125;)</span><br><span class="line">   ....: </span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: df2</span><br><span class="line">Out[<span class="number">11</span>]: </span><br><span class="line">     A          B    C  D      E    F</span><br><span class="line"><span class="number">0</span>  <span class="number">1.0</span> <span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.0</span>  <span class="number">3</span>   test  foo</span><br><span class="line"><span class="number">1</span>  <span class="number">1.0</span> <span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.0</span>  <span class="number">3</span>  train  foo</span><br><span class="line"><span class="number">2</span>  <span class="number">1.0</span> <span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.0</span>  <span class="number">3</span>   test  foo</span><br><span class="line"><span class="number">3</span>  <span class="number">1.0</span> <span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.0</span>  <span class="number">3</span>  train  foo</span><br></pre></td></tr></table></figure></div><p>4、查看不同列的数据类型：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">12</span>]: df2.dtypes</span><br><span class="line">Out[<span class="number">12</span>]: </span><br><span class="line">A           float64</span><br><span class="line">B    datetime64[ns]</span><br><span class="line">C           float32</span><br><span class="line">D             int32</span><br><span class="line">E          category</span><br><span class="line">F            object</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure></div><p>5、如果你使用的是 IPython，使用 Tab 自动补全功能会自动识别所有的属性以及自定义的列，下图中是所有能够被自动识别的属性的一个子集：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">13</span>]: df2.&lt;TAB&gt;</span><br><span class="line">df2.A                  df2.boxplot</span><br><span class="line">df2.abs                df2.C</span><br><span class="line">df2.add                df2.clip</span><br><span class="line">df2.add_prefix         df2.clip_lower</span><br><span class="line">df2.add_suffix         df2.clip_upper</span><br><span class="line">df2.align              df2.columns</span><br><span class="line">df2.all                df2.combine</span><br><span class="line">df2.any                df2.combineAdd</span><br><span class="line">df2.append             df2.combine_first</span><br><span class="line">df2.apply              df2.combineMult</span><br><span class="line">df2.applymap           df2.compound</span><br><span class="line">df2.as_blocks          df2.consolidate</span><br><span class="line">df2.asfreq             df2.convert_objects</span><br><span class="line">df2.as_matrix          df2.copy</span><br><span class="line">df2.astype             df2.corr</span><br><span class="line">df2.at                 df2.corrwith</span><br><span class="line">df2.at_time            df2.count</span><br><span class="line">df2.axes               df2.cov</span><br><span class="line">df2.B                  df2.cummax</span><br><span class="line">df2.between_time       df2.cummin</span><br><span class="line">df2.bfill              df2.cumprod</span><br><span class="line">df2.blocks             df2.cumsum</span><br><span class="line">df2.bool               df2.D</span><br></pre></td></tr></table></figure></div><h1 id="二、-查看数据"><a href="#二、-查看数据" class="headerlink" title="二、 查看数据"></a>二、 查看数据</h1><p>详情请参阅：<a href="http://pandas.pydata.org/pandas-docs/stable/basics.html#basics" target="_blank" rel="noopener external nofollow noreferrer">基础</a>。</p><p>1、 查看<code>DataFrame</code>中头部和尾部的行：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">14</span>]: df.head()</span><br><span class="line">Out[<span class="number">14</span>]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.469112</span> <span class="number">-0.282863</span> <span class="number">-1.509059</span> <span class="number">-1.135632</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span> <span class="number">-1.044236</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">1.071804</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">0.271860</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span> <span class="number">-1.087401</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">15</span>]: df.tail(<span class="number">3</span>)</span><br><span class="line">Out[<span class="number">15</span>]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">0.271860</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span> <span class="number">-1.087401</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span> <span class="number">-0.673690</span>  <span class="number">0.113648</span> <span class="number">-1.478427</span>  <span class="number">0.524988</span></span><br></pre></td></tr></table></figure></div><p>2、 显示索引、列和底层的 numpy 数据：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">16</span>]: df.index</span><br><span class="line">Out[<span class="number">16</span>]: </span><br><span class="line">DatetimeIndex([<span class="string">'2013-01-01'</span>, <span class="string">'2013-01-02'</span>, <span class="string">'2013-01-03'</span>, <span class="string">'2013-01-04'</span>,</span><br><span class="line">               <span class="string">'2013-01-05'</span>, <span class="string">'2013-01-06'</span>],</span><br><span class="line">              dtype=<span class="string">'datetime64[ns]'</span>, freq=<span class="string">'D'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: df.columns</span><br><span class="line">Out[<span class="number">17</span>]: Index([<span class="string">u'A'</span>, <span class="string">u'B'</span>, <span class="string">u'C'</span>, <span class="string">u'D'</span>], dtype=<span class="string">'object'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: df.values</span><br><span class="line">Out[<span class="number">18</span>]: </span><br><span class="line">array([[ <span class="number">0.4691</span>, <span class="number">-0.2829</span>, <span class="number">-1.5091</span>, <span class="number">-1.1356</span>],</span><br><span class="line">       [ <span class="number">1.2121</span>, <span class="number">-0.1732</span>,  <span class="number">0.1192</span>, <span class="number">-1.0442</span>],</span><br><span class="line">       [<span class="number">-0.8618</span>, <span class="number">-2.1046</span>, <span class="number">-0.4949</span>,  <span class="number">1.0718</span>],</span><br><span class="line">       [ <span class="number">0.7216</span>, <span class="number">-0.7068</span>, <span class="number">-1.0396</span>,  <span class="number">0.2719</span>],</span><br><span class="line">       [<span class="number">-0.425</span> ,  <span class="number">0.567</span> ,  <span class="number">0.2762</span>, <span class="number">-1.0874</span>],</span><br><span class="line">       [<span class="number">-0.6737</span>,  <span class="number">0.1136</span>, <span class="number">-1.4784</span>,  <span class="number">0.525</span> ]])</span><br></pre></td></tr></table></figure></div><p>3、 <code>describe()</code>函数对于数据的快速统计汇总：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">19</span>]: df.describe()</span><br><span class="line">Out[<span class="number">19</span>]: </span><br><span class="line">              A         B         C         D</span><br><span class="line">count  <span class="number">6.000000</span>  <span class="number">6.000000</span>  <span class="number">6.000000</span>  <span class="number">6.000000</span></span><br><span class="line">mean   <span class="number">0.073711</span> <span class="number">-0.431125</span> <span class="number">-0.687758</span> <span class="number">-0.233103</span></span><br><span class="line">std    <span class="number">0.843157</span>  <span class="number">0.922818</span>  <span class="number">0.779887</span>  <span class="number">0.973118</span></span><br><span class="line">min   <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-1.509059</span> <span class="number">-1.135632</span></span><br><span class="line"><span class="number">25</span>%   <span class="number">-0.611510</span> <span class="number">-0.600794</span> <span class="number">-1.368714</span> <span class="number">-1.076610</span></span><br><span class="line"><span class="number">50</span>%    <span class="number">0.022070</span> <span class="number">-0.228039</span> <span class="number">-0.767252</span> <span class="number">-0.386188</span></span><br><span class="line"><span class="number">75</span>%    <span class="number">0.658444</span>  <span class="number">0.041933</span> <span class="number">-0.034326</span>  <span class="number">0.461706</span></span><br><span class="line">max    <span class="number">1.212112</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span>  <span class="number">1.071804</span></span><br></pre></td></tr></table></figure></div><p>4、 对数据的转置：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">20</span>]: df.T</span><br><span class="line">Out[<span class="number">20</span>]: </span><br><span class="line">   <span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">2013</span><span class="number">-01</span><span class="number">-03</span>  <span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">2013</span><span class="number">-01</span><span class="number">-05</span>  <span class="number">2013</span><span class="number">-01</span><span class="number">-06</span></span><br><span class="line">A    <span class="number">0.469112</span>    <span class="number">1.212112</span>   <span class="number">-0.861849</span>    <span class="number">0.721555</span>   <span class="number">-0.424972</span>   <span class="number">-0.673690</span></span><br><span class="line">B   <span class="number">-0.282863</span>   <span class="number">-0.173215</span>   <span class="number">-2.104569</span>   <span class="number">-0.706771</span>    <span class="number">0.567020</span>    <span class="number">0.113648</span></span><br><span class="line">C   <span class="number">-1.509059</span>    <span class="number">0.119209</span>   <span class="number">-0.494929</span>   <span class="number">-1.039575</span>    <span class="number">0.276232</span>   <span class="number">-1.478427</span></span><br><span class="line">D   <span class="number">-1.135632</span>   <span class="number">-1.044236</span>    <span class="number">1.071804</span>    <span class="number">0.271860</span>   <span class="number">-1.087401</span>    <span class="number">0.524988</span></span><br></pre></td></tr></table></figure></div><p>5、 按轴进行排序</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">21</span>]: df.sort_index(axis=<span class="number">1</span>, ascending=<span class="literal">False</span>)</span><br><span class="line">Out[<span class="number">21</span>]: </span><br><span class="line">                   D         C         B         A</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span> <span class="number">-1.135632</span> <span class="number">-1.509059</span> <span class="number">-0.282863</span>  <span class="number">0.469112</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span> <span class="number">-1.044236</span>  <span class="number">0.119209</span> <span class="number">-0.173215</span>  <span class="number">1.212112</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span>  <span class="number">1.071804</span> <span class="number">-0.494929</span> <span class="number">-2.104569</span> <span class="number">-0.861849</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.271860</span> <span class="number">-1.039575</span> <span class="number">-0.706771</span>  <span class="number">0.721555</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-1.087401</span>  <span class="number">0.276232</span>  <span class="number">0.567020</span> <span class="number">-0.424972</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span>  <span class="number">0.524988</span> <span class="number">-1.478427</span>  <span class="number">0.113648</span> <span class="number">-0.673690</span></span><br></pre></td></tr></table></figure></div><p>6、 按值进行排序</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">22</span>]: df.sort_values(by=<span class="string">'B'</span>)</span><br><span class="line">Out[<span class="number">22</span>]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">1.071804</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">0.271860</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.469112</span> <span class="number">-0.282863</span> <span class="number">-1.509059</span> <span class="number">-1.135632</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span> <span class="number">-1.044236</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span> <span class="number">-0.673690</span>  <span class="number">0.113648</span> <span class="number">-1.478427</span>  <span class="number">0.524988</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span> <span class="number">-1.087401</span></span><br></pre></td></tr></table></figure></div><h1 id="三、-选择"><a href="#三、-选择" class="headerlink" title="三、 选择"></a>三、 选择</h1><p>虽然标准的 Python/Numpy 的选择和设置表达式都能够直接派上用场，但是作为工程使用的代码，我们推荐使用经过优化的 pandas 数据访问方式： <code>.at</code>, <code>.iat</code>, <code>.loc</code>, <code>.iloc</code> 和 <code>.ix</code>。详情请参阅<a href="http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing" target="_blank" rel="noopener external nofollow noreferrer">索引和选取数据</a> 和 <a href="http://pandas.pydata.org/pandas-docs/stable/advanced.html#advanced" target="_blank" rel="noopener external nofollow noreferrer">多重索引/高级索引</a>。</p><h2 id="获取"><a href="#获取" class="headerlink" title="获取"></a>获取</h2><p>1、 选择一个单独的列，这将会返回一个<code>Series</code>，等同于<code>df.A</code>：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">23</span>]: df[<span class="string">'A'</span>]</span><br><span class="line">Out[<span class="number">23</span>]: </span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>    <span class="number">0.469112</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>    <span class="number">1.212112</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span>   <span class="number">-0.861849</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>    <span class="number">0.721555</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span>   <span class="number">-0.424972</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span>   <span class="number">-0.673690</span></span><br><span class="line">Freq: D, Name: A, dtype: float64</span><br></pre></td></tr></table></figure></div><p>2、 通过<code>[]</code>进行选择，这将会对行进行切片</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">24</span>]: df[<span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line">Out[<span class="number">24</span>]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.469112</span> <span class="number">-0.282863</span> <span class="number">-1.509059</span> <span class="number">-1.135632</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span> <span class="number">-1.044236</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">1.071804</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: df[<span class="string">'20130102'</span>:<span class="string">'20130104'</span>]</span><br><span class="line">Out[<span class="number">25</span>]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span> <span class="number">-1.044236</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">1.071804</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">0.271860</span></span><br></pre></td></tr></table></figure></div><h2 id="通过标签选择"><a href="#通过标签选择" class="headerlink" title="通过标签选择"></a>通过标签选择</h2><p>1、 使用标签来获取一个交叉的区域</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">26</span>]: df.loc[dates[<span class="number">0</span>]]</span><br><span class="line">Out[<span class="number">26</span>]: </span><br><span class="line">A    <span class="number">0.469112</span></span><br><span class="line">B   <span class="number">-0.282863</span></span><br><span class="line">C   <span class="number">-1.509059</span></span><br><span class="line">D   <span class="number">-1.135632</span></span><br><span class="line">Name: <span class="number">2013</span><span class="number">-01</span><span class="number">-01</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>, dtype: float64</span><br></pre></td></tr></table></figure></div><p>2、 通过标签来在多个轴上进行选择</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">27</span>]: df.loc[:,[<span class="string">'A'</span>,<span class="string">'B'</span>]]</span><br><span class="line">Out[<span class="number">27</span>]: </span><br><span class="line">                   A         B</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.469112</span> <span class="number">-0.282863</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span> <span class="number">-0.673690</span>  <span class="number">0.113648</span></span><br></pre></td></tr></table></figure></div><p>3、 标签切片</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">28</span>]: df.loc[<span class="string">'20130102'</span>:<span class="string">'20130104'</span>,[<span class="string">'A'</span>,<span class="string">'B'</span>]]</span><br><span class="line">Out[<span class="number">28</span>]: </span><br><span class="line">                   A         B</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span></span><br></pre></td></tr></table></figure></div><p>4、 对于返回的对象进行维度缩减</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">29</span>]: df.loc[<span class="string">'20130102'</span>,[<span class="string">'A'</span>,<span class="string">'B'</span>]]</span><br><span class="line">Out[<span class="number">29</span>]: </span><br><span class="line">A    <span class="number">1.212112</span></span><br><span class="line">B   <span class="number">-0.173215</span></span><br><span class="line">Name: <span class="number">2013</span><span class="number">-01</span><span class="number">-02</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>, dtype: float64</span><br></pre></td></tr></table></figure></div><p>5、 获取一个标量</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">30</span>]: df.loc[dates[<span class="number">0</span>],<span class="string">'A'</span>]</span><br><span class="line">Out[<span class="number">30</span>]: <span class="number">0.46911229990718628</span></span><br></pre></td></tr></table></figure></div><p>6、 快速访问一个标量（与上一个方法等价）</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">31</span>]: df.at[dates[<span class="number">0</span>],<span class="string">'A'</span>]</span><br><span class="line">Out[<span class="number">31</span>]: <span class="number">0.46911229990718628</span></span><br></pre></td></tr></table></figure></div><h2 id="通过位置选择"><a href="#通过位置选择" class="headerlink" title="通过位置选择"></a>通过位置选择</h2><p>1、 通过传递数值进行位置选择（选择的是行）</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">32</span>]: df.iloc[<span class="number">3</span>]</span><br><span class="line">Out[<span class="number">32</span>]: </span><br><span class="line">A    <span class="number">0.721555</span></span><br><span class="line">B   <span class="number">-0.706771</span></span><br><span class="line">C   <span class="number">-1.039575</span></span><br><span class="line">D    <span class="number">0.271860</span></span><br><span class="line">Name: <span class="number">2013</span><span class="number">-01</span><span class="number">-04</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>, dtype: float64</span><br></pre></td></tr></table></figure></div><p>2、 通过数值进行切片，与 numpy/python 中的情况类似</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">33</span>]: df.iloc[<span class="number">3</span>:<span class="number">5</span>,<span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">33</span>]: </span><br><span class="line">                   A         B</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span></span><br></pre></td></tr></table></figure></div><p>3、 通过指定一个位置的列表，与 numpy/python 中的情况类似</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">34</span>]: df.iloc[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>],[<span class="number">0</span>,<span class="number">2</span>]]</span><br><span class="line">Out[<span class="number">34</span>]: </span><br><span class="line">                   A         C</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span>  <span class="number">0.119209</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-0.494929</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.276232</span></span><br></pre></td></tr></table></figure></div><p>4、 对行进行切片</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">35</span>]: df.iloc[<span class="number">1</span>:<span class="number">3</span>,:]</span><br><span class="line">Out[<span class="number">35</span>]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span> <span class="number">-1.044236</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">1.071804</span></span><br></pre></td></tr></table></figure></div><p>5、 对列进行切片</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">36</span>]: df.iloc[:,<span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">Out[<span class="number">36</span>]: </span><br><span class="line">                   B         C</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span> <span class="number">-0.282863</span> <span class="number">-1.509059</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span>  <span class="number">0.113648</span> <span class="number">-1.478427</span></span><br></pre></td></tr></table></figure></div><p>6、 获取特定的值</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">37</span>]: df.iloc[<span class="number">1</span>,<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">37</span>]: <span class="number">-0.17321464905330858</span></span><br></pre></td></tr></table></figure></div><p>快速访问标量（等同于前一个方法）：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">38</span>]: df.iat[<span class="number">1</span>,<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">38</span>]: <span class="number">-0.17321464905330858</span></span><br></pre></td></tr></table></figure></div><h2 id="布尔索引"><a href="#布尔索引" class="headerlink" title="布尔索引"></a>布尔索引</h2><p>1、 使用一个单独列的值来选择数据：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">39</span>]: df[df.A &gt; <span class="number">0</span>]</span><br><span class="line">Out[<span class="number">39</span>]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.469112</span> <span class="number">-0.282863</span> <span class="number">-1.509059</span> <span class="number">-1.135632</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span> <span class="number">-1.044236</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">0.271860</span></span><br></pre></td></tr></table></figure></div><p>2、 使用<code>where</code>操作来选择数据：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">40</span>]: df[df &gt; <span class="number">0</span>]</span><br><span class="line">Out[<span class="number">40</span>]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.469112</span>       NaN       NaN       NaN</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span>       NaN  <span class="number">0.119209</span>       NaN</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span>       NaN       NaN       NaN  <span class="number">1.071804</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span>       NaN       NaN  <span class="number">0.271860</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span>       NaN  <span class="number">0.567020</span>  <span class="number">0.276232</span>       NaN</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span>       NaN  <span class="number">0.113648</span>       NaN  <span class="number">0.524988</span></span><br></pre></td></tr></table></figure></div><p>3、 使用<code>isin()</code>方法来过滤：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">41</span>]: df2 = df.copy()</span><br><span class="line"></span><br><span class="line">In [<span class="number">42</span>]: df2[<span class="string">'E'</span>] = [<span class="string">'one'</span>, <span class="string">'one'</span>,<span class="string">'two'</span>,<span class="string">'three'</span>,<span class="string">'four'</span>,<span class="string">'three'</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: df2</span><br><span class="line">Out[<span class="number">43</span>]: </span><br><span class="line">                   A         B         C         D      E</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.469112</span> <span class="number">-0.282863</span> <span class="number">-1.509059</span> <span class="number">-1.135632</span>    one</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span> <span class="number">-1.044236</span>    one</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">1.071804</span>    two</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">0.271860</span>  three</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span> <span class="number">-1.087401</span>   four</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span> <span class="number">-0.673690</span>  <span class="number">0.113648</span> <span class="number">-1.478427</span>  <span class="number">0.524988</span>  three</span><br><span class="line"></span><br><span class="line">In [<span class="number">44</span>]: df2[df2[<span class="string">'E'</span>].isin([<span class="string">'two'</span>,<span class="string">'four'</span>])]</span><br><span class="line">Out[<span class="number">44</span>]: </span><br><span class="line">                   A         B         C         D     E</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">1.071804</span>   two</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span> <span class="number">-1.087401</span>  four</span><br></pre></td></tr></table></figure></div><h2 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h2><p>1、 设置一个新的列：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">45</span>]: s1 = pd.Series([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], index=pd.date_range(<span class="string">'20130102'</span>, periods=<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">46</span>]: s1</span><br><span class="line">Out[<span class="number">46</span>]: </span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>    <span class="number">1</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span>    <span class="number">2</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>    <span class="number">3</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span>    <span class="number">4</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span>    <span class="number">5</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-07</span>    <span class="number">6</span></span><br><span class="line">Freq: D, dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">47</span>]: df[<span class="string">'F'</span>] = s1</span><br></pre></td></tr></table></figure></div><p>2、 通过标签设置新的值：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">48</span>]: df.at[dates[<span class="number">0</span>],<span class="string">'A'</span>] = <span class="number">0</span></span><br></pre></td></tr></table></figure></div><p>3、 通过位置设置新的值：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">49</span>]: df.iat[<span class="number">0</span>,<span class="number">1</span>] = <span class="number">0</span></span><br></pre></td></tr></table></figure></div><p>4、 通过一个numpy数组设置一组新值：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">50</span>]: df.loc[:,<span class="string">'D'</span>] = np.array([<span class="number">5</span>] * len(df))</span><br></pre></td></tr></table></figure></div><p>上述操作结果如下：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">51</span>]: df</span><br><span class="line">Out[<span class="number">51</span>]: </span><br><span class="line">                   A         B         C  D    F</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span> <span class="number">-1.509059</span>  <span class="number">5</span>  NaN</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span>  <span class="number">5</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">5</span>  <span class="number">2.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">5</span>  <span class="number">3.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span>  <span class="number">5</span>  <span class="number">4.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span> <span class="number">-0.673690</span>  <span class="number">0.113648</span> <span class="number">-1.478427</span>  <span class="number">5</span>  <span class="number">5.0</span></span><br></pre></td></tr></table></figure></div><p>5、 通过where操作来设置新的值：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">52</span>]: df2 = df.copy()</span><br><span class="line"></span><br><span class="line">In [<span class="number">53</span>]: df2[df2 &gt; <span class="number">0</span>] = -df2</span><br><span class="line"></span><br><span class="line">In [<span class="number">54</span>]: df2</span><br><span class="line">Out[<span class="number">54</span>]: </span><br><span class="line">                   A         B         C  D    F</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span> <span class="number">-1.509059</span> <span class="number">-5</span>  NaN</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span> <span class="number">-1.212112</span> <span class="number">-0.173215</span> <span class="number">-0.119209</span> <span class="number">-5</span> <span class="number">-1.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span> <span class="number">-5</span> <span class="number">-2.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span> <span class="number">-0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span> <span class="number">-5</span> <span class="number">-3.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span> <span class="number">-0.567020</span> <span class="number">-0.276232</span> <span class="number">-5</span> <span class="number">-4.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span> <span class="number">-0.673690</span> <span class="number">-0.113648</span> <span class="number">-1.478427</span> <span class="number">-5</span> <span class="number">-5.0</span></span><br></pre></td></tr></table></figure></div><h1 id="四、-缺失值处理"><a href="#四、-缺失值处理" class="headerlink" title="四、 缺失值处理"></a>四、 缺失值处理</h1><p>在 pandas 中，使用<code>np.nan</code>来代替缺失值，这些值将默认不会包含在计算中，详情请参阅：<a href="http://pandas.pydata.org/pandas-docs/stable/missing_data.html#missing-data" target="_blank" rel="noopener external nofollow noreferrer">缺失的数据</a>。</p><p>1、 <code>reindex()</code>方法可以对指定轴上的索引进行改变/增加/删除操作，这将返回原始数据的一个拷贝：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">55</span>]: df1 = df.reindex(index=dates[<span class="number">0</span>:<span class="number">4</span>], columns=list(df.columns) + [<span class="string">'E'</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">56</span>]: df1.loc[dates[<span class="number">0</span>]:dates[<span class="number">1</span>],<span class="string">'E'</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">57</span>]: df1</span><br><span class="line">Out[<span class="number">57</span>]: </span><br><span class="line">                   A         B         C  D    F    E</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span> <span class="number">-1.509059</span>  <span class="number">5</span>  NaN  <span class="number">1.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span>  <span class="number">5</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">5</span>  <span class="number">2.0</span>  NaN</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">5</span>  <span class="number">3.0</span>  NaN</span><br></pre></td></tr></table></figure></div><p>2、 去掉包含缺失值的行：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">58</span>]: df1.dropna(how=<span class="string">'any'</span>)</span><br><span class="line">Out[<span class="number">58</span>]: </span><br><span class="line">                   A         B         C  D    F    E</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span>  <span class="number">5</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br></pre></td></tr></table></figure></div><p>3、 对缺失值进行填充：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">59</span>]: df1.fillna(value=<span class="number">5</span>)</span><br><span class="line">Out[<span class="number">59</span>]: </span><br><span class="line">                   A         B         C  D    F    E</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span> <span class="number">-1.509059</span>  <span class="number">5</span>  <span class="number">5.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span>  <span class="number">5</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">5</span>  <span class="number">2.0</span>  <span class="number">5.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">5</span>  <span class="number">3.0</span>  <span class="number">5.0</span></span><br></pre></td></tr></table></figure></div><p>4、 对数据进行布尔填充：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">n [<span class="number">60</span>]: pd.isnull(df1)</span><br><span class="line">Out[<span class="number">60</span>]: </span><br><span class="line">                A      B      C      D      F      E</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>   <span class="literal">True</span>  <span class="literal">False</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>   <span class="literal">True</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>  <span class="literal">False</span>   <span class="literal">True</span></span><br></pre></td></tr></table></figure></div><h1 id="五、-相关操作"><a href="#五、-相关操作" class="headerlink" title="五、 相关操作"></a>五、 相关操作</h1><p>详情请参与 <a href="http://pandas.pydata.org/pandas-docs/stable/basics.html#basics-binop" target="_blank" rel="noopener external nofollow noreferrer">基本的二进制操作</a></p><h2 id="统计（相关操作通常情况下不包括缺失值）"><a href="#统计（相关操作通常情况下不包括缺失值）" class="headerlink" title="统计（相关操作通常情况下不包括缺失值）"></a>统计（相关操作通常情况下不包括缺失值）</h2><p>1、 执行描述性统计：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">61</span>]: df.mean()</span><br><span class="line">Out[<span class="number">61</span>]: </span><br><span class="line">A   <span class="number">-0.004474</span></span><br><span class="line">B   <span class="number">-0.383981</span></span><br><span class="line">C   <span class="number">-0.687758</span></span><br><span class="line">D    <span class="number">5.000000</span></span><br><span class="line">F    <span class="number">3.000000</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></div><p>2、 在其他轴上进行相同的操作：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">62</span>]: df.mean(<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">62</span>]: </span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>    <span class="number">0.872735</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>    <span class="number">1.431621</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span>    <span class="number">0.707731</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>    <span class="number">1.395042</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span>    <span class="number">1.883656</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span>    <span class="number">1.592306</span></span><br><span class="line">Freq: D, dtype: float64</span><br></pre></td></tr></table></figure></div><p>3、 对于拥有不同维度，需要对齐的对象进行操作。Pandas 会自动的沿着指定的维度进行广播：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">63</span>]: s = pd.Series([<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,np.nan,<span class="number">6</span>,<span class="number">8</span>], index=dates).shift(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">64</span>]: s</span><br><span class="line">Out[<span class="number">64</span>]: </span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>    NaN</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>    NaN</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span>    <span class="number">1.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>    <span class="number">3.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span>    <span class="number">5.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span>    NaN</span><br><span class="line">Freq: D, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">65</span>]: df.sub(s, axis=<span class="string">'index'</span>)</span><br><span class="line">Out[<span class="number">65</span>]: </span><br><span class="line">                   A         B         C    D    F</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>       NaN       NaN       NaN  NaN  NaN</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>       NaN       NaN       NaN  NaN  NaN</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-1.861849</span> <span class="number">-3.104569</span> <span class="number">-1.494929</span>  <span class="number">4.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span> <span class="number">-2.278445</span> <span class="number">-3.706771</span> <span class="number">-4.039575</span>  <span class="number">2.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-5.424972</span> <span class="number">-4.432980</span> <span class="number">-4.723768</span>  <span class="number">0.0</span> <span class="number">-1.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span>       NaN       NaN       NaN  NaN  NaN</span><br></pre></td></tr></table></figure></div><h2 id="Apply"><a href="#Apply" class="headerlink" title="Apply"></a><code>Apply</code></h2><p>1、 对数据应用函数：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">66</span>]: df.apply(np.cumsum)</span><br><span class="line">Out[<span class="number">66</span>]: </span><br><span class="line">                   A         B         C   D     F</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span> <span class="number">-1.509059</span>   <span class="number">5</span>   NaN</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span> <span class="number">-1.389850</span>  <span class="number">10</span>   <span class="number">1.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span>  <span class="number">0.350263</span> <span class="number">-2.277784</span> <span class="number">-1.884779</span>  <span class="number">15</span>   <span class="number">3.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">1.071818</span> <span class="number">-2.984555</span> <span class="number">-2.924354</span>  <span class="number">20</span>   <span class="number">6.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span>  <span class="number">0.646846</span> <span class="number">-2.417535</span> <span class="number">-2.648122</span>  <span class="number">25</span>  <span class="number">10.0</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span> <span class="number">-0.026844</span> <span class="number">-2.303886</span> <span class="number">-4.126549</span>  <span class="number">30</span>  <span class="number">15.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">67</span>]: df.apply(<span class="keyword">lambda</span> x: x.max() - x.min())</span><br><span class="line">Out[<span class="number">67</span>]: </span><br><span class="line">A    <span class="number">2.073961</span></span><br><span class="line">B    <span class="number">2.671590</span></span><br><span class="line">C    <span class="number">1.785291</span></span><br><span class="line">D    <span class="number">0.000000</span></span><br><span class="line">F    <span class="number">4.000000</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></div><h2 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h2><p>具体请参照：<a href="http://pandas.pydata.org/pandas-docs/stable/basics.html#basics-discretization" target="_blank" rel="noopener external nofollow noreferrer">直方图和离散化</a>。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">68</span>]: s = pd.Series(np.random.randint(<span class="number">0</span>, <span class="number">7</span>, size=<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">69</span>]: s</span><br><span class="line">Out[<span class="number">69</span>]: </span><br><span class="line"><span class="number">0</span>    <span class="number">4</span></span><br><span class="line"><span class="number">1</span>    <span class="number">2</span></span><br><span class="line"><span class="number">2</span>    <span class="number">1</span></span><br><span class="line"><span class="number">3</span>    <span class="number">2</span></span><br><span class="line"><span class="number">4</span>    <span class="number">6</span></span><br><span class="line"><span class="number">5</span>    <span class="number">4</span></span><br><span class="line"><span class="number">6</span>    <span class="number">4</span></span><br><span class="line"><span class="number">7</span>    <span class="number">6</span></span><br><span class="line"><span class="number">8</span>    <span class="number">4</span></span><br><span class="line"><span class="number">9</span>    <span class="number">4</span></span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line">In [<span class="number">70</span>]: s.value_counts()</span><br><span class="line">Out[<span class="number">70</span>]: </span><br><span class="line"><span class="number">4</span>    <span class="number">5</span></span><br><span class="line"><span class="number">6</span>    <span class="number">2</span></span><br><span class="line"><span class="number">2</span>    <span class="number">2</span></span><br><span class="line"><span class="number">1</span>    <span class="number">1</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></div><h2 id="字符串方法"><a href="#字符串方法" class="headerlink" title="字符串方法"></a>字符串方法</h2><p><code>Series</code>对象在其<code>str</code>属性中配备了一组字符串处理方法，可以很容易的应用到数组中的每个元素，如下段代码所示。更多详情请参考：<a href="http://pandas.pydata.org/pandas-docs/stable/text.html#text-string-methods" target="_blank" rel="noopener external nofollow noreferrer">字符串向量化方法</a>。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">71</span>]: s = pd.Series([<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>, <span class="string">'Aaba'</span>, <span class="string">'Baca'</span>, np.nan, <span class="string">'CABA'</span>, <span class="string">'dog'</span>, <span class="string">'cat'</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">72</span>]: s.str.lower()</span><br><span class="line">Out[<span class="number">72</span>]: </span><br><span class="line"><span class="number">0</span>       a</span><br><span class="line"><span class="number">1</span>       b</span><br><span class="line"><span class="number">2</span>       c</span><br><span class="line"><span class="number">3</span>    aaba</span><br><span class="line"><span class="number">4</span>    baca</span><br><span class="line"><span class="number">5</span>     NaN</span><br><span class="line"><span class="number">6</span>    caba</span><br><span class="line"><span class="number">7</span>     dog</span><br><span class="line"><span class="number">8</span>     cat</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure></div><h1 id="六、-合并"><a href="#六、-合并" class="headerlink" title="六、 合并"></a>六、 合并</h1><p>Pandas 提供了大量的方法能够轻松的对<code>Series</code>，<code>DataFrame</code>和<code>Panel</code>对象进行各种符合各种逻辑关系的合并操作。具体请参阅：<a href="http://pandas.pydata.org/pandas-docs/stable/merging.html#merging" target="_blank" rel="noopener external nofollow noreferrer">合并</a>。</p><h2 id="Concat"><a href="#Concat" class="headerlink" title="Concat"></a><code>Concat</code></h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">73</span>]: df = pd.DataFrame(np.random.randn(<span class="number">10</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">74</span>]: df</span><br><span class="line">Out[<span class="number">74</span>]: </span><br><span class="line">          <span class="number">0</span>         <span class="number">1</span>         <span class="number">2</span>         <span class="number">3</span></span><br><span class="line"><span class="number">0</span> <span class="number">-0.548702</span>  <span class="number">1.467327</span> <span class="number">-1.015962</span> <span class="number">-0.483075</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1.637550</span> <span class="number">-1.217659</span> <span class="number">-0.291519</span> <span class="number">-1.745505</span></span><br><span class="line"><span class="number">2</span> <span class="number">-0.263952</span>  <span class="number">0.991460</span> <span class="number">-0.919069</span>  <span class="number">0.266046</span></span><br><span class="line"><span class="number">3</span> <span class="number">-0.709661</span>  <span class="number">1.669052</span>  <span class="number">1.037882</span> <span class="number">-1.705775</span></span><br><span class="line"><span class="number">4</span> <span class="number">-0.919854</span> <span class="number">-0.042379</span>  <span class="number">1.247642</span> <span class="number">-0.009920</span></span><br><span class="line"><span class="number">5</span>  <span class="number">0.290213</span>  <span class="number">0.495767</span>  <span class="number">0.362949</span>  <span class="number">1.548106</span></span><br><span class="line"><span class="number">6</span> <span class="number">-1.131345</span> <span class="number">-0.089329</span>  <span class="number">0.337863</span> <span class="number">-0.945867</span></span><br><span class="line"><span class="number">7</span> <span class="number">-0.932132</span>  <span class="number">1.956030</span>  <span class="number">0.017587</span> <span class="number">-0.016692</span></span><br><span class="line"><span class="number">8</span> <span class="number">-0.575247</span>  <span class="number">0.254161</span> <span class="number">-1.143704</span>  <span class="number">0.215897</span></span><br><span class="line"><span class="number">9</span>  <span class="number">1.193555</span> <span class="number">-0.077118</span> <span class="number">-0.408530</span> <span class="number">-0.862495</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># break it into pieces</span></span><br><span class="line">In [<span class="number">75</span>]: pieces = [df[:<span class="number">3</span>], df[<span class="number">3</span>:<span class="number">7</span>], df[<span class="number">7</span>:]]</span><br><span class="line"></span><br><span class="line">In [<span class="number">76</span>]: pd.concat(pieces)</span><br><span class="line">Out[<span class="number">76</span>]: </span><br><span class="line">          <span class="number">0</span>         <span class="number">1</span>         <span class="number">2</span>         <span class="number">3</span></span><br><span class="line"><span class="number">0</span> <span class="number">-0.548702</span>  <span class="number">1.467327</span> <span class="number">-1.015962</span> <span class="number">-0.483075</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1.637550</span> <span class="number">-1.217659</span> <span class="number">-0.291519</span> <span class="number">-1.745505</span></span><br><span class="line"><span class="number">2</span> <span class="number">-0.263952</span>  <span class="number">0.991460</span> <span class="number">-0.919069</span>  <span class="number">0.266046</span></span><br><span class="line"><span class="number">3</span> <span class="number">-0.709661</span>  <span class="number">1.669052</span>  <span class="number">1.037882</span> <span class="number">-1.705775</span></span><br><span class="line"><span class="number">4</span> <span class="number">-0.919854</span> <span class="number">-0.042379</span>  <span class="number">1.247642</span> <span class="number">-0.009920</span></span><br><span class="line"><span class="number">5</span>  <span class="number">0.290213</span>  <span class="number">0.495767</span>  <span class="number">0.362949</span>  <span class="number">1.548106</span></span><br><span class="line"><span class="number">6</span> <span class="number">-1.131345</span> <span class="number">-0.089329</span>  <span class="number">0.337863</span> <span class="number">-0.945867</span></span><br><span class="line"><span class="number">7</span> <span class="number">-0.932132</span>  <span class="number">1.956030</span>  <span class="number">0.017587</span> <span class="number">-0.016692</span></span><br><span class="line"><span class="number">8</span> <span class="number">-0.575247</span>  <span class="number">0.254161</span> <span class="number">-1.143704</span>  <span class="number">0.215897</span></span><br><span class="line"><span class="number">9</span>  <span class="number">1.193555</span> <span class="number">-0.077118</span> <span class="number">-0.408530</span> <span class="number">-0.862495</span></span><br></pre></td></tr></table></figure></div><h2 id="Join"><a href="#Join" class="headerlink" title="Join"></a><code>Join</code></h2><p>类似于 SQL 类型的合并，具体请参阅：<a href="http://pandas.pydata.org/pandas-docs/stable/merging.html#merging-join" target="_blank" rel="noopener external nofollow noreferrer">数据库风格的连接</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">77</span>]: left = pd.DataFrame(&#123;<span class="string">'key'</span>: [<span class="string">'foo'</span>, <span class="string">'foo'</span>], <span class="string">'lval'</span>: [<span class="number">1</span>, <span class="number">2</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">78</span>]: right = pd.DataFrame(&#123;<span class="string">'key'</span>: [<span class="string">'foo'</span>, <span class="string">'foo'</span>], <span class="string">'rval'</span>: [<span class="number">4</span>, <span class="number">5</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">79</span>]: left</span><br><span class="line">Out[<span class="number">79</span>]: </span><br><span class="line">   key  lval</span><br><span class="line"><span class="number">0</span>  foo     <span class="number">1</span></span><br><span class="line"><span class="number">1</span>  foo     <span class="number">2</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">80</span>]: right</span><br><span class="line">Out[<span class="number">80</span>]: </span><br><span class="line">   key  rval</span><br><span class="line"><span class="number">0</span>  foo     <span class="number">4</span></span><br><span class="line"><span class="number">1</span>  foo     <span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">81</span>]: pd.merge(left, right, on=<span class="string">'key'</span>)</span><br><span class="line">Out[<span class="number">81</span>]: </span><br><span class="line">   key  lval  rval</span><br><span class="line"><span class="number">0</span>  foo     <span class="number">1</span>     <span class="number">4</span></span><br><span class="line"><span class="number">1</span>  foo     <span class="number">1</span>     <span class="number">5</span></span><br><span class="line"><span class="number">2</span>  foo     <span class="number">2</span>     <span class="number">4</span></span><br><span class="line"><span class="number">3</span>  foo     <span class="number">2</span>     <span class="number">5</span></span><br></pre></td></tr></table></figure></div><p>另一个例子：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">82</span>]: left = pd.DataFrame(&#123;<span class="string">'key'</span>: [<span class="string">'foo'</span>, <span class="string">'bar'</span>], <span class="string">'lval'</span>: [<span class="number">1</span>, <span class="number">2</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">83</span>]: right = pd.DataFrame(&#123;<span class="string">'key'</span>: [<span class="string">'foo'</span>, <span class="string">'bar'</span>], <span class="string">'rval'</span>: [<span class="number">4</span>, <span class="number">5</span>]&#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">84</span>]: left</span><br><span class="line">Out[<span class="number">84</span>]: </span><br><span class="line">   key  lval</span><br><span class="line"><span class="number">0</span>  foo     <span class="number">1</span></span><br><span class="line"><span class="number">1</span>  bar     <span class="number">2</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">85</span>]: right</span><br><span class="line">Out[<span class="number">85</span>]: </span><br><span class="line">   key  rval</span><br><span class="line"><span class="number">0</span>  foo     <span class="number">4</span></span><br><span class="line"><span class="number">1</span>  bar     <span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">86</span>]: pd.merge(left, right, on=<span class="string">'key'</span>)</span><br><span class="line">Out[<span class="number">86</span>]: </span><br><span class="line">   key  lval  rval</span><br><span class="line"><span class="number">0</span>  foo     <span class="number">1</span>     <span class="number">4</span></span><br><span class="line"><span class="number">1</span>  bar     <span class="number">2</span>     <span class="number">5</span></span><br></pre></td></tr></table></figure></div><h2 id="Append"><a href="#Append" class="headerlink" title="Append"></a><code>Append</code></h2><p>将一行连接到一个<code>DataFrame</code>上，具体请参阅<a href="http://pandas.pydata.org/pandas-docs/stable/merging.html#merging-concatenation" target="_blank" rel="noopener external nofollow noreferrer">附加</a>：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">87</span>]: df = pd.DataFrame(np.random.randn(<span class="number">8</span>, <span class="number">4</span>), columns=[<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>,<span class="string">'D'</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">88</span>]: df</span><br><span class="line">Out[<span class="number">88</span>]: </span><br><span class="line">          A         B         C         D</span><br><span class="line"><span class="number">0</span>  <span class="number">1.346061</span>  <span class="number">1.511763</span>  <span class="number">1.627081</span> <span class="number">-0.990582</span></span><br><span class="line"><span class="number">1</span> <span class="number">-0.441652</span>  <span class="number">1.211526</span>  <span class="number">0.268520</span>  <span class="number">0.024580</span></span><br><span class="line"><span class="number">2</span> <span class="number">-1.577585</span>  <span class="number">0.396823</span> <span class="number">-0.105381</span> <span class="number">-0.532532</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1.453749</span>  <span class="number">1.208843</span> <span class="number">-0.080952</span> <span class="number">-0.264610</span></span><br><span class="line"><span class="number">4</span> <span class="number">-0.727965</span> <span class="number">-0.589346</span>  <span class="number">0.339969</span> <span class="number">-0.693205</span></span><br><span class="line"><span class="number">5</span> <span class="number">-0.339355</span>  <span class="number">0.593616</span>  <span class="number">0.884345</span>  <span class="number">1.591431</span></span><br><span class="line"><span class="number">6</span>  <span class="number">0.141809</span>  <span class="number">0.220390</span>  <span class="number">0.435589</span>  <span class="number">0.192451</span></span><br><span class="line"><span class="number">7</span> <span class="number">-0.096701</span>  <span class="number">0.803351</span>  <span class="number">1.715071</span> <span class="number">-0.708758</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">89</span>]: s = df.iloc[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">90</span>]: df.append(s, ignore_index=<span class="literal">True</span>)</span><br><span class="line">Out[<span class="number">90</span>]: </span><br><span class="line">          A         B         C         D</span><br><span class="line"><span class="number">0</span>  <span class="number">1.346061</span>  <span class="number">1.511763</span>  <span class="number">1.627081</span> <span class="number">-0.990582</span></span><br><span class="line"><span class="number">1</span> <span class="number">-0.441652</span>  <span class="number">1.211526</span>  <span class="number">0.268520</span>  <span class="number">0.024580</span></span><br><span class="line"><span class="number">2</span> <span class="number">-1.577585</span>  <span class="number">0.396823</span> <span class="number">-0.105381</span> <span class="number">-0.532532</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1.453749</span>  <span class="number">1.208843</span> <span class="number">-0.080952</span> <span class="number">-0.264610</span></span><br><span class="line"><span class="number">4</span> <span class="number">-0.727965</span> <span class="number">-0.589346</span>  <span class="number">0.339969</span> <span class="number">-0.693205</span></span><br><span class="line"><span class="number">5</span> <span class="number">-0.339355</span>  <span class="number">0.593616</span>  <span class="number">0.884345</span>  <span class="number">1.591431</span></span><br><span class="line"><span class="number">6</span>  <span class="number">0.141809</span>  <span class="number">0.220390</span>  <span class="number">0.435589</span>  <span class="number">0.192451</span></span><br><span class="line"><span class="number">7</span> <span class="number">-0.096701</span>  <span class="number">0.803351</span>  <span class="number">1.715071</span> <span class="number">-0.708758</span></span><br><span class="line"><span class="number">8</span>  <span class="number">1.453749</span>  <span class="number">1.208843</span> <span class="number">-0.080952</span> <span class="number">-0.264610</span></span><br></pre></td></tr></table></figure></div><h1 id="七、-分组"><a href="#七、-分组" class="headerlink" title="七、 分组"></a>七、 分组</h1><p>对于”group by”操作，我们通常是指以下一个或多个操作步骤：</p><ul><li><p>（Splitting）按照一些规则将数据分为不同的组；</p></li><li><p>（Applying）对于每组数据分别执行一个函数；</p></li><li><p>（Combining）将结果组合到一个数据结构中；</p></li></ul><p>详情请参阅：<a href="http://pandas.pydata.org/pandas-docs/stable/groupby.html#groupby" target="_blank" rel="noopener external nofollow noreferrer">_Grouping section_</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">91</span>]: df = pd.DataFrame(&#123;<span class="string">'A'</span> : [<span class="string">'foo'</span>, <span class="string">'bar'</span>, <span class="string">'foo'</span>, <span class="string">'bar'</span>,</span><br><span class="line">   ....:                           <span class="string">'foo'</span>, <span class="string">'bar'</span>, <span class="string">'foo'</span>, <span class="string">'foo'</span>],</span><br><span class="line">   ....:                    <span class="string">'B'</span> : [<span class="string">'one'</span>, <span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'three'</span>,</span><br><span class="line">   ....:                           <span class="string">'two'</span>, <span class="string">'two'</span>, <span class="string">'one'</span>, <span class="string">'three'</span>],</span><br><span class="line">   ....:                    <span class="string">'C'</span> : np.random.randn(<span class="number">8</span>),</span><br><span class="line">   ....:                    <span class="string">'D'</span> : np.random.randn(<span class="number">8</span>)&#125;)</span><br><span class="line">   ....: </span><br><span class="line"></span><br><span class="line">In [<span class="number">92</span>]: df</span><br><span class="line">Out[<span class="number">92</span>]: </span><br><span class="line">     A      B         C         D</span><br><span class="line"><span class="number">0</span>  foo    one <span class="number">-1.202872</span> <span class="number">-0.055224</span></span><br><span class="line"><span class="number">1</span>  bar    one <span class="number">-1.814470</span>  <span class="number">2.395985</span></span><br><span class="line"><span class="number">2</span>  foo    two  <span class="number">1.018601</span>  <span class="number">1.552825</span></span><br><span class="line"><span class="number">3</span>  bar  three <span class="number">-0.595447</span>  <span class="number">0.166599</span></span><br><span class="line"><span class="number">4</span>  foo    two  <span class="number">1.395433</span>  <span class="number">0.047609</span></span><br><span class="line"><span class="number">5</span>  bar    two <span class="number">-0.392670</span> <span class="number">-0.136473</span></span><br><span class="line"><span class="number">6</span>  foo    one  <span class="number">0.007207</span> <span class="number">-0.561757</span></span><br><span class="line"><span class="number">7</span>  foo  three  <span class="number">1.928123</span> <span class="number">-1.623033</span></span><br></pre></td></tr></table></figure></div><p>1、 分组并对每个分组执行<code>sum</code>函数：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">93</span>]: df.groupby(<span class="string">'A'</span>).sum()</span><br><span class="line">Out[<span class="number">93</span>]: </span><br><span class="line">            C        D</span><br><span class="line">A                     </span><br><span class="line">bar <span class="number">-2.802588</span>  <span class="number">2.42611</span></span><br><span class="line">foo  <span class="number">3.146492</span> <span class="number">-0.63958</span></span><br></pre></td></tr></table></figure></div><p>2、 通过多个列进行分组形成一个层次索引，然后执行函数：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">94</span>]: df.groupby([<span class="string">'A'</span>,<span class="string">'B'</span>]).sum()</span><br><span class="line">Out[<span class="number">94</span>]: </span><br><span class="line">                  C         D</span><br><span class="line">A   B                        </span><br><span class="line">bar one   <span class="number">-1.814470</span>  <span class="number">2.395985</span></span><br><span class="line">    three <span class="number">-0.595447</span>  <span class="number">0.166599</span></span><br><span class="line">    two   <span class="number">-0.392670</span> <span class="number">-0.136473</span></span><br><span class="line">foo one   <span class="number">-1.195665</span> <span class="number">-0.616981</span></span><br><span class="line">    three  <span class="number">1.928123</span> <span class="number">-1.623033</span></span><br><span class="line">    two    <span class="number">2.414034</span>  <span class="number">1.600434</span></span><br></pre></td></tr></table></figure></div><h1 id="八、-改变形状"><a href="#八、-改变形状" class="headerlink" title="八、 改变形状"></a>八、 改变形状</h1><p>详情请参阅 <a href="http://pandas.pydata.org/pandas-docs/stable/advanced.html#advanced-hierarchical" target="_blank" rel="noopener external nofollow noreferrer">层次索引</a> 和 <a href="http://pandas.pydata.org/pandas-docs/stable/reshaping.html#reshaping-stacking" target="_blank" rel="noopener external nofollow noreferrer">改变形状</a>。</p><h2 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a><code>Stack</code></h2><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">95</span>]: tuples = list(zip(*[[<span class="string">'bar'</span>, <span class="string">'bar'</span>, <span class="string">'baz'</span>, <span class="string">'baz'</span>,</span><br><span class="line">   ....:                      <span class="string">'foo'</span>, <span class="string">'foo'</span>, <span class="string">'qux'</span>, <span class="string">'qux'</span>],</span><br><span class="line">   ....:                     [<span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'one'</span>, <span class="string">'two'</span>,</span><br><span class="line">   ....:                      <span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'one'</span>, <span class="string">'two'</span>]]))</span><br><span class="line">   ....: </span><br><span class="line"></span><br><span class="line">In [<span class="number">96</span>]: index = pd.MultiIndex.from_tuples(tuples, names=[<span class="string">'first'</span>, <span class="string">'second'</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">97</span>]: df = pd.DataFrame(np.random.randn(<span class="number">8</span>, <span class="number">2</span>), index=index, columns=[<span class="string">'A'</span>, <span class="string">'B'</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">98</span>]: df2 = df[:<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">99</span>]: df2</span><br><span class="line">Out[<span class="number">99</span>]: </span><br><span class="line">                     A         B</span><br><span class="line">first second                    </span><br><span class="line">bar   one     <span class="number">0.029399</span> <span class="number">-0.542108</span></span><br><span class="line">      two     <span class="number">0.282696</span> <span class="number">-0.087302</span></span><br><span class="line">baz   one    <span class="number">-1.575170</span>  <span class="number">1.771208</span></span><br><span class="line">      two     <span class="number">0.816482</span>  <span class="number">1.100230</span></span><br></pre></td></tr></table></figure></div><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">100</span>]: stacked = df2.stack()</span><br><span class="line"></span><br><span class="line">In [<span class="number">101</span>]: stacked</span><br><span class="line">Out[<span class="number">101</span>]: </span><br><span class="line">first  second   </span><br><span class="line">bar    one     A    <span class="number">0.029399</span></span><br><span class="line">               B   <span class="number">-0.542108</span></span><br><span class="line">       two     A    <span class="number">0.282696</span></span><br><span class="line">               B   <span class="number">-0.087302</span></span><br><span class="line">baz    one     A   <span class="number">-1.575170</span></span><br><span class="line">               B    <span class="number">1.771208</span></span><br><span class="line">       two     A    <span class="number">0.816482</span></span><br><span class="line">               B    <span class="number">1.100230</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></div><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">102</span>]: stacked.unstack()</span><br><span class="line">Out[<span class="number">102</span>]: </span><br><span class="line">                     A         B</span><br><span class="line">first second                    </span><br><span class="line">bar   one     <span class="number">0.029399</span> <span class="number">-0.542108</span></span><br><span class="line">      two     <span class="number">0.282696</span> <span class="number">-0.087302</span></span><br><span class="line">baz   one    <span class="number">-1.575170</span>  <span class="number">1.771208</span></span><br><span class="line">      two     <span class="number">0.816482</span>  <span class="number">1.100230</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">103</span>]: stacked.unstack(<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">103</span>]: </span><br><span class="line">second        one       two</span><br><span class="line">first                      </span><br><span class="line">bar   A  <span class="number">0.029399</span>  <span class="number">0.282696</span></span><br><span class="line">      B <span class="number">-0.542108</span> <span class="number">-0.087302</span></span><br><span class="line">baz   A <span class="number">-1.575170</span>  <span class="number">0.816482</span></span><br><span class="line">      B  <span class="number">1.771208</span>  <span class="number">1.100230</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">104</span>]: stacked.unstack(<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">104</span>]: </span><br><span class="line">first          bar       baz</span><br><span class="line">second                      </span><br><span class="line">one    A  <span class="number">0.029399</span> <span class="number">-1.575170</span></span><br><span class="line">       B <span class="number">-0.542108</span>  <span class="number">1.771208</span></span><br><span class="line">two    A  <span class="number">0.282696</span>  <span class="number">0.816482</span></span><br><span class="line">       B <span class="number">-0.087302</span>  <span class="number">1.100230</span></span><br></pre></td></tr></table></figure></div><h2 id="数据透视表"><a href="#数据透视表" class="headerlink" title="数据透视表"></a>数据透视表</h2><p>详情请参阅：<a href="http://pandas.pydata.org/pandas-docs/stable/reshaping.html#reshaping-pivot" target="_blank" rel="noopener external nofollow noreferrer">数据透视表</a>.</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">105</span>]: df = pd.DataFrame(&#123;<span class="string">'A'</span> : [<span class="string">'one'</span>, <span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'three'</span>] * <span class="number">3</span>,</span><br><span class="line">   .....:                    <span class="string">'B'</span> : [<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>] * <span class="number">4</span>,</span><br><span class="line">   .....:                    <span class="string">'C'</span> : [<span class="string">'foo'</span>, <span class="string">'foo'</span>, <span class="string">'foo'</span>, <span class="string">'bar'</span>, <span class="string">'bar'</span>, <span class="string">'bar'</span>] * <span class="number">2</span>,</span><br><span class="line">   .....:                    <span class="string">'D'</span> : np.random.randn(<span class="number">12</span>),</span><br><span class="line">   .....:                    <span class="string">'E'</span> : np.random.randn(<span class="number">12</span>)&#125;)</span><br><span class="line">   .....: </span><br><span class="line"></span><br><span class="line">In [<span class="number">106</span>]: df</span><br><span class="line">Out[<span class="number">106</span>]: </span><br><span class="line">        A  B    C         D         E</span><br><span class="line"><span class="number">0</span>     one  A  foo  <span class="number">1.418757</span> <span class="number">-0.179666</span></span><br><span class="line"><span class="number">1</span>     one  B  foo <span class="number">-1.879024</span>  <span class="number">1.291836</span></span><br><span class="line"><span class="number">2</span>     two  C  foo  <span class="number">0.536826</span> <span class="number">-0.009614</span></span><br><span class="line"><span class="number">3</span>   three  A  bar  <span class="number">1.006160</span>  <span class="number">0.392149</span></span><br><span class="line"><span class="number">4</span>     one  B  bar <span class="number">-0.029716</span>  <span class="number">0.264599</span></span><br><span class="line"><span class="number">5</span>     one  C  bar <span class="number">-1.146178</span> <span class="number">-0.057409</span></span><br><span class="line"><span class="number">6</span>     two  A  foo  <span class="number">0.100900</span> <span class="number">-1.425638</span></span><br><span class="line"><span class="number">7</span>   three  B  foo <span class="number">-1.035018</span>  <span class="number">1.024098</span></span><br><span class="line"><span class="number">8</span>     one  C  foo  <span class="number">0.314665</span> <span class="number">-0.106062</span></span><br><span class="line"><span class="number">9</span>     one  A  bar <span class="number">-0.773723</span>  <span class="number">1.824375</span></span><br><span class="line"><span class="number">10</span>    two  B  bar <span class="number">-1.170653</span>  <span class="number">0.595974</span></span><br><span class="line"><span class="number">11</span>  three  C  bar  <span class="number">0.648740</span>  <span class="number">1.167115</span></span><br></pre></td></tr></table></figure></div><p>可以从这个数据中轻松的生成数据透视表：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">107</span>]: pd.pivot_table(df, values=<span class="string">'D'</span>, index=[<span class="string">'A'</span>, <span class="string">'B'</span>], columns=[<span class="string">'C'</span>])</span><br><span class="line">Out[<span class="number">107</span>]: </span><br><span class="line">C             bar       foo</span><br><span class="line">A     B                    </span><br><span class="line">one   A <span class="number">-0.773723</span>  <span class="number">1.418757</span></span><br><span class="line">      B <span class="number">-0.029716</span> <span class="number">-1.879024</span></span><br><span class="line">      C <span class="number">-1.146178</span>  <span class="number">0.314665</span></span><br><span class="line">three A  <span class="number">1.006160</span>       NaN</span><br><span class="line">      B       NaN <span class="number">-1.035018</span></span><br><span class="line">      C  <span class="number">0.648740</span>       NaN</span><br><span class="line">two   A       NaN  <span class="number">0.100900</span></span><br><span class="line">      B <span class="number">-1.170653</span>       NaN</span><br><span class="line">      C       NaN  <span class="number">0.536826</span></span><br></pre></td></tr></table></figure></div><h1 id="九、-时间序列"><a href="#九、-时间序列" class="headerlink" title="九、 时间序列"></a>九、 时间序列</h1><p>Pandas 在对频率转换进行重新采样时拥有简单、强大且高效的功能（如将按秒采样的数据转换为按5分钟为单位进行采样的数据）。这种操作在金融领域非常常见。具体参考：<a href="http://pandas.pydata.org/pandas-docs/stable/timeseries.html#timeseries" target="_blank" rel="noopener external nofollow noreferrer">时间序列</a>。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">108</span>]: rng = pd.date_range(<span class="string">'1/1/2012'</span>, periods=<span class="number">100</span>, freq=<span class="string">'S'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">109</span>]: ts = pd.Series(np.random.randint(<span class="number">0</span>, <span class="number">500</span>, len(rng)), index=rng)</span><br><span class="line"></span><br><span class="line">In [<span class="number">110</span>]: ts.resample(<span class="string">'5Min'</span>).sum()</span><br><span class="line">Out[<span class="number">110</span>]: </span><br><span class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-01</span>    <span class="number">25083</span></span><br><span class="line">Freq: <span class="number">5</span>T, dtype: int64</span><br></pre></td></tr></table></figure></div><p>1、 时区表示：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">111</span>]: rng = pd.date_range(<span class="string">'3/6/2012 00:00'</span>, periods=<span class="number">5</span>, freq=<span class="string">'D'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">112</span>]: ts = pd.Series(np.random.randn(len(rng)), rng)</span><br><span class="line"></span><br><span class="line">In [<span class="number">113</span>]: ts</span><br><span class="line">Out[<span class="number">113</span>]: </span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-06</span>    <span class="number">0.464000</span></span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-07</span>    <span class="number">0.227371</span></span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-08</span>   <span class="number">-0.496922</span></span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-09</span>    <span class="number">0.306389</span></span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-10</span>   <span class="number">-2.290613</span></span><br><span class="line">Freq: D, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">114</span>]: ts_utc = ts.tz_localize(<span class="string">'UTC'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">115</span>]: ts_utc</span><br><span class="line">Out[<span class="number">115</span>]: </span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-06</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>    <span class="number">0.464000</span></span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-07</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>    <span class="number">0.227371</span></span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-08</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>   <span class="number">-0.496922</span></span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-09</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>    <span class="number">0.306389</span></span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-10</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>+<span class="number">00</span>:<span class="number">00</span>   <span class="number">-2.290613</span></span><br><span class="line">Freq: D, dtype: float64</span><br></pre></td></tr></table></figure></div><p>2、 时区转换：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">116</span>]: ts_utc.tz_convert(<span class="string">'US/Eastern'</span>)</span><br><span class="line">Out[<span class="number">116</span>]: </span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-05</span> <span class="number">19</span>:<span class="number">00</span>:<span class="number">00</span><span class="number">-05</span>:<span class="number">00</span>    <span class="number">0.464000</span></span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-06</span> <span class="number">19</span>:<span class="number">00</span>:<span class="number">00</span><span class="number">-05</span>:<span class="number">00</span>    <span class="number">0.227371</span></span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-07</span> <span class="number">19</span>:<span class="number">00</span>:<span class="number">00</span><span class="number">-05</span>:<span class="number">00</span>   <span class="number">-0.496922</span></span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-08</span> <span class="number">19</span>:<span class="number">00</span>:<span class="number">00</span><span class="number">-05</span>:<span class="number">00</span>    <span class="number">0.306389</span></span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-09</span> <span class="number">19</span>:<span class="number">00</span>:<span class="number">00</span><span class="number">-05</span>:<span class="number">00</span>   <span class="number">-2.290613</span></span><br><span class="line">Freq: D, dtype: float64</span><br></pre></td></tr></table></figure></div><p>3、 时间跨度转换：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">117</span>]: rng = pd.date_range(<span class="string">'1/1/2012'</span>, periods=<span class="number">5</span>, freq=<span class="string">'M'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">118</span>]: ts = pd.Series(np.random.randn(len(rng)), index=rng)</span><br><span class="line"></span><br><span class="line">In [<span class="number">119</span>]: ts</span><br><span class="line">Out[<span class="number">119</span>]: </span><br><span class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-31</span>   <span class="number">-1.134623</span></span><br><span class="line"><span class="number">2012</span><span class="number">-02</span><span class="number">-29</span>   <span class="number">-1.561819</span></span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-31</span>   <span class="number">-0.260838</span></span><br><span class="line"><span class="number">2012</span><span class="number">-04</span><span class="number">-30</span>    <span class="number">0.281957</span></span><br><span class="line"><span class="number">2012</span><span class="number">-05</span><span class="number">-31</span>    <span class="number">1.523962</span></span><br><span class="line">Freq: M, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">120</span>]: ps = ts.to_period()</span><br><span class="line"></span><br><span class="line">In [<span class="number">121</span>]: ps</span><br><span class="line">Out[<span class="number">121</span>]: </span><br><span class="line"><span class="number">2012</span><span class="number">-01</span>   <span class="number">-1.134623</span></span><br><span class="line"><span class="number">2012</span><span class="number">-02</span>   <span class="number">-1.561819</span></span><br><span class="line"><span class="number">2012</span><span class="number">-03</span>   <span class="number">-0.260838</span></span><br><span class="line"><span class="number">2012</span><span class="number">-04</span>    <span class="number">0.281957</span></span><br><span class="line"><span class="number">2012</span><span class="number">-05</span>    <span class="number">1.523962</span></span><br><span class="line">Freq: M, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">122</span>]: ps.to_timestamp()</span><br><span class="line">Out[<span class="number">122</span>]: </span><br><span class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-01</span>   <span class="number">-1.134623</span></span><br><span class="line"><span class="number">2012</span><span class="number">-02</span><span class="number">-01</span>   <span class="number">-1.561819</span></span><br><span class="line"><span class="number">2012</span><span class="number">-03</span><span class="number">-01</span>   <span class="number">-0.260838</span></span><br><span class="line"><span class="number">2012</span><span class="number">-04</span><span class="number">-01</span>    <span class="number">0.281957</span></span><br><span class="line"><span class="number">2012</span><span class="number">-05</span><span class="number">-01</span>    <span class="number">1.523962</span></span><br><span class="line">Freq: MS, dtype: float64</span><br></pre></td></tr></table></figure></div><p>4、 时期和时间戳之间的转换使得可以使用一些方便的算术函数。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">123</span>]: prng = pd.period_range(<span class="string">'1990Q1'</span>, <span class="string">'2000Q4'</span>, freq=<span class="string">'Q-NOV'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">124</span>]: ts = pd.Series(np.random.randn(len(prng)), prng)</span><br><span class="line"></span><br><span class="line">In [<span class="number">125</span>]: ts.index = (prng.asfreq(<span class="string">'M'</span>, <span class="string">'e'</span>) + <span class="number">1</span>).asfreq(<span class="string">'H'</span>, <span class="string">'s'</span>) + <span class="number">9</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">126</span>]: ts.head()</span><br><span class="line">Out[<span class="number">126</span>]: </span><br><span class="line"><span class="number">1990</span><span class="number">-03</span><span class="number">-01</span> <span class="number">09</span>:<span class="number">00</span>   <span class="number">-0.902937</span></span><br><span class="line"><span class="number">1990</span><span class="number">-06</span><span class="number">-01</span> <span class="number">09</span>:<span class="number">00</span>    <span class="number">0.068159</span></span><br><span class="line"><span class="number">1990</span><span class="number">-09</span><span class="number">-01</span> <span class="number">09</span>:<span class="number">00</span>   <span class="number">-0.057873</span></span><br><span class="line"><span class="number">1990</span><span class="number">-12</span><span class="number">-01</span> <span class="number">09</span>:<span class="number">00</span>   <span class="number">-0.368204</span></span><br><span class="line"><span class="number">1991</span><span class="number">-03</span><span class="number">-01</span> <span class="number">09</span>:<span class="number">00</span>   <span class="number">-1.144073</span></span><br><span class="line">Freq: H, dtype: float64</span><br></pre></td></tr></table></figure></div><h1 id="十、-Categorical"><a href="#十、-Categorical" class="headerlink" title="十、 Categorical"></a>十、 Categorical</h1><p>从 0.15 版本开始，pandas 可以在<code>DataFrame</code>中支持 Categorical 类型的数据，详细 介绍参看：<a href="http://pandas.pydata.org/pandas-docs/stable/categorical.html#categorical" target="_blank" rel="noopener external nofollow noreferrer">Categorical 简介</a>和<a href="http://pandas.pydata.org/pandas-docs/stable/api.html#api-categorical" target="_blank" rel="noopener external nofollow noreferrer">_API documentation_</a>。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">127</span>]: df = pd.DataFrame(&#123;<span class="string">"id"</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], <span class="string">"raw_grade"</span>:[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'b'</span>, <span class="string">'a'</span>, <span class="string">'a'</span>, <span class="string">'e'</span>]&#125;)</span><br></pre></td></tr></table></figure></div><p>1、 将原始的<code>grade</code>转换为 Categorical 数据类型：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">128</span>]: df[<span class="string">"grade"</span>] = df[<span class="string">"raw_grade"</span>].astype(<span class="string">"category"</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">129</span>]: df[<span class="string">"grade"</span>]</span><br><span class="line">Out[<span class="number">129</span>]: </span><br><span class="line"><span class="number">0</span>    a</span><br><span class="line"><span class="number">1</span>    b</span><br><span class="line"><span class="number">2</span>    b</span><br><span class="line"><span class="number">3</span>    a</span><br><span class="line"><span class="number">4</span>    a</span><br><span class="line"><span class="number">5</span>    e</span><br><span class="line">Name: grade, dtype: category</span><br><span class="line">Categories (<span class="number">3</span>, object): [a, b, e]</span><br></pre></td></tr></table></figure></div><p>2、 将 Categorical 类型数据重命名为更有意义的名称：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">130</span>]: df[<span class="string">"grade"</span>].cat.categories = [<span class="string">"very good"</span>, <span class="string">"good"</span>, <span class="string">"very bad"</span>]</span><br></pre></td></tr></table></figure></div><p>3、 对类别进行重新排序，增加缺失的类别：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">131</span>]: df[<span class="string">"grade"</span>] = df[<span class="string">"grade"</span>].cat.set_categories([<span class="string">"very bad"</span>, <span class="string">"bad"</span>, <span class="string">"medium"</span>, <span class="string">"good"</span>, <span class="string">"very good"</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">132</span>]: df[<span class="string">"grade"</span>]</span><br><span class="line">Out[<span class="number">132</span>]: </span><br><span class="line"><span class="number">0</span>    very good</span><br><span class="line"><span class="number">1</span>         good</span><br><span class="line"><span class="number">2</span>         good</span><br><span class="line"><span class="number">3</span>    very good</span><br><span class="line"><span class="number">4</span>    very good</span><br><span class="line"><span class="number">5</span>     very bad</span><br><span class="line">Name: grade, dtype: category</span><br><span class="line">Categories (<span class="number">5</span>, object): [very bad, bad, medium, good, very good]</span><br></pre></td></tr></table></figure></div><p>4、 排序是按照 Categorical 的顺序进行的而不是按照字典顺序进行：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">133</span>]: df.sort_values(by=<span class="string">"grade"</span>)</span><br><span class="line">Out[<span class="number">133</span>]: </span><br><span class="line">   id raw_grade      grade</span><br><span class="line"><span class="number">5</span>   <span class="number">6</span>         e   very bad</span><br><span class="line"><span class="number">1</span>   <span class="number">2</span>         b       good</span><br><span class="line"><span class="number">2</span>   <span class="number">3</span>         b       good</span><br><span class="line"><span class="number">0</span>   <span class="number">1</span>         a  very good</span><br><span class="line"><span class="number">3</span>   <span class="number">4</span>         a  very good</span><br><span class="line"><span class="number">4</span>   <span class="number">5</span>         a  very good</span><br></pre></td></tr></table></figure></div><p>5、 对 Categorical 列进行排序时存在空的类别：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">134</span>]: df.groupby(<span class="string">"grade"</span>).size()</span><br><span class="line">Out[<span class="number">134</span>]: </span><br><span class="line">grade</span><br><span class="line">very bad     <span class="number">1</span></span><br><span class="line">bad          <span class="number">0</span></span><br><span class="line">medium       <span class="number">0</span></span><br><span class="line">good         <span class="number">2</span></span><br><span class="line">very good    <span class="number">3</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></div><h1 id="十一、-画图"><a href="#十一、-画图" class="headerlink" title="十一、 画图"></a>十一、 画图</h1><p>具体文档参看：<a href="http://pandas.pydata.org/pandas-docs/stable/visualization.html#visualization" target="_blank" rel="noopener external nofollow noreferrer">绘图</a>文档。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">135</span>]: ts = pd.Series(np.random.randn(<span class="number">1000</span>), index=pd.date_range(<span class="string">'1/1/2000'</span>, periods=<span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">136</span>]: ts = ts.cumsum()</span><br><span class="line"></span><br><span class="line">In [<span class="number">137</span>]: ts.plot()</span><br><span class="line">Out[<span class="number">137</span>]: &lt;matplotlib.axes._subplots.AxesSubplot at <span class="number">0x7ff2ab2af550</span>&gt;</span><br></pre></td></tr></table></figure></div><p><img src="http://pandas.pydata.org/pandas-docs/stable/_images/series_plot_basic.png" alt></p><p>对于<code>DataFrame</code>来说，<code>plot</code>是一种将所有列及其标签进行绘制的简便方法：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">138</span>]: df = pd.DataFrame(np.random.randn(<span class="number">1000</span>, <span class="number">4</span>), index=ts.index,</span><br><span class="line">   .....:                   columns=[<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>, <span class="string">'D'</span>])</span><br><span class="line">   .....: </span><br><span class="line"></span><br><span class="line">In [<span class="number">139</span>]: df = df.cumsum()</span><br><span class="line"></span><br><span class="line">In [<span class="number">140</span>]: plt.figure(); df.plot(); plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">Out[<span class="number">140</span>]: &lt;matplotlib.legend.Legend at <span class="number">0x7ff29c8163d0</span>&gt;</span><br></pre></td></tr></table></figure></div><p><img src="http://pandas.pydata.org/pandas-docs/stable/_images/frame_plot_basic.png" alt></p><h1 id="十二、-导入和保存数据"><a href="#十二、-导入和保存数据" class="headerlink" title="十二、 导入和保存数据"></a>十二、 导入和保存数据</h1><h2 id="CSV"><a href="#CSV" class="headerlink" title="CSV"></a>CSV</h2><p>参考：<a href="http://pandas.pydata.org/pandas-docs/stable/io.html#io-store-in-csv" target="_blank" rel="noopener external nofollow noreferrer">写入 CSV 文件</a>。</p><p>1、 写入 csv 文件：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">141</span>]: df.to_csv(<span class="string">'foo.csv'</span>)</span><br></pre></td></tr></table></figure></div><p>2、 从 csv 文件中读取：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">142</span>]: pd.read_csv(<span class="string">'foo.csv'</span>)</span><br><span class="line">Out[<span class="number">142</span>]: </span><br><span class="line">     Unnamed: <span class="number">0</span>          A          B         C          D</span><br><span class="line"><span class="number">0</span>    <span class="number">2000</span><span class="number">-01</span><span class="number">-01</span>   <span class="number">0.266457</span>  <span class="number">-0.399641</span> <span class="number">-0.219582</span>   <span class="number">1.186860</span></span><br><span class="line"><span class="number">1</span>    <span class="number">2000</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">-1.170732</span>  <span class="number">-0.345873</span>  <span class="number">1.653061</span>  <span class="number">-0.282953</span></span><br><span class="line"><span class="number">2</span>    <span class="number">2000</span><span class="number">-01</span><span class="number">-03</span>  <span class="number">-1.734933</span>   <span class="number">0.530468</span>  <span class="number">2.060811</span>  <span class="number">-0.515536</span></span><br><span class="line"><span class="number">3</span>    <span class="number">2000</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">-1.555121</span>   <span class="number">1.452620</span>  <span class="number">0.239859</span>  <span class="number">-1.156896</span></span><br><span class="line"><span class="number">4</span>    <span class="number">2000</span><span class="number">-01</span><span class="number">-05</span>   <span class="number">0.578117</span>   <span class="number">0.511371</span>  <span class="number">0.103552</span>  <span class="number">-2.428202</span></span><br><span class="line"><span class="number">5</span>    <span class="number">2000</span><span class="number">-01</span><span class="number">-06</span>   <span class="number">0.478344</span>   <span class="number">0.449933</span> <span class="number">-0.741620</span>  <span class="number">-1.962409</span></span><br><span class="line"><span class="number">6</span>    <span class="number">2000</span><span class="number">-01</span><span class="number">-07</span>   <span class="number">1.235339</span>  <span class="number">-0.091757</span> <span class="number">-1.543861</span>  <span class="number">-1.084753</span></span><br><span class="line">..          ...        ...        ...       ...        ...</span><br><span class="line"><span class="number">993</span>  <span class="number">2002</span><span class="number">-09</span><span class="number">-20</span> <span class="number">-10.628548</span>  <span class="number">-9.153563</span> <span class="number">-7.883146</span>  <span class="number">28.313940</span></span><br><span class="line"><span class="number">994</span>  <span class="number">2002</span><span class="number">-09</span><span class="number">-21</span> <span class="number">-10.390377</span>  <span class="number">-8.727491</span> <span class="number">-6.399645</span>  <span class="number">30.914107</span></span><br><span class="line"><span class="number">995</span>  <span class="number">2002</span><span class="number">-09</span><span class="number">-22</span>  <span class="number">-8.985362</span>  <span class="number">-8.485624</span> <span class="number">-4.669462</span>  <span class="number">31.367740</span></span><br><span class="line"><span class="number">996</span>  <span class="number">2002</span><span class="number">-09</span><span class="number">-23</span>  <span class="number">-9.558560</span>  <span class="number">-8.781216</span> <span class="number">-4.499815</span>  <span class="number">30.518439</span></span><br><span class="line"><span class="number">997</span>  <span class="number">2002</span><span class="number">-09</span><span class="number">-24</span>  <span class="number">-9.902058</span>  <span class="number">-9.340490</span> <span class="number">-4.386639</span>  <span class="number">30.105593</span></span><br><span class="line"><span class="number">998</span>  <span class="number">2002</span><span class="number">-09</span><span class="number">-25</span> <span class="number">-10.216020</span>  <span class="number">-9.480682</span> <span class="number">-3.933802</span>  <span class="number">29.758560</span></span><br><span class="line"><span class="number">999</span>  <span class="number">2002</span><span class="number">-09</span><span class="number">-26</span> <span class="number">-11.856774</span> <span class="number">-10.671012</span> <span class="number">-3.216025</span>  <span class="number">29.369368</span></span><br><span class="line"></span><br><span class="line">[<span class="number">1000</span> rows x <span class="number">5</span> columns]</span><br></pre></td></tr></table></figure></div><h2 id="HDF5"><a href="#HDF5" class="headerlink" title="HDF5"></a>HDF5</h2><p>参考：<a href="http://pandas.pydata.org/pandas-docs/stable/io.html#io-hdf5" target="_blank" rel="noopener external nofollow noreferrer">HDF5 存储</a></p><p>1、 写入 HDF5 存储：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">143</span>]: df.to_hdf(<span class="string">'foo.h5'</span>,<span class="string">'df'</span>)</span><br></pre></td></tr></table></figure></div><p>2、 从 HDF5 存储中读取：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">144</span>]: pd.read_hdf(<span class="string">'foo.h5'</span>,<span class="string">'df'</span>)</span><br><span class="line">Out[<span class="number">144</span>]: </span><br><span class="line">                    A          B         C          D</span><br><span class="line"><span class="number">2000</span><span class="number">-01</span><span class="number">-01</span>   <span class="number">0.266457</span>  <span class="number">-0.399641</span> <span class="number">-0.219582</span>   <span class="number">1.186860</span></span><br><span class="line"><span class="number">2000</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">-1.170732</span>  <span class="number">-0.345873</span>  <span class="number">1.653061</span>  <span class="number">-0.282953</span></span><br><span class="line"><span class="number">2000</span><span class="number">-01</span><span class="number">-03</span>  <span class="number">-1.734933</span>   <span class="number">0.530468</span>  <span class="number">2.060811</span>  <span class="number">-0.515536</span></span><br><span class="line"><span class="number">2000</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">-1.555121</span>   <span class="number">1.452620</span>  <span class="number">0.239859</span>  <span class="number">-1.156896</span></span><br><span class="line"><span class="number">2000</span><span class="number">-01</span><span class="number">-05</span>   <span class="number">0.578117</span>   <span class="number">0.511371</span>  <span class="number">0.103552</span>  <span class="number">-2.428202</span></span><br><span class="line"><span class="number">2000</span><span class="number">-01</span><span class="number">-06</span>   <span class="number">0.478344</span>   <span class="number">0.449933</span> <span class="number">-0.741620</span>  <span class="number">-1.962409</span></span><br><span class="line"><span class="number">2000</span><span class="number">-01</span><span class="number">-07</span>   <span class="number">1.235339</span>  <span class="number">-0.091757</span> <span class="number">-1.543861</span>  <span class="number">-1.084753</span></span><br><span class="line"><span class="meta">... </span>              ...        ...       ...        ...</span><br><span class="line"><span class="number">2002</span><span class="number">-09</span><span class="number">-20</span> <span class="number">-10.628548</span>  <span class="number">-9.153563</span> <span class="number">-7.883146</span>  <span class="number">28.313940</span></span><br><span class="line"><span class="number">2002</span><span class="number">-09</span><span class="number">-21</span> <span class="number">-10.390377</span>  <span class="number">-8.727491</span> <span class="number">-6.399645</span>  <span class="number">30.914107</span></span><br><span class="line"><span class="number">2002</span><span class="number">-09</span><span class="number">-22</span>  <span class="number">-8.985362</span>  <span class="number">-8.485624</span> <span class="number">-4.669462</span>  <span class="number">31.367740</span></span><br><span class="line"><span class="number">2002</span><span class="number">-09</span><span class="number">-23</span>  <span class="number">-9.558560</span>  <span class="number">-8.781216</span> <span class="number">-4.499815</span>  <span class="number">30.518439</span></span><br><span class="line"><span class="number">2002</span><span class="number">-09</span><span class="number">-24</span>  <span class="number">-9.902058</span>  <span class="number">-9.340490</span> <span class="number">-4.386639</span>  <span class="number">30.105593</span></span><br><span class="line"><span class="number">2002</span><span class="number">-09</span><span class="number">-25</span> <span class="number">-10.216020</span>  <span class="number">-9.480682</span> <span class="number">-3.933802</span>  <span class="number">29.758560</span></span><br><span class="line"><span class="number">2002</span><span class="number">-09</span><span class="number">-26</span> <span class="number">-11.856774</span> <span class="number">-10.671012</span> <span class="number">-3.216025</span>  <span class="number">29.369368</span></span><br><span class="line"></span><br><span class="line">[<span class="number">1000</span> rows x <span class="number">4</span> columns]</span><br></pre></td></tr></table></figure></div><h2 id="Excel"><a href="#Excel" class="headerlink" title="Excel"></a>Excel</h2><p>参考：<a href="http://pandas.pydata.org/pandas-docs/stable/io.html#io-excel" target="_blank" rel="noopener external nofollow noreferrer">_MS Excel_</a></p><p>1、 写入excel文件：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">145</span>]: df.to_excel(<span class="string">'foo.xlsx'</span>, sheet_name=<span class="string">'Sheet1'</span>)</span><br></pre></td></tr></table></figure></div><p>2、 从excel文件中读取：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">146</span>]: pd.read_excel(<span class="string">'foo.xlsx'</span>, <span class="string">'Sheet1'</span>, index_col=<span class="literal">None</span>, na_values=[<span class="string">'NA'</span>])</span><br><span class="line">Out[<span class="number">146</span>]: </span><br><span class="line">                    A          B         C          D</span><br><span class="line"><span class="number">2000</span><span class="number">-01</span><span class="number">-01</span>   <span class="number">0.266457</span>  <span class="number">-0.399641</span> <span class="number">-0.219582</span>   <span class="number">1.186860</span></span><br><span class="line"><span class="number">2000</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">-1.170732</span>  <span class="number">-0.345873</span>  <span class="number">1.653061</span>  <span class="number">-0.282953</span></span><br><span class="line"><span class="number">2000</span><span class="number">-01</span><span class="number">-03</span>  <span class="number">-1.734933</span>   <span class="number">0.530468</span>  <span class="number">2.060811</span>  <span class="number">-0.515536</span></span><br><span class="line"><span class="number">2000</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">-1.555121</span>   <span class="number">1.452620</span>  <span class="number">0.239859</span>  <span class="number">-1.156896</span></span><br><span class="line"><span class="number">2000</span><span class="number">-01</span><span class="number">-05</span>   <span class="number">0.578117</span>   <span class="number">0.511371</span>  <span class="number">0.103552</span>  <span class="number">-2.428202</span></span><br><span class="line"><span class="number">2000</span><span class="number">-01</span><span class="number">-06</span>   <span class="number">0.478344</span>   <span class="number">0.449933</span> <span class="number">-0.741620</span>  <span class="number">-1.962409</span></span><br><span class="line"><span class="number">2000</span><span class="number">-01</span><span class="number">-07</span>   <span class="number">1.235339</span>  <span class="number">-0.091757</span> <span class="number">-1.543861</span>  <span class="number">-1.084753</span></span><br><span class="line"><span class="meta">... </span>              ...        ...       ...        ...</span><br><span class="line"><span class="number">2002</span><span class="number">-09</span><span class="number">-20</span> <span class="number">-10.628548</span>  <span class="number">-9.153563</span> <span class="number">-7.883146</span>  <span class="number">28.313940</span></span><br><span class="line"><span class="number">2002</span><span class="number">-09</span><span class="number">-21</span> <span class="number">-10.390377</span>  <span class="number">-8.727491</span> <span class="number">-6.399645</span>  <span class="number">30.914107</span></span><br><span class="line"><span class="number">2002</span><span class="number">-09</span><span class="number">-22</span>  <span class="number">-8.985362</span>  <span class="number">-8.485624</span> <span class="number">-4.669462</span>  <span class="number">31.367740</span></span><br><span class="line"><span class="number">2002</span><span class="number">-09</span><span class="number">-23</span>  <span class="number">-9.558560</span>  <span class="number">-8.781216</span> <span class="number">-4.499815</span>  <span class="number">30.518439</span></span><br><span class="line"><span class="number">2002</span><span class="number">-09</span><span class="number">-24</span>  <span class="number">-9.902058</span>  <span class="number">-9.340490</span> <span class="number">-4.386639</span>  <span class="number">30.105593</span></span><br><span class="line"><span class="number">2002</span><span class="number">-09</span><span class="number">-25</span> <span class="number">-10.216020</span>  <span class="number">-9.480682</span> <span class="number">-3.933802</span>  <span class="number">29.758560</span></span><br><span class="line"><span class="number">2002</span><span class="number">-09</span><span class="number">-26</span> <span class="number">-11.856774</span> <span class="number">-10.671012</span> <span class="number">-3.216025</span>  <span class="number">29.369368</span></span><br><span class="line"></span><br><span class="line">[<span class="number">1000</span> rows x <span class="number">4</span> columns]</span><br></pre></td></tr></table></figure></div><h1 id="十三、陷阱"><a href="#十三、陷阱" class="headerlink" title="十三、陷阱"></a>十三、陷阱</h1><p>如果你尝试某个操作并且看到如下异常：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PY"><figure class="iseeu highlight /py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">if</span> pd.Series([<span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">False</span>]):</span><br><span class="line">    print(<span class="string">"I was true"</span>)</span><br><span class="line">Traceback</span><br><span class="line">    ...</span><br><span class="line">ValueError: The truth value of an array <span class="keyword">is</span> ambiguous. Use a.empty, a.any() <span class="keyword">or</span> a.all().</span><br></pre></td></tr></table></figure></div><p>解释及处理方式请见<a href="http://pandas.pydata.org/pandas-docs/stable/basics.html#basics-compare" target="_blank" rel="noopener external nofollow noreferrer">比较</a>。</p><p>同时请见<a href="http://pandas.pydata.org/pandas-docs/stable/gotchas.html#gotchas" target="_blank" rel="noopener external nofollow noreferrer">陷阱</a>。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>pandas</category>
      </categories>
      <tags>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习课程</title>
    <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><!-- build time:Mon Apr 20 2020 13:02:11 GMT+0800 (GMT+08:00) --><h2 id="机器学习概述"><a href="#机器学习概述" class="headerlink" title="机器学习概述"></a>机器学习概述</h2><h3 id="什么是机器学习"><a href="#什么是机器学习" class="headerlink" title="什么是机器学习"></a>什么是机器学习</h3><p>机器学习是从<strong><span style="color:red">数据</span></strong>中自动分析获得<strong><span style="color:red">规律(模型)</span></strong>，并利用规律对<strong><span style="color:red">未知数据进行预测</span></strong>。</p><h3 id="机器学习算法分类"><a href="#机器学习算法分类" class="headerlink" title="机器学习算法分类"></a>机器学习算法分类</h3><h6 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h6><p>目标值：类别—分类问题</p><p>KNN、贝叶斯分类、决策树与随机森林、逻辑回归</p><p>目标值：连续型数据—回归问题</p><p>线性回归、岭回归</p><h6 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h6><p>目标值：无</p><p>聚类K-means</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/1fd68fd47f13030f88eecd632db3a4db.png" alt="img"></p><h3 id="机器学习开发流程"><a href="#机器学习开发流程" class="headerlink" title="机器学习开发流程"></a>机器学习开发流程</h3><p>1）获取数据</p><p>2）数据处理</p><p>3）特征工程</p><p>4）机器学习算法训练—模型</p><p>5）模型评估</p><p>6）应用</p><h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>数据———数据集的构成———特征值 + 目标值</p><h4 id="可用数据集"><a href="#可用数据集" class="headerlink" title="可用数据集"></a>可用数据集</h4><p>Kaggle特点：1、大数据竞赛平台 2、80万科学家 3、真实数据 4、数据量巨大</p><p>UCI特点：1、收录了360个数据集 2、覆盖科学、生活、经济等领域 3、数据量几十万</p><p>scikit-learn特点：1、数据量较小 2、方便学习</p><p>网址：</p><p>Kaggle网址：<a href="https://www.kaggle.com/datasets" target="_blank" rel="noopener external nofollow noreferrer">https://www.kaggle.com/datasets</a></p><p>UCI数据集网址： <a href="http://archive.ics.uci.edu/ml/" target="_blank" rel="noopener external nofollow noreferrer">http://archive.ics.uci.edu/ml/</a></p><p>scikit-learn网址：<a href="http://scikit-learn.org/stable/datasets/index.html#datasets" target="_blank" rel="noopener external nofollow noreferrer">http://scikit-learn.org/stable/datasets/index.html#datasets</a></p><h4 id="sklearn数据集"><a href="#sklearn数据集" class="headerlink" title="sklearn数据集"></a>sklearn数据集</h4><p>load_*小规模的数据集</p><p>fetch_*大规模的数据集</p><p>Bunch类型</p><p>数据集划分—model_selection.train_test_split()</p><ul><li><p>训练数据：用于训练，构建模型</p></li><li><p>测试数据：在模型检验时使用，用于评估模型是否有效</p></li></ul><h3 id="特征工程介绍"><a href="#特征工程介绍" class="headerlink" title="特征工程介绍"></a>特征工程介绍</h3><p>特征工程是将原始数据转换为更好地代表预测模型的潜在问题的特征的过程，从而提高了对未知数据的模型准确性。</p><p>sklearn 特征工程</p><p>Scikit-learn包含的内容：分类、聚类、回归、特征工程、模型选择和调优。</p><p>pandas 数据清洗、数据处理</p><p><strong><span style="color:red">特征处理</span></strong>是特征工程的核心部分，包括<strong><span style="color:red">特征提取</span></strong>、<strong><span style="color:red">数据预处理</span></strong>、<strong><span style="color:red">特征选择</span></strong>、<strong><span style="color:red">特征降维</span></strong>等。</p><h3 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h3><p>特征提取包括将任意数据（如文本或图像）转换为可用于机器学习的数字特征。<br>注：特征值化是为了计算机更好的去理解数据</p><p><strong>包：sklearn.feature_extraction</strong></p><p><strong>字典特征提取</strong></p><ul><li><p>应用DictVectorizer实现对类别特征进行数值化、离散化</p><p>sklearn.feature_extraction.DictVectorizer(sparse=True,…)<br>DictVectorizer.fit_transform(X) X:字典或者包含字典的迭代器返回值：返回sparse矩阵<br>DictVectorizer.inverse_transform(X) X:array数组或者sparse矩阵 返回值:转换之前数据格式<br>DictVectorizer.get_feature_names() 返回类别名称<br><strong>应用：</strong></p></li></ul><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#对字典类型的数据进行特征抽取</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line">data = [&#123;<span class="string">'city'</span>: <span class="string">'北京'</span>,<span class="string">'temperature'</span>:<span class="number">100</span>&#125;, &#123;<span class="string">'city'</span>: <span class="string">'上海'</span>,<span class="string">'temperature'</span>:<span class="number">60</span>&#125;, &#123;<span class="string">'city'</span>: <span class="string">'深圳'</span>,<span class="string">'temperature'</span>:<span class="number">30</span>&#125;]</span><br><span class="line"><span class="comment"># 1、实例化一个转换器类</span></span><br><span class="line">transfer = DictVectorizer(sparse=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 2、调用fit_transform</span></span><br><span class="line">data = transfer.fit_transform(data)</span><br><span class="line">print(<span class="string">"返回的结果:\n"</span>, data)</span><br><span class="line"><span class="comment"># 打印特征名字</span></span><br><span class="line">print(<span class="string">"特征名字：\n"</span>, transfer.get_feature_names())</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">返回的结果:</span><br><span class="line"> [[  <span class="number">0.</span>   <span class="number">1.</span>   <span class="number">0.</span> <span class="number">100.</span>]</span><br><span class="line"> [  <span class="number">1.</span>   <span class="number">0.</span>   <span class="number">0.</span>  <span class="number">60.</span>]</span><br><span class="line"> [  <span class="number">0.</span>   <span class="number">0.</span>   <span class="number">1.</span>  <span class="number">30.</span>]]</span><br><span class="line">特征名字：</span><br><span class="line"> [<span class="string">'city=上海'</span>, <span class="string">'city=北京'</span>, <span class="string">'city=深圳'</span>, <span class="string">'temperature'</span>]</span><br></pre></td></tr></table></figure></div><p><strong>文本特征提取</strong></p><ul><li><p><strong>独热编码</strong>（One-HotEncoding）</p></li><li><p>应用CountVectorizer实现对文本特征进行数值化</p></li><li><p>应用TfidfVectorizer(TF-IDF)实现对文本特征进行数值化</p><p>sklearn.feature_extraction.text.CountVectorizer(stop_words=[])</p><p>返回词频矩阵<br>CountVectorizer.fit_transform(X) X:文本或者包含文本字符串的可迭代对象 返回值：返回sparse矩阵<br>CountVectorizer.inverse_transform(X) X:array数组或者sparse矩阵 返回值:转换之前数据格<br>CountVectorizer.get_feature_names() 返回值:单词列表<br>sklearn.feature_extraction.text.TfidfVectorizer</p><ul><li>TF-IDF的主要思想是：如果<strong>某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现</strong>，则认为此词或者短语具有很好的类别区分能力，适合用来分类。</li><li><strong>TF-IDF作用：用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。</strong></li></ul></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="comment"># 对于文本数据，进行特征抽取</span></span><br><span class="line">tf = TfidfVectorizer()</span><br><span class="line">x_train = tf.fit_transform(x_train)<span class="comment">#20类新闻分类数据集</span></span><br><span class="line"><span class="comment">#这里打印出来的列表是：训练集当中的所有不同词的组成的一个列表</span></span><br><span class="line">print(tf.get_feature_names())</span><br><span class="line"><span class="comment"># print(x_train.toarray())</span></span><br><span class="line">x_test = tf.transform(x_test) <span class="comment"># 不需要fit_transform</span></span><br></pre></td></tr></table></figure></div><ul><li><strong>应用</strong></li></ul><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer,TfidfVectorizer</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cut_word</span><span class="params">(text)</span>:</span></span><br><span class="line">    <span class="comment"># 用jieba对中文字符串进行分词</span></span><br><span class="line">    text = <span class="string">" "</span>.join(list(jieba.cut(text)))</span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"><span class="comment">#对中文进行特征抽取</span></span><br><span class="line">data = [<span class="string">"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。"</span>,</span><br><span class="line">            <span class="string">"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。"</span>,</span><br><span class="line">            <span class="string">"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。"</span>,</span><br><span class="line">            <span class="string">"life is short,i like like python"</span>, <span class="string">"life is too long,i dislike python"</span>]</span><br><span class="line"><span class="comment"># 将原始数据转换成分好词的形式</span></span><br><span class="line">text_list = []</span><br><span class="line"><span class="keyword">for</span> sent <span class="keyword">in</span> data:</span><br><span class="line">	text_list.append(cut_word(sent))</span><br><span class="line">print(text_list)</span><br><span class="line"><span class="comment"># 1、实例化一个转换器类</span></span><br><span class="line">transfer = CountVectorizer()</span><br><span class="line"><span class="comment">#transfer = TfidfVectorizer()</span></span><br><span class="line"><span class="comment"># 2、调用fit_transform</span></span><br><span class="line">data = transfer.fit_transform(text_list)</span><br><span class="line">print(<span class="string">"文本特征抽取的结果：\n"</span>, data.toarray())</span><br><span class="line">print(<span class="string">"返回特征名字：\n"</span>, transfer.get_feature_names())</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">[<span class="string">'一种 还是 一种 今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。'</span>, <span class="string">'我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。'</span>, <span class="string">'如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。'</span>, <span class="string">'life   is   short , i   like   like   python'</span>, <span class="string">'life   is   too   long , i   dislike   python'</span>]</span><br><span class="line">文本特征抽取的结果：</span><br><span class="line"> [[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span></span><br><span class="line">  <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">3</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line">  <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">4</span> <span class="number">3</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line">  <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line">  <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line">  <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br><span class="line">返回特征名字：</span><br><span class="line"> [<span class="string">'dislike'</span>, <span class="string">'is'</span>, <span class="string">'life'</span>, <span class="string">'like'</span>, <span class="string">'long'</span>, <span class="string">'python'</span>, <span class="string">'short'</span>, <span class="string">'too'</span>, <span class="string">'一种'</span>, <span class="string">'不会'</span>, <span class="string">'不要'</span>, <span class="string">'之前'</span>, <span class="string">'了解'</span>, <span class="string">'事物'</span>, <span class="string">'今天'</span>, <span class="string">'光是在'</span>, <span class="string">'几百万年'</span>, <span class="string">'发出'</span>, <span class="string">'取决于'</span>, <span class="string">'只用'</span>, <span class="string">'后天'</span>, <span class="string">'含义'</span>, <span class="string">'大部分'</span>, <span class="string">'如何'</span>, <span class="string">'如果'</span>, <span class="string">'宇宙'</span>, <span class="string">'我们'</span>, <span class="string">'所以'</span>, <span class="string">'放弃'</span>, <span class="string">'方式'</span>, <span class="string">'明天'</span>, <span class="string">'星系'</span>, <span class="string">'晚上'</span>, <span class="string">'某样'</span>, <span class="string">'残酷'</span>, <span class="string">'每个'</span>, <span class="string">'看到'</span>, <span class="string">'真正'</span>, <span class="string">'秘密'</span>, <span class="string">'绝对'</span>, <span class="string">'美好'</span>, <span class="string">'联系'</span>, <span class="string">'过去'</span>, <span class="string">'还是'</span>, <span class="string">'这样'</span>]</span><br></pre></td></tr></table></figure></div><p><strong>图像特征提取</strong>（深度学习将介绍）</p><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><h4 id="去除唯一属性"><a href="#去除唯一属性" class="headerlink" title="去除唯一属性"></a>去除唯一属性</h4><p>唯一属性通常是一些id属性，这些属性并不能刻画样本自身的分布规律，所以简单地删除这些属性即可。</p><h4 id="处理缺失值"><a href="#处理缺失值" class="headerlink" title="处理缺失值"></a>处理缺失值</h4><p>缺失值处理的三种方法：直接使用含有缺失值的特征；删除含有缺失值的特征（该方法在包含缺失值的属性含有大量缺失值而仅仅包含极少量有效值时是有效的）；缺失值补全。</p><p>常见的缺失值补全方法：均值插补、同类均值插补、建模预测、高维映射、多重插补、极大似然估计、压缩感知和矩阵补全。</p><p>（1）<strong>均值插补</strong></p><p>如果样本属性的距离是可度量的，则使用该属性有效值的平均值来插补缺失的值；</p><p>如果的距离是不可度量的，则使用该属性有效值的众数来插补缺失的值。<strong>如果使用众数插补，出现数据倾斜会造成什么影响？</strong></p><p>（2）<strong>同类均值插补</strong></p><p>首先将样本进行分类，然后以该类中样本的均值来插补缺失值。</p><p><strong>（3）建模预测</strong></p><p>将缺失的属性作为预测目标来预测，将数据集按照是否含有特定属性的缺失值分为两类，利用现有的机器学习算法对待预测数据集的缺失值进行预测。</p><p>该方法的根本的缺陷是如果其他属性和缺失属性无关，则预测的结果毫无意义；但是若预测结果相当准确，则说明这个缺失属性是没必要纳入数据集中的；一般的情况是介于两者之间。</p><p><strong>（4）高维映射</strong></p><p>将属性映射到高维空间，采用独热码编码（one-hot）技术。将包含K个离散取值范围的属性值扩展为K+1个属性值，若该属性值缺失，则扩展后的第K+1个属性值置为1。</p><p>这种做法是最精确的做法，保留了所有的信息，也未添加任何额外信息，若预处理时把所有的变量都这样处理，会大大增加数据的维度。这样做的好处是完整保留了原始数据的全部信息、不用考虑缺失值；缺点是计算量大大提升，且只有在样本量非常大的时候效果才好。</p><p>（5）<strong>多重插补</strong>（MultipleImputation，MI）</p><p>多重插补认为待插补的值是随机的，实践上通常是估计出待插补的值，再加上不同的噪声，形成多组可选插补值，根据某种选择依据，选取最合适的插补值。</p><p>（6）<strong>压缩感知和矩阵补全</strong></p><p>（7）<strong>手动插补</strong></p><p>插补处理只是将未知值补以我们的主观估计值，不一定完全符合客观事实。在许多情况下，根据对所在领域的理解，手动对缺失值进行插补的效果会更好。</p><h4 id="特征编码"><a href="#特征编码" class="headerlink" title="特征编码"></a>特征编码</h4><p>（1）<strong>标签处理</strong></p><p>通常我们会把字符型的标签转换成数值型的</p><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.DataFrame([</span><br><span class="line">            [<span class="string">'green'</span>, <span class="string">'M'</span>, <span class="number">10.1</span>, <span class="string">'class1'</span>], </span><br><span class="line">            [<span class="string">'red'</span>, <span class="string">'L'</span>, <span class="number">13.5</span>, <span class="string">'class2'</span>], </span><br><span class="line">            [<span class="string">'blue'</span>, <span class="string">'XL'</span>, <span class="number">15.3</span>, <span class="string">'class1'</span>]])</span><br><span class="line">df.columns = [<span class="string">'color'</span>, <span class="string">'size'</span>, <span class="string">'prize'</span>, <span class="string">'class label'</span>]</span><br><span class="line"><span class="comment">#标签处理</span></span><br><span class="line">class_mapping = &#123;label:idx <span class="keyword">for</span> idx,label <span class="keyword">in</span> enumerate(set(df[<span class="string">'class label'</span>]))&#125;</span><br><span class="line">df[<span class="string">'class label'</span>] = df[<span class="string">'class label'</span>].map(class_mapping)</span><br><span class="line">print(df)</span><br><span class="line">print(<span class="string">'-----------------------------------'</span>)</span><br><span class="line">size_mapping = &#123;</span><br><span class="line">           <span class="string">'XL'</span>: <span class="number">3</span>,</span><br><span class="line">           <span class="string">'L'</span>: <span class="number">2</span>,</span><br><span class="line">           <span class="string">'M'</span>: <span class="number">1</span>&#125;</span><br><span class="line"></span><br><span class="line">df[<span class="string">'size'</span>] = df[<span class="string">'size'</span>].map(size_mapping)</span><br><span class="line">print(df)</span><br></pre></td></tr></table></figure></div><p>输出结果:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">   color size  prize  <span class="class"><span class="keyword">class</span> <span class="title">label</span></span></span><br><span class="line"><span class="class">0  <span class="title">green</span>    <span class="title">M</span>   10.1            1</span></span><br><span class="line"><span class="class">1    <span class="title">red</span>    <span class="title">L</span>   13.5            0</span></span><br><span class="line"><span class="class">2   <span class="title">blue</span>   <span class="title">XL</span>   15.3            1</span></span><br><span class="line"><span class="class">-----------------------------------</span></span><br><span class="line"><span class="class">   <span class="title">color</span>  <span class="title">size</span>  <span class="title">prize</span>  <span class="title">class</span> <span class="title">label</span></span></span><br><span class="line"><span class="class">0  <span class="title">green</span>     1   10.1            1</span></span><br><span class="line"><span class="class">1    <span class="title">red</span>     2   13.5            0</span></span><br><span class="line"><span class="class">2   <span class="title">blue</span>     3   15.3            1</span></span><br></pre></td></tr></table></figure></div><p>（2）<strong>二值化</strong></p><p>二值化的过程是将数值型的属性转换为布尔值的属性，设定一个阈值作为划分属性值为0和1的分隔点。</p><p>使用preproccessing库的Binarizer类对数据进行二值化的代码如下：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Binarizer</span><br><span class="line"><span class="comment">#二值化，阈值设置为3，返回值为二值化后的数据</span></span><br><span class="line">Binarizer(threshold=<span class="number">3</span>).fit_transform(X)  <span class="comment">#X=iris.data（鸢尾花）数据集</span></span><br></pre></td></tr></table></figure></div><p>（3）<strong>scikit DictVectorizer</strong></p><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.DataFrame([</span><br><span class="line">            [<span class="string">'green'</span>, <span class="string">'M'</span>, <span class="number">10.1</span>, <span class="string">'class1'</span>], </span><br><span class="line">            [<span class="string">'red'</span>, <span class="string">'L'</span>, <span class="number">13.5</span>, <span class="string">'class2'</span>], </span><br><span class="line">            [<span class="string">'blue'</span>, <span class="string">'XL'</span>, <span class="number">15.3</span>, <span class="string">'class1'</span>]])</span><br><span class="line">df.columns = [<span class="string">'color'</span>, <span class="string">'size'</span>, <span class="string">'prize'</span>, <span class="string">'class label'</span>]</span><br><span class="line">print(df)</span><br><span class="line">print(<span class="string">'----------------------------------------------------------------------'</span>)</span><br><span class="line"><span class="comment">#print(df.transpose().to_dict().values())</span></span><br><span class="line"><span class="comment">#print('----------------------------------------------------------------------')</span></span><br><span class="line">feature = df.iloc[:, :<span class="number">-1</span>]</span><br><span class="line">print(feature)</span><br><span class="line">print(<span class="string">'----------------------------------------------------------------------'</span>)</span><br><span class="line"><span class="comment"># ②对于x转换成字典数据</span></span><br><span class="line">feature=feature.to_dict(orient=<span class="string">"records"</span>)</span><br><span class="line"><span class="comment">#feature=feature.transpose().to_dict().values() #对所有的数据都做了映射</span></span><br><span class="line"><span class="comment">#使用 DictVectorizer将得到特征的字典</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line">dvec = DictVectorizer(sparse=<span class="literal">False</span>)</span><br><span class="line">X = dvec.fit_transform(feature)</span><br><span class="line">print(dvec.get_feature_names())</span><br><span class="line">print(<span class="string">'----------------------------------------------------------------------'</span>)</span><br><span class="line">print(X)</span><br><span class="line">print(<span class="string">'----------------------------------------------------------------------'</span>)</span><br><span class="line"><span class="comment">#可以调用 get_feature_names 来返回新的列的名字，其中0和1就代表是不是这个属性.</span></span><br><span class="line">data=pd.DataFrame(X, columns=dvec.get_feature_names())</span><br><span class="line">print(data)</span><br></pre></td></tr></table></figure></div><p>输出结果:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">   color size  prize <span class="class"><span class="keyword">class</span> <span class="title">label</span></span></span><br><span class="line"><span class="class">0  <span class="title">green</span>    <span class="title">M</span>   10.1      <span class="title">class1</span></span></span><br><span class="line"><span class="class">1    <span class="title">red</span>    <span class="title">L</span>   13.5      <span class="title">class2</span></span></span><br><span class="line"><span class="class">2   <span class="title">blue</span>   <span class="title">XL</span>   15.3      <span class="title">class1</span></span></span><br><span class="line"><span class="class">----------------------------------------------------------------------</span></span><br><span class="line"><span class="class">   <span class="title">color</span> <span class="title">size</span>  <span class="title">prize</span></span></span><br><span class="line"><span class="class">0  <span class="title">green</span>    <span class="title">M</span>   10.1</span></span><br><span class="line"><span class="class">1    <span class="title">red</span>    <span class="title">L</span>   13.5</span></span><br><span class="line"><span class="class">2   <span class="title">blue</span>   <span class="title">XL</span>   15.3</span></span><br><span class="line"><span class="class">----------------------------------------------------------------------</span></span><br><span class="line">['color=blue', 'color=green', 'color=red', 'prize', 'size=L', 'size=M', 'size=XL']</span><br><span class="line">----------------------------------------------------------------------</span><br><span class="line">[[ <span class="number">0.</span>   <span class="number">1.</span>   <span class="number">0.</span>  <span class="number">10.1</span>  <span class="number">0.</span>   <span class="number">1.</span>   <span class="number">0.</span> ]</span><br><span class="line"> [ <span class="number">0.</span>   <span class="number">0.</span>   <span class="number">1.</span>  <span class="number">13.5</span>  <span class="number">1.</span>   <span class="number">0.</span>   <span class="number">0.</span> ]</span><br><span class="line"> [ <span class="number">1.</span>   <span class="number">0.</span>   <span class="number">0.</span>  <span class="number">15.3</span>  <span class="number">0.</span>   <span class="number">0.</span>   <span class="number">1.</span> ]]</span><br><span class="line">----------------------------------------------------------------------</span><br><span class="line">   color=blue  color=green  color=red  prize  size=L  size=M  size=XL</span><br><span class="line"><span class="number">0</span>         <span class="number">0.0</span>          <span class="number">1.0</span>        <span class="number">0.0</span>   <span class="number">10.1</span>     <span class="number">0.0</span>     <span class="number">1.0</span>      <span class="number">0.0</span></span><br><span class="line"><span class="number">1</span>         <span class="number">0.0</span>          <span class="number">0.0</span>        <span class="number">1.0</span>   <span class="number">13.5</span>     <span class="number">1.0</span>     <span class="number">0.0</span>      <span class="number">0.0</span></span><br><span class="line"><span class="number">2</span>         <span class="number">1.0</span>          <span class="number">0.0</span>        <span class="number">0.0</span>   <span class="number">15.3</span>     <span class="number">0.0</span>     <span class="number">0.0</span>      <span class="number">1.0</span></span><br></pre></td></tr></table></figure></div><p>（4）<strong>独热编码</strong>（One-HotEncoding）</p><p>独热编码采用N位状态寄存器来对N个可能的取值进行编码，每个状态都由独立的寄存器来表示，并且在任意时刻只有其中一位有效。</p><p>独热编码的优点：能够处理非数值属性；在一定程度上扩充了特征；编码后的属性是稀疏的，存在大量的零元分量。</p><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.DataFrame([</span><br><span class="line">            [<span class="string">'green'</span>, <span class="string">'M'</span>, <span class="number">10.1</span>, <span class="string">'class1'</span>], </span><br><span class="line">            [<span class="string">'red'</span>, <span class="string">'L'</span>, <span class="number">13.5</span>, <span class="string">'class2'</span>], </span><br><span class="line">            [<span class="string">'blue'</span>, <span class="string">'XL'</span>, <span class="number">15.3</span>, <span class="string">'class1'</span>]])</span><br><span class="line">df.columns = [<span class="string">'color'</span>, <span class="string">'size'</span>, <span class="string">'prize'</span>, <span class="string">'class label'</span>]</span><br><span class="line"><span class="comment">#OneHotEncoder 必须使用整数作为输入，所以得先使用scikit LabelEncoder处理一下</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">class_le = LabelEncoder()</span><br><span class="line">df[<span class="string">'class label'</span>] = class_le.fit_transform(df[<span class="string">'class label'</span>])</span><br><span class="line">print(df)</span><br><span class="line">print(<span class="string">'-----------------------------------'</span>)</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line">ohe = OneHotEncoder(sparse=<span class="literal">False</span>)</span><br><span class="line">X = ohe.fit_transform(df[[<span class="string">'color'</span>]].values)</span><br><span class="line">print(X)</span><br></pre></td></tr></table></figure></div><p>输出结果:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">   color size  prize  <span class="class"><span class="keyword">class</span> <span class="title">label</span></span></span><br><span class="line"><span class="class">0  <span class="title">green</span>    <span class="title">M</span>   10.1            0</span></span><br><span class="line"><span class="class">1    <span class="title">red</span>    <span class="title">L</span>   13.5            1</span></span><br><span class="line"><span class="class">2   <span class="title">blue</span>   <span class="title">XL</span>   15.3            0</span></span><br><span class="line"><span class="class">-----------------------------------</span></span><br><span class="line"><span class="class">[[0. 1. 0.]</span></span><br><span class="line"><span class="class"> [0. 0. 1.]</span></span><br><span class="line"><span class="class"> [1. 0. 0.]]</span></span><br></pre></td></tr></table></figure></div><p>注：Pandas库中同样有类似的操作，使用get_dummies也可以得到相应的特征</p><p>（5）<strong>pandas get_dummies</strong></p><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.DataFrame([</span><br><span class="line">            [<span class="string">'green'</span>,<span class="number">10.1</span>], </span><br><span class="line">            [<span class="string">'red'</span>, <span class="number">13.5</span>], </span><br><span class="line">            [<span class="string">'blue'</span>,<span class="number">15.3</span>]])</span><br><span class="line">df.columns = [<span class="string">'color'</span>, <span class="string">'prize'</span>]</span><br><span class="line">df=pd.get_dummies(df)</span><br><span class="line">print(df)</span><br></pre></td></tr></table></figure></div><p>输出结果:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">   prize  color_blue  color_green  color_red</span><br><span class="line"><span class="number">0</span>   <span class="number">10.1</span>           <span class="number">0</span>            <span class="number">1</span>          <span class="number">0</span></span><br><span class="line"><span class="number">1</span>   <span class="number">13.5</span>           <span class="number">0</span>            <span class="number">0</span>          <span class="number">1</span></span><br><span class="line"><span class="number">2</span>   <span class="number">15.3</span>           <span class="number">1</span>            <span class="number">0</span>          <span class="number">0</span></span><br></pre></td></tr></table></figure></div><h4 id="无量纲化、正则化"><a href="#无量纲化、正则化" class="headerlink" title="无量纲化、正则化"></a>无量纲化、正则化</h4><h6 id="无量纲化"><a href="#无量纲化" class="headerlink" title="无量纲化"></a>无量纲化</h6><p>数据标准化是将样本的属性缩放到某个指定的范围。</p><p><strong>标准化</strong>：基于原始数据的均值（mean）和标准差（standarddeviation）进行数据的标准化。</p><p>要求 均值$\mu = 0$ 和标准差 $\sigma = 1$</p><p>公式表达为：</p><script type="math/tex;mode=display">\begin{equation} z = \frac{x - \mu}{\sigma}\end{equation}</script><p>使用preproccessing库的StandardScaler类对数据进行标准化的代码如下：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler </span><br><span class="line"><span class="comment">#标准化，返回值为标准化后的数据</span></span><br><span class="line">ss=StandardScaler()</span><br><span class="line">X1=ss.fit_transform(X) <span class="comment">#X=iris.data（鸢尾花）数据集</span></span><br></pre></td></tr></table></figure></div><p><strong>归一化</strong>：处理后的所有特征的值都会被压缩到 0到1区间上.这样做还可以抑制离群值对结果的影响.</p><p>公式表达为：</p><script type="math/tex;mode=display">{\begin{equation} X_{norm} = \frac{X - X_{min}}{X_{max}-X_{min}} \end{equation}}</script><p>使用preproccessing库的MinMaxScaler类对数据进行区间缩放的代码如下：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="comment">#区间缩放，返回值为缩放到[0, 1]区间的数据</span></span><br><span class="line">mms=MinMaxScaler()</span><br><span class="line">X2=mms.fit_transform(X) <span class="comment">#X=iris.data（鸢尾花）数据集</span></span><br></pre></td></tr></table></figure></div><h6 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h6><p>正则化的过程是将每个样本缩放到单位范数（每个样本的范数为1），如果后面要使用如二次型（点积）或者其它核方法计算两个样本之间的相似性这个方法会很有用。</p><p>该方法主要应用于文本分类和聚类中。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Normalizer</span><br><span class="line">ss=Normalizer()</span><br><span class="line">X3=ss.fit_transform(X) <span class="comment">#X=iris.data（鸢尾花）数据集</span></span><br></pre></td></tr></table></figure></div><h6 id="标准化与正则化的区别"><a href="#标准化与正则化的区别" class="headerlink" title="标准化与正则化的区别"></a>标准化与正则化的区别</h6><p>简单来说，<strong><span style="color:red">标准化是依照特征矩阵的列处理数据</span></strong>，其通过求z-score的方法，将样本的特征值转换到同一量纲下。<strong><span style="color:red">正则化是依照特征矩阵的行处理数据</span></strong>，其目的在于样本向量在点乘运算或其他核函数计算相似性时，拥有统一的标准，也就是说都转化为“单位向量”。</p><h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p>特征选择：数据中包含冗余或相关变量（或特征、属性、指标），旨在从原有特征中找出主要特征。</p><p>包：<strong>sklearn.feature_selection</strong></p><p>当数据预处理完成后，我们需要选择有意义的特征输入机器学习的算法和模型进行训练。通常来说，从两个方面考虑来选择特征：</p><ul><li><strong>特征是否发散</strong>：如果一个<strong><span style="color:red">特征不发散，例如方差接近于0</span></strong>，也就是说样本在这个特征上基本上没有差异，<strong><span style="color:red">这个特征对于样本的区分并没有什么用</span></strong>。</li><li><strong>特征与目标的相关性</strong>：这点比较显见，<strong><span style="color:red">与目标相关性高的特征，应当优选选择</span></strong>。除移除低方差法外，本文介绍的其他方法均从相关性考虑。</li></ul><p><strong>根据特征选择的形式又可以将特征选择方法分为3种：</strong></p><h4 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h4><p>Filter：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。</p><p><strong>方差选择法</strong>：低方差特征过滤</p><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line">X = [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line">sel = VarianceThreshold(threshold=(<span class="number">.8</span> * (<span class="number">1</span> - <span class="number">.8</span>)))</span><br><span class="line">X1=sel.fit_transform(X)</span><br><span class="line">print(X1)</span><br></pre></td></tr></table></figure></div><p>输出结果:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">[[<span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span>]]</span><br></pre></td></tr></table></figure></div><p>果然, VarianceThreshold 移除了第一列特征，第一列中特征值为0的概率达到了5/6.</p><p><strong>相关系数</strong>：特征与特征之间的相关程度（<strong><span style="color:red">与目标相关性高的特征，应当优选选择</span></strong>）</p><ul><li><p>对于<strong><span style="color:red">分类问题(y离散)</span></strong>，可采用：</p><p><strong><span style="color:#00f">卡方检验</span></strong>，<em>f_classif</em>, <em>mutual_info_classif</em>，<strong><span style="color:#00f">互信息</span></strong></p></li><li><p>对于<strong><span style="color:red">回归问题(y连续)</span></strong>，可采用：<br><strong><span style="color:#00f">皮尔森相关系数</span></strong>，<strong><span style="color:#00f"><em>f_regression</em></span></strong>, <em>mutual_info_regression</em>，最大信息系数</p><p><strong>卡方(Chi2)检验</strong></p><p>​ 经典的卡方检验是检验定性自变量对定性因变量的相关性。假设自变量有N种取值，因变量有M种取值，考虑自变量等于i且因变量等于j的样本频数的观察值与期望的差距，构建统计量：</p><script type="math/tex;mode=display">\chi^{2}=\sum \frac{(A-E)^{2}}{E}</script><p>假设有两个分类变量X和Y，它们的值域分别为{x1, x2}和{y1, y2}，其样本频数列联表为：</p></li></ul><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/表格1.JPG" alt></p><p>经典的卡方检验是检验定性自变量对定性因变量的相关性，针对分类问题。比如，我们可以对样本进行一次chi2测试来选择最佳的两项特征：</p><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2</span><br><span class="line">iris = load_iris()</span><br><span class="line">X, y = iris.data, iris.target</span><br><span class="line">print(X.shape)</span><br><span class="line">X_new = SelectKBest(chi2, k=<span class="number">2</span>).fit_transform(X, y)</span><br><span class="line">print(X_new.shape)</span><br></pre></td></tr></table></figure></div><p>输出结果:</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">(<span class="number">150</span>, <span class="number">4</span>)</span><br><span class="line">(<span class="number">150</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure></div><p><strong>Pearson相关系数 (Pearson Correlation)</strong></p><p>​ 皮尔森相关系数是一种最简单的，能帮助理解特征和响应变量之间关系的方法，该方法衡量的是变量之间的线性相关性，结果的取值区间为[-1，1]，-1表示完全的负相关，+1表示完全的正相关，0表示没有线性相关。</p><p>​ Pearson Correlation速度快、易于计算，经常在拿到数据(经过清洗和特征提取之后的)之后第一时间就执行。Scipy的 pearsonr 方法能够同时计算相关系数和p-value.</p><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">size = <span class="number">300</span></span><br><span class="line">x = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, size)</span><br><span class="line"><span class="comment"># pearsonr(x, y)的输入为特征矩阵和目标向量</span></span><br><span class="line">print(<span class="string">"Lower noise"</span>, pearsonr(x, x + np.random.normal(<span class="number">0</span>, <span class="number">1</span>, size)))</span><br><span class="line">print(<span class="string">"Higher noise"</span>, pearsonr(x, x + np.random.normal(<span class="number">0</span>, <span class="number">10</span>, size)))</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#输出为二元组(sorce, p-value)的数组</span></span><br><span class="line">Lower noise (<span class="number">0.7182483686213842</span>, <span class="number">7.324017312997672e-49</span>)</span><br><span class="line">Higher noise (<span class="number">0.05796429207933815</span>, <span class="number">0.31700993885325246</span>)</span><br></pre></td></tr></table></figure></div><p>这个例子中，我们比较了变量在加入噪音之前和之后的差异。当噪音比较小的时候，相关性很强，p-value很低。</p><p><strong>实例分析：股票的财务指标相关性计算</strong></p><p>分析</p><ul><li><p>两两特征之间进行相关性计算</p><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_csv(<span class="string">"factor_returns.csv"</span>)</span><br><span class="line">factor = [<span class="string">'pe_ratio'</span>, <span class="string">'pb_ratio'</span>, <span class="string">'market_cap'</span>, <span class="string">'return_on_asset_net_profit'</span>, <span class="string">'du_return_on_equity'</span>, <span class="string">'ev'</span>,<span class="string">'earnings_per_share'</span>, <span class="string">'revenue'</span>, <span class="string">'total_expense'</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(factor)):</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> range(i, len(factor) - <span class="number">1</span>):</span><br><span class="line">		print(<span class="string">"指标%s与指标%s之间的相关性大小为%f"</span> % (factor[i], factor[j + <span class="number">1</span>], pearsonr(data[factor[i]], data[factor[j + <span class="number">1</span>]])[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure></div><p>输出结果：（展示部分数据结果）</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">指标pe_ratio与指标pb_ratio之间的相关性大小为<span class="number">-0.004389</span></span><br><span class="line">指标pe_ratio与指标market_cap之间的相关性大小为<span class="number">-0.068861</span></span><br><span class="line">………………………………………………………………………………………………………………………………………………………………</span><br><span class="line">指标return_on_asset_net_profit与指标du_return_on_equity之间的相关性大小为<span class="number">0.818697</span></span><br><span class="line">指标return_on_asset_net_profit与指标ev之间的相关性大小为<span class="number">-0.101225</span></span><br><span class="line">………………………………………………………………………………………………………………………………………………………………</span><br><span class="line">指标revenue与指标total_expense之间的相关性大小为<span class="number">0.995845</span></span><br></pre></td></tr></table></figure></div><p>从中我们得出</p></li><li><p>指标revenue与指标total_expense之间的相关性大小为0.995845</p></li><li><p>指标return_on_asset_net_profit与指标du_return_on_equity之间的相关性大小为0.818697</p><p>我们也可以通过画图来观察结果</p><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">8</span>), dpi=<span class="number">100</span>)</span><br><span class="line">plt.scatter(data[<span class="string">'revenue'</span>], data[<span class="string">'total_expense'</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/Figure_1.png" alt="Figure_1"></p><p>注：特征与特征之间相关性很高：1）选取其中一个；2）权重加权求和；3）主成分分析</p><p>Scikit-learn提供的 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html" target="_blank" rel="noopener external nofollow noreferrer">f_regrssion</a> 方法能够批量计算特征的f_score和p-value，非常方便，参考sklearn的 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html" target="_blank" rel="noopener external nofollow noreferrer">pipeline</a></p><p><strong>Pearson相关系数的一个明显缺陷是，作为特征排序机制，</strong>他只对线性关系敏感。如果关系是非线性的，即便两个变量具有一一对应的关系，Pearson相关性也可能会接近0。例如：</p><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">x = np.random.uniform(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">100000</span>)</span><br><span class="line"><span class="keyword">print</span> pearsonr(x, x**<span class="number">2</span>)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="number">-0.00230804707612</span></span><br></pre></td></tr></table></figure></div><p>更多类似的例子参考 <a href="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/506px-Correlation_examples2.svg.png" target="_blank" rel="noopener external nofollow noreferrer">sample plots</a> 。另外，如果仅仅根据相关系数这个值来判断的话，有时候会具有很强的误导性，如 <a href="http://www.matrix67.com/blog/archives/2308" target="_blank" rel="noopener external nofollow noreferrer">Anscombe’s quartet</a> ，最好把数据可视化出来，以免得出错误的结论。</p><p><strong>互信息和最大信息系数 (Mutual information and maximal information coefficient (MIC)</strong></p><p>经典的互信息（互信息为随机变量X与Y之间的互信息$I(X;Y)$为单个事件之间互信息的数学期望）也是评价定性自变量对定性因变量的相关性的，互信息计算公式如下：</p><script type="math/tex;mode=display">I(X ; Y)=\sum_{x \in X} \sum_{y \in Y} p(x, y) \log \frac{p(x, y)}{p(x) p(y)}</script><p>互信息直接用于特征选择其实不是太方便：</p><p>1、它不属于度量方式，也没有办法归一化，在不同数据及上的结果无法做比较；</p><p>2、对于连续变量的计算不是很方便（X和Y都是集合，x，y都是离散的取值），通常变量需要先离散化，而互信息的结果对离散化的方式很敏感。</p><p>最大信息系数克服了这两个问题。它首先寻找一种最优的离散化方式，然后把互信息取值转换成一种度量方式，取值区间在[0，1]。 <a href="http://minepy.readthedocs.io/en/latest/" target="_blank" rel="noopener external nofollow noreferrer">minepy</a> 提供了MIC功能。</p><p>反过头来看y=x^2这个例子，MIC算出来的互信息值为1(最大的取值)。</p><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> minepy <span class="keyword">import</span> MINE</span><br><span class="line">m = MINE()</span><br><span class="line">x = np.random.uniform(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">10000</span>)</span><br><span class="line">m.compute_score(x, x**<span class="number">2</span>)</span><br><span class="line">print(m.mic())</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="number">1.0000000000000009</span></span><br></pre></td></tr></table></figure></div><p>MIC的统计能力遭到了 <a href="http://statweb.stanford.edu/~tibs/reshef/comment.pdf" target="_blank" rel="noopener external nofollow noreferrer">一些质疑</a> ，当零假设不成立时，MIC的统计就会受到影响。在有的数据集上不存在这个问题，但有的数据集上就存在这个问题。</p><p><strong>距离相关系数 (Distance Correlation)</strong></p><p>距离相关系数是为了克服Pearson相关系数的弱点而生的。在$X$和$X^2$这个例子中，即便Pearson相关系数是0，我们也不能断定这两个变量是独立的（有可能是非线性相关）；但如果距离相关系数是0，那么我们就可以说这两个变量是独立的。</p><p>R的 energy 包里提供了距离相关系数的实现，另外这是 <a href="https://gist.github.com/josef-pkt/2938402" target="_blank" rel="noopener external nofollow noreferrer">Python gist</a> 的实现。</p><p>尽管有 MIC 和 距离相关系数在了，但当变量之间的关系接近线性相关的时候，Pearson相关系数仍然是不可替代的。<br>第一，Pearson相关系数计算速度快，这在处理大规模数据的时候很重要。<br>第二，Pearson相关系数的取值区间是[-1，1]，而MIC和距离相关系数都是[0，1]。这个特点使得Pearson相关系数能够表征更丰富的关系，符号表示关系的正负，绝对值能够表示强度。当然，Pearson相关性有效的前提是两个变量的变化关系是单调的。</p><p><strong>基于模型的特征排序 (Model based ranking)</strong></p><p>这种方法的思路是直接使用你要用的机器学习算法，<strong>针对每个单独的特征和响应变量建立预测模型。</strong>假如特征和响应变量之间的关系是<strong>非线性的</strong>，可以用基于树的方法(决策树、随机森林)、或者扩展的线性模型等。基于树的方法比较易于使用，因为他们对非线性关系的建模比较好，并且不需要太多的调试。但要注意过拟合问题，因此树的深度最好不要太大，再就是<strong>运用交叉验证</strong>。</p><p>在波士顿房价数据集上使用sklearn的随机森林回归给出一个单变量选择的例子(这里使用了交叉验证)：</p><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score, ShuffleSplit</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># Load boston housing dataset as an example</span></span><br><span class="line">boston = load_boston()</span><br><span class="line">X = boston[<span class="string">"data"</span>]</span><br><span class="line">Y = boston[<span class="string">"target"</span>]</span><br><span class="line">names = boston[<span class="string">"feature_names"</span>]</span><br><span class="line">rf = RandomForestRegressor(n_estimators=<span class="number">20</span>, max_depth=<span class="number">4</span>)</span><br><span class="line">scores = []</span><br><span class="line"><span class="comment"># 单独采用每个特征进行建模，并进行交叉验证</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(X.shape[<span class="number">1</span>]):</span><br><span class="line">    score = cross_val_score(rf, X[:, i:i+<span class="number">1</span>], Y, scoring=<span class="string">"r2"</span>,  cv=ShuffleSplit(len(X), <span class="number">3</span>, <span class="number">.3</span>)) <span class="comment"># 注意X[:, i]和X[:, i:i+1]的区别</span></span><br><span class="line">    scores.append((format(np.mean(score), <span class="string">'.3f'</span>), names[i]))</span><br><span class="line">print(sorted(scores, reverse=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">[(<span class="string">'-8.082'</span>, <span class="string">'TAX'</span>), (<span class="string">'-6.871'</span>, <span class="string">'CHAS'</span>), (<span class="string">'-6.420'</span>, <span class="string">'RM'</span>), (<span class="string">'-6.315'</span>, <span class="string">'DIS'</span>), (<span class="string">'-4.833'</span>, <span class="string">'INDUS'</span>), (<span class="string">'-4.816'</span>, <span class="string">'AGE'</span>), (<span class="string">'-4.742'</span>, <span class="string">'LSTAT'</span>), (<span class="string">'-4.638'</span>, <span class="string">'RAD'</span>), (<span class="string">'-3.411'</span>, <span class="string">'NOX'</span>), (<span class="string">'-3.123'</span>, <span class="string">'CRIM'</span>), (<span class="string">'-26.603'</span>, <span class="string">'PTRATIO'</span>), (<span class="string">'-12.284'</span>, <span class="string">'B'</span>), (<span class="string">'-1.995'</span>, <span class="string">'ZN'</span>)]</span><br></pre></td></tr></table></figure></div></li></ul><h4 id="Wrapper"><a href="#Wrapper" class="headerlink" title="Wrapper"></a>Wrapper</h4><p>Wrapper：包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。</p><p>主要方法有：recursive feature elimination algorithm(递归特征消除算法)</p><h4 id="Embedded"><a href="#Embedded" class="headerlink" title="Embedded"></a>Embedded</h4><p>Embedded：嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。比如，Lasso和RF（随机森林）都有各自的特征选择方法。</p><p>注：使用SelectFromModel选择特征</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromMode</span><br></pre></td></tr></table></figure></div><h3 id="特征降维"><a href="#特征降维" class="headerlink" title="特征降维"></a>特征降维</h3><p>二维数组 此处的降维：降低特征的个数 效果：特征与特征之间不相关</p><p><strong><span style="color:red">降维</span></strong>是指在某种限定条件下，<strong><span style="color:red">降低随机变量（特征）个数</span></strong>，得到<strong><span style="color:red">一组“不相关”主变量</span></strong>的过程。</p><p>当特征选择完成后，可以直接训练模型了，但是可能由于特征矩阵过大，导致计算量大，训练时间长的问题，因此降低特征矩阵维度也是必不可少的。常见的降维方法：主成分分析法（PCA）和线性判别分析（LDA），<strong><span style="color:orange">线性判别分析本身也是一个分类模型</span></strong>。PCA和LDA有很多的相似点，<strong><span style="color:orange">其本质是要将原始的样本映射到维度更低的样本空间中</span></strong>，但是PCA和LDA的映射目标不一样：<strong><span style="color:#00f">PCA是为了让映射后的样本具有最大的发散性；而LDA是为了让映射后的样本有最好的分类性能</span></strong>。所以说PCA是一种无监督的降维方法，而LDA是一种有监督的降维方法。</p><h4 id="主成分分析法（PCA）"><a href="#主成分分析法（PCA）" class="headerlink" title="主成分分析法（PCA）"></a>主成分分析法（PCA）</h4><p>基本思想：构造原变量的一系列线性组合形成几个综合指标，以<strong><span style="color:red">去除数据的相关性</span></strong>，并使低维数据最大程度保持原始高维数据的方差信息。</p><p><strong>主成分个数的确定：</strong></p><ol><li>贡献率：第i个主成分的方差在全部方差中所占比重，反映第i个主成分所提取的总信息的份额。</li><li>累计贡献率：前k个主成分在全部方差中所占比重</li><li>主成分个数的确定：累计贡献率&gt;0.85</li></ol><p><strong>相关系数矩阵or协方差阵？</strong><br>当涉及变量的量纲不同或取值范围相差较大的指标时，应考虑从相关系数矩阵出发进行主成分分析；（相关系数矩阵消除了量纲的影响。）对同度量或取值范围相差不大的数据，从协方差阵出发。</p><p>使用decomposition库的PCA类选择特征的代码如下：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="comment">#主成分分析法，返回降维后的数据</span></span><br><span class="line"><span class="comment">#参数n_components为主成分数目</span></span><br><span class="line">PCA(n_components=<span class="number">2</span>).fit_transform(X) <span class="comment">#X=iris.data（鸢尾花）数据集</span></span><br></pre></td></tr></table></figure></div><p>n_components：</p><ul><li>小数：表示保留百分之多少的信息</li><li>整数：减少到多少特征</li></ul><h4 id="线性判别分析法（LDA）"><a href="#线性判别分析法（LDA）" class="headerlink" title="线性判别分析法（LDA）"></a>线性判别分析法（LDA）</h4><p>至多能把C类数据降维到C-1维子空间</p><p>使用lda库的LDA类选择特征的代码如下：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.lda <span class="keyword">import</span> LDA</span><br><span class="line"><span class="comment">#线性判别分析法，返回降维后的数据</span></span><br><span class="line"><span class="comment">#参数n_components为降维后的维数</span></span><br><span class="line">LDA(n_components=<span class="number">2</span>).fit_transform(X,Y) <span class="comment">#X=iris.data,Y= iris.target（鸢尾花）数据集</span></span><br></pre></td></tr></table></figure></div><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/2.JPG" alt="2"></p><h2 id="分类算法"><a href="#分类算法" class="headerlink" title="分类算法"></a>分类算法</h2><p>分类问题：目标值—类别</p><h3 id="sklearn转换器和估计器"><a href="#sklearn转换器和估计器" class="headerlink" title="sklearn转换器和估计器"></a>sklearn转换器和估计器</h3><h4 id="转换器"><a href="#转换器" class="headerlink" title="转换器"></a>转换器</h4><p>1.实例化 (实例化的是一个转换器类(Transformer))<br>2 调用fit_transform(对于文档建立分类词频矩阵，不能同时调用)<br>标准化：<br>(x - mean) / std<br>fit_transform()<br>fit() #计算 每一列的平均值、标准差<br>transform() # (x - mean) / std进行最终的转换</p><h4 id="估计器"><a href="#估计器" class="headerlink" title="估计器"></a>估计器</h4><h6 id="sklearn机器学习算法的实现"><a href="#sklearn机器学习算法的实现" class="headerlink" title="sklearn机器学习算法的实现"></a>sklearn机器学习算法的实现</h6><p>1、用于分类的估计器：</p><ul><li>sklearn.neighbors k-近邻算法</li><li>sklearn.naive_bayes 贝叶斯</li><li>sklearn.linear_model.LogisticRegression 逻辑回归</li><li>sklearn.tree 决策树与随机森林</li></ul><p>2、用于回归的估计器：</p><ul><li>sklearn.linear_model.LinearRegression 线性回归</li><li>sklearn.linear_model.Ridge 岭回归</li></ul><p>3、用于无监督学习的估计器</p><ul><li>sklearn.cluster.KMeans 聚类</li></ul><h6 id="估计器工作流程"><a href="#估计器工作流程" class="headerlink" title="估计器工作流程"></a>估计器工作流程</h6><p>1、实例化一个estimator</p><p>2、estimator.fit(x_train, y_train) 计算<br>—— 调用完毕，模型生成</p><p>3 模型评估：<br>1）直接比对真实值和预测值<br>y_predict = estimator.predict(x_test)<br>y_test y_predict<br>2）计算准确率<br>accuracy = estimator.score(x_test, y_test)</p><h3 id="K-近邻算法"><a href="#K-近邻算法" class="headerlink" title="K-近邻算法"></a>K-近邻算法</h3><h4 id="K-近邻算法（KNN）"><a href="#K-近邻算法（KNN）" class="headerlink" title="K-近邻算法（KNN）"></a>K-近邻算法（KNN）</h4><p>K-近邻算法(KNN)理论/原理：“物以类聚，人以群分”</p><p>相同/近似样本在样本空间中是比较接近的，所以可以使用和当前样本比较近的其他样本的目标属性值作为当前样本的预测值。</p><p>k-近邻算法的工作机制很简单：</p><p>给定测试样本，基于某种距离度量（一般使用欧几里德距离）找出训练集中与其最靠近的k个训练样本，然后基于这k个“邻居”的信息来进行预测。</p><p>如何确定谁是邻居？</p><p>计算距离：</p><p>距离公式：<br>欧氏距离：<script type="math/tex">d = \sqrt{(x1 - y1)^2 + (x2 - y2)^2 + (x3 - y3)^2 + ……}</script><br>曼哈顿距离—绝对值距离<br>明可夫斯基距离：欧氏距离和曼哈顿距离的推广 metric_params=None</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/123.jpg" alt="123"></p><p>图中<strong><span style="color:red">红线</span></strong>代表曼哈顿距离，<strong><span style="color:green">绿线</span></strong>代表欧氏距离，也就是直线距离，而<strong><span style="color:#00f">蓝线</span></strong>和<strong><span style="color:#ff0">黄线</span></strong>代表等价的曼哈顿距离。</p><h4 id="电影类型分析"><a href="#电影类型分析" class="headerlink" title="电影类型分析"></a>电影类型分析</h4><p>假设我们有现在几部电影</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/电影类型分析.png" alt="电影类型分析"></p><p>其中？ 号电影不知道类别，如何去预测？我们可以利用K近邻算法的思想</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/电影距离计算.png" alt="电影距离计算"></p><p>k = 1 ——&gt;最近距离18.7——&gt;电影为爱情片——&gt;预测？号电影为爱情片<br>k = 2 ——&gt;最近距离18.7和19.2——两部电影都是爱情片——预测？号电影为爱情片<br>……<br>k = 6——&gt; 六部电影爱情片和动作片一样多——&gt;无法确定<br>k = 7 ——&gt;若4部动作片，3部爱情片——&gt;预测？号电影为动作片,但实际电影为爱情片</p><p>如果取的最近的电影数量不一样？会是什么结果？<br>k 值取得过小，容易受到异常点的影响<br>k 值取得过大，样本不均衡的影响</p><h4 id="K-近邻算法API"><a href="#K-近邻算法API" class="headerlink" title="K-近邻算法API"></a>K-近邻算法API</h4><p>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5,weights=’uniform’,algorithm=’auto’,<br>leaf_size=30,p=2,metric=’minkowski’,metric_params=None,n_jobs=None,**kwargs)</p><ul><li>邻居数k: n_neighbors:int,可选(默认= 5)</li><li>权重weights: weights = ‘uniform’ weights = ‘distance’</li><li><p>距离度量: p=1距离度量采用曼哈顿距离；p=2距离度量采用欧氏距离</p></li><li><p>algorithm：{‘auto’，‘ball_tree’，‘kd_tree’，‘brute’}，可选用于计算最近邻居的算法：‘ball_tree’将会使用 BallTree，‘kd_tree’将使用 KDTree。‘auto’将尝试根据传递给fit方法的值来决定最合适的算法。 (不同实现方式影响效率)</p></li></ul><h4 id="案例：鸢尾花种类预测"><a href="#案例：鸢尾花种类预测" class="headerlink" title="案例：鸢尾花种类预测"></a>案例：鸢尾花种类预测</h4><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#1)导入库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="comment">#2)获取数据</span></span><br><span class="line">x,y = datasets.load_iris(<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#3）划分数据集</span></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size  = <span class="number">0.2</span>)</span><br><span class="line"><span class="comment">#4）特征工程：标准化</span></span><br><span class="line">ss=StandardScaler()</span><br><span class="line">x_train=ss.fit_transform(x_train)</span><br><span class="line">x_test=ss.transform(x_test)</span><br><span class="line"><span class="comment">#5)KNN算法预估器(训练数据)</span></span><br><span class="line">estimator=KNeighborsClassifier(n_neighbors=<span class="number">3</span>) <span class="comment">#设置k=3</span></span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line"><span class="comment">#6)模型评估</span></span><br><span class="line"><span class="comment">#方法1：直接比对真实值和预测值</span></span><br><span class="line">y_predict=estimator.predict(x_test)</span><br><span class="line">print(<span class="string">'y_predict:\n'</span>,y_predict)</span><br><span class="line">print(<span class="string">'直接比对真实值和预测值：\n'</span>,y_test  y_predict)</span><br><span class="line"><span class="comment">#方法2：计算准确率</span></span><br><span class="line">score=estimator.score(x_test,y_test)</span><br><span class="line">print(<span class="string">'准确率为：\n'</span>,score)</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">y_predict:</span><br><span class="line"> [<span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line">直接比对真实值和预测值：</span><br><span class="line"> [ <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span></span><br><span class="line">  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span></span><br><span class="line">  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span> <span class="literal">False</span>  <span class="literal">True</span>]</span><br><span class="line">准确率为：</span><br><span class="line"> <span class="number">0.9666666666666667</span></span><br></pre></td></tr></table></figure></div><h4 id="K-近邻总结"><a href="#K-近邻总结" class="headerlink" title="K-近邻总结"></a>K-近邻总结</h4><p>优点：简单，易于理解，易于实现，无需训练<br>缺点：<br>1）必须指定K值，K值选择不当则分类精度不能保证<br>2）懒惰算法，对测试样本分类时的计算量大，内存开销大<br>使用场景：小数据场景，几千～几万样本，具体场景具体业务去测试</p><h3 id="模型选择与调优"><a href="#模型选择与调优" class="headerlink" title="模型选择与调优"></a>模型选择与调优</h3><h4 id="什么是交叉验证-cross-validation"><a href="#什么是交叉验证-cross-validation" class="headerlink" title="什么是交叉验证(cross validation)"></a>什么是交叉验证(cross validation)</h4><p>交叉验证：将拿到的训练数据，分为训练和验证集。以下图为例：将数据分成4份，其中一份作为验证集。然后经过4次(组)的测试，每次都更换不同的验证集。即得到4组模型的结果，取平均值作为最终结果。又称4折交叉验证。</p><ul><li><p>训练集：训练集+验证集</p></li><li><p>测试集：测试集</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/交叉验证过程.png" alt="交叉验证过程"></p></li></ul><h4 id="超参数搜索-网格搜索-Grid-Search"><a href="#超参数搜索-网格搜索-Grid-Search" class="headerlink" title="超参数搜索-网格搜索(Grid Search)"></a>超参数搜索-网格搜索(Grid Search)</h4><p>通常情况下，<strong>有很多参数是需要手动指定的（如k-近邻算法中的K值），这种叫超参数</strong>。但是手动过程繁杂，所以需要对模型预设几种超参数组合。<strong>每组超参数都采用交叉验证来进行评估。最后选出最优参数组合建立模型。</strong></p><h6 id="模型选择与调优-1"><a href="#模型选择与调优-1" class="headerlink" title="模型选择与调优:"></a>模型选择与调优:</h6><p>sklearn.model_selection.GridSearchCV(estimator, param_grid=None,cv=None)</p><ul><li>对估计器的指定参数值进行详尽搜索</li><li>estimator：估计器对象</li><li>param_grid：估计器参数(dict){“n_neighbors”:[1,3,5]}</li><li>cv：指定几折交叉验证</li><li>fit：输入训练数据</li><li>score：准确率</li><li>结果分析：<br>bestscore:在交叉验证中验证的最好结果_<br>bestestimator：最好的参数模型<br>cvresults:每次交叉验证后的验证集准确率结果和训练集准确率结果</li></ul><h4 id="鸢尾花案例调优"><a href="#鸢尾花案例调优" class="headerlink" title="鸢尾花案例调优"></a>鸢尾花案例调优</h4><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="comment"># grid网格，search搜索，cv：cross_validation</span></span><br><span class="line"><span class="comment"># 搜索算法最合适的参数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="comment">#1)获取数据</span></span><br><span class="line">x,y = datasets.load_iris(<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#2）划分数据集</span></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size  = <span class="number">0.2</span>)</span><br><span class="line"><span class="comment">#3）特征工程：标准化</span></span><br><span class="line">ss=StandardScaler()</span><br><span class="line">x_train=ss.fit_transform(x_train)</span><br><span class="line">x_test=ss.transform(x_test)</span><br><span class="line"><span class="comment">#4)KNN算法预估器</span></span><br><span class="line">estimator=KNeighborsClassifier()</span><br><span class="line"><span class="comment">#网格搜索GridSearchCV进行最佳参数的查找</span></span><br><span class="line">params = &#123;<span class="string">'n_neighbors'</span>:[i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">30</span>)],</span><br><span class="line">          <span class="string">'weights'</span>:[<span class="string">'distance'</span>,<span class="string">'uniform'</span>],</span><br><span class="line">          <span class="string">'p'</span>:[<span class="number">1</span>,<span class="number">2</span>]&#125;</span><br><span class="line"><span class="comment"># cross_val_score类似</span></span><br><span class="line">estimator = GridSearchCV(estimator,param_grid=params,scoring=<span class="string">'accuracy'</span>,cv = <span class="number">6</span>)</span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line"><span class="comment">#5)模型评估</span></span><br><span class="line"><span class="comment">#方法1：直接比对真实值和预测值</span></span><br><span class="line">y_predict=estimator.predict(x_test)</span><br><span class="line">print(<span class="string">'y_predict:\n'</span>,y_predict)</span><br><span class="line">print(<span class="string">'直接比对真实值和预测值：\n'</span>,y_test  y_predict)</span><br><span class="line"><span class="comment">#方法2：计算准确率</span></span><br><span class="line">score=estimator.score(x_test,y_test)</span><br><span class="line">print(<span class="string">'准确率为：\n'</span>,score)</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看了GridSearchCV最佳的参数组合</span></span><br><span class="line"><span class="comment">#最佳参数：best_params_</span></span><br><span class="line">print(<span class="string">'最佳参数：\n'</span>,estimator.best_params_)</span><br><span class="line"><span class="comment">#最佳结果：best_score_</span></span><br><span class="line">print(<span class="string">'最佳结果：\n'</span>,estimator.best_score_)</span><br><span class="line"><span class="comment">#最佳估计器：best_estimator_</span></span><br><span class="line">print(<span class="string">'最佳估计器：\n'</span>,estimator.best_estimator_)</span><br><span class="line"><span class="comment">#交叉验证结果：cv_results_</span></span><br><span class="line"><span class="comment">#print('交叉验证结果：\n',estimator.cv_results_)</span></span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">y_predict:</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line">直接比对真实值和预测值：</span><br><span class="line"> [ <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span> <span class="literal">False</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span></span><br><span class="line">  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span> <span class="literal">False</span> <span class="literal">False</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span></span><br><span class="line">  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span> <span class="literal">False</span>  <span class="literal">True</span>]</span><br><span class="line">准确率为：</span><br><span class="line"> <span class="number">0.8666666666666667</span></span><br><span class="line">最佳参数：</span><br><span class="line"> &#123;<span class="string">'n_neighbors'</span>: <span class="number">15</span>, <span class="string">'p'</span>: <span class="number">2</span>, <span class="string">'weights'</span>: <span class="string">'distance'</span>&#125;</span><br><span class="line">最佳结果：</span><br><span class="line"> <span class="number">0.9833333333333333</span></span><br><span class="line">最佳估计器：</span><br><span class="line"> KNeighborsClassifier(algorithm=<span class="string">'auto'</span>, leaf_size=<span class="number">30</span>, metric=<span class="string">'minkowski'</span>,</span><br><span class="line">                     metric_params=<span class="literal">None</span>, n_jobs=<span class="literal">None</span>, n_neighbors=<span class="number">15</span>, p=<span class="number">2</span>,</span><br><span class="line">                     weights=<span class="string">'distance'</span>)</span><br></pre></td></tr></table></figure></div><p>注：最佳结果—训练集再分为训练集+验证集，验证集的效果；准确率—整体测试集的效果。数据集不同</p><h3 id="朴素贝叶斯算法"><a href="#朴素贝叶斯算法" class="headerlink" title="朴素贝叶斯算法"></a>朴素贝叶斯算法</h3><p>朴素贝叶斯分类器是基于概率论的分类模型，其思想是先计算样本的先验概率，然后利用贝叶斯公式测算未知样本属于某个类别的后验概率，最终以最大后验概率对应的类别作为未知样本的预测类别。之所以叫”朴素”，是因为整个形式化过程只做最简单、最原始的假设。</p><h4 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h4><h5 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h5><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/1234.JPG" alt="1234"></p><p>问题：</p><p>1、女神喜欢的概率？ $P(喜欢)=\frac{4}{7}$</p><p>2、职业是程序员并且体型匀称的概率？ $P(程序员，匀称)=\frac{1}{7}$ (联合概率)</p><p>3、在女神喜欢的条件下，职业是程序员的概率？ $P(程序员|喜欢)=\frac{2}{4}=\frac{1}{2}$ （条件概率）</p><p>4、在女神喜欢的条件下，职业是产品，体重是超重的概率？</p><p>​ $P(程序员，超重|喜欢)=\frac{1}{4}$ （联合概率、条件概率）</p><p>相互独立：$P(AB)=P(A)P(B)$&lt;=&gt;事件A与事件B相互独立</p><p>$P(程序员，匀称)=\frac{1}{7}$ $P(程序员)=\frac{3}{7}$ $P(匀称)=\frac{4}{7}$ $P(程序员，匀称)≠P(程序员)P(匀称)$ 不独立</p><p><strong><span style="color:red">贝叶斯公式：</span></strong>$P(A|B)=\frac{P(B|A)P(A)}{P(B)}$</p><p>$P(喜欢|产品经理,超重)=\frac{P(产品经理,超重|喜欢)P(喜欢)}{P(产品经理,超重)}=0$</p><p>朴素? 假设:特征与特征之间是相互独立的</p><p><strong><span style="color:red">朴素贝叶斯算法</span></strong>=朴素+贝叶斯</p><p>$P(喜欢|产品经理,超重)=\frac{P(产品经理,超重|喜欢)P(喜欢)}{P(产品经理,超重)}=\frac{P(产品经理|喜欢)P(超重|喜欢)P(喜欢)}{P(产品经理)P(超重)}=\frac{7}{12}$</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/8d16d796670bb4901c7a4c13ca3aa1fa.jpg" alt="img"></p><h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><p>朴素贝叶斯算法应用场景：文本分类</p><p>公式：$P(C|W)=\frac{P(W|C)P(C)}{P(W)}$</p><p>注：$W$为给定文档的特征值（频数统计，预测文档提供），$C$为文档类别</p><p><strong>公式如果应用在文章分类的场景当中，我们可以这样看：</strong></p><script type="math/tex;mode=display">P(C|F1,F2,…)=\frac{P(F1,F2,…|C)P(C)}{P(F1,F2,…)}</script><p><strong>其中$C$可以是不同类别</strong></p><p>公式分为三个部分：</p><ul><li><p>$P(C)$：每个文档类别的概率(某文档类别数／总文档数量)</p></li><li><p>$P(W|C)$：给定类别下特征（被预测文档中出现的词）的概率</p><p>​ 计算方法：$P(F1│C)=Ni/N $（训练文档中去计算）</p><p>​ $Ni$为该$F1$词在$C$类别所有文档中出现的次数<br>​ $N$为所属类别$C$下的文档所有词出现的次数和</p></li><li><p>$P(F1,F2,…) $预测文档中每个词的概率</p></li></ul><h4 id="常用贝叶斯分类器"><a href="#常用贝叶斯分类器" class="headerlink" title="常用贝叶斯分类器"></a>常用贝叶斯分类器</h4><h5 id="1-高斯贝叶斯分类器"><a href="#1-高斯贝叶斯分类器" class="headerlink" title="1.高斯贝叶斯分类器"></a>1.高斯贝叶斯分类器</h5><p>适用条件：自变量X均为连续的数值型<br>假设条件：自变量X服从高斯正态分布<br>自变量X的条件概率：$P(x_j∣C_i)=\frac{1}{\sqrt{2\pi}\sigma_{ji}}exp(-\frac{(x_j-\mu_{ji})^2}{2\sigma_{ji}^2})$</p><p>其中$x_j$为第$j$个自变量的取值，$μ_{ji}$为训练集中自变量$x_j$属于类别 $C_i$的均值，$σ_{ji}$为训练集中自变量$x_j$属于类别 $C_i$的标准差。</p><h5 id="2-多项式贝叶斯分类器"><a href="#2-多项式贝叶斯分类器" class="headerlink" title="2.多项式贝叶斯分类器"></a>2.多项式贝叶斯分类器</h5><p>适用条件：自变量X均为离散型变量<br>假设条件：自变量X的条件概率服从多项式分布<br>自变量X的条件概率：$P(x_j=x_{jk}∣C_i)=\frac{N_{ik}+\alpha}{N_i+n\alpha}$</p><p>其中$x_{jk}$为自变量$x_j$的第$k$个取值，$N_{ik}$表示因变量为类别$C_i$时自变量$x_j$取值$x_{jk}$的样本个数，$N_i$为类别$C_i$的样本个数，$α$为平滑系数（防止条件概率等于0，通常取1），n为训练文档中统计出的<strong><span style="color:red">特征词</span></strong>个数。</p><h5 id="3-伯努利贝叶斯分类器"><a href="#3-伯努利贝叶斯分类器" class="headerlink" title="3.伯努利贝叶斯分类器"></a>3.伯努利贝叶斯分类器</h5><p>适用条件：自变量X均为0-1二元变量<br>假设条件：自变量X的条件概率服从伯努利分布<br>自变量X的条件概率</p><p>$P(x_j∣C_i)=px_j+(1−p)(1−x_j)$</p><p>其中$x_j$为第$j$个自变量，其取值为0或1；$p$表示类别为$C_i$时自变量取1的概率，可以用经验频率代替</p><p>$p=P(x_j=1∣C_i)=\frac{N_{i1}+α}{N_i+nα}$</p><p>$N_{i1}$表示在类别$C_i$时自变量$x_j$取1的样本量。</p><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><h5 id="1-高斯贝叶斯分类器-1"><a href="#1-高斯贝叶斯分类器-1" class="headerlink" title="1.高斯贝叶斯分类器"></a>1.高斯贝叶斯分类器</h5><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#高斯贝叶斯分类器进行癌症预测</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="comment"># 1、读取数据</span></span><br><span class="line">column_name = [<span class="string">'Sample code number'</span>, <span class="string">'Clump Thickness'</span>, <span class="string">'Uniformity of Cell Size'</span>, <span class="string">'Uniformity of Cell Shape'</span>,</span><br><span class="line">                   <span class="string">'Marginal Adhesion'</span>, <span class="string">'Single Epithelial Cell Size'</span>, <span class="string">'Bare Nuclei'</span>, <span class="string">'Bland Chromatin'</span>,</span><br><span class="line">                   <span class="string">'Normal Nucleoli'</span>, <span class="string">'Mitoses'</span>, <span class="string">'Class'</span>]</span><br><span class="line">data = pd.read_csv(<span class="string">"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data"</span>,</span><br><span class="line">                       names=column_name)</span><br><span class="line"><span class="comment"># 2、数据处理—处理缺失值</span></span><br><span class="line">data = data.replace(to_replace=<span class="string">'?'</span>, value=np.nan)   <span class="comment">#1)替换np.nan</span></span><br><span class="line">data = data.dropna()    <span class="comment">#2)删除缺失值</span></span><br><span class="line">print(data.isnull().any()) <span class="comment">#确认不存在缺失值</span></span><br><span class="line">print(<span class="string">'-----------------------------------'</span>)</span><br><span class="line"><span class="comment"># 取出特征值</span></span><br><span class="line">x = data[column_name[<span class="number">1</span>:<span class="number">10</span>]]  <span class="comment">#x=data.iloc[:,1:-1]</span></span><br><span class="line">y = data[column_name[<span class="number">10</span>]]   <span class="comment">#y=data['Class']</span></span><br><span class="line"><span class="comment">#设置正例和负例</span></span><br><span class="line">y = y.map(&#123;<span class="number">2</span>:<span class="number">0</span>,<span class="number">4</span>:<span class="number">1</span>&#125;)</span><br><span class="line">print(y.value_counts())</span><br><span class="line">print(<span class="string">'-----------------------------------'</span>)</span><br><span class="line"><span class="comment">#3、分割数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.3</span>)</span><br><span class="line"><span class="comment">#4、特征工程—标准化</span></span><br><span class="line">std = StandardScaler()</span><br><span class="line">x_train = std.fit_transform(x_train)</span><br><span class="line">x_test = std.transform(x_test)</span><br><span class="line"><span class="comment">#5、estimator估计器流程</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> naive_bayes</span><br><span class="line"><span class="comment">#调用高斯朴素贝叶斯分类器的“类”</span></span><br><span class="line">gnb = naive_bayes.GaussianNB()</span><br><span class="line"><span class="comment">#模型拟合</span></span><br><span class="line">gnb.fit(x_train,y_train)</span><br><span class="line"><span class="comment">#6、进行预测（模型评估）</span></span><br><span class="line"><span class="comment">#模型在测试数据集上的预测</span></span><br><span class="line">gnb_pred = gnb.predict(x_test)</span><br><span class="line"><span class="comment">#各类别的预测数量</span></span><br><span class="line">print(pd.Series(gnb_pred).value_counts())</span><br><span class="line">print(<span class="string">'-----------------------------------'</span>)</span><br><span class="line"><span class="comment">#导入第三方包</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="comment">#构建混淆矩阵</span></span><br><span class="line">cm = pd.crosstab(gnb_pred,y_test)</span><br><span class="line"><span class="comment">#绘制混淆矩阵图</span></span><br><span class="line">sns.heatmap(cm,annot = <span class="literal">True</span> , cmap = <span class="string">'GnBu'</span> , fmt = <span class="string">'d'</span>)</span><br><span class="line"><span class="comment">#去除x轴和y轴的标签</span></span><br><span class="line">plt.xlabel(<span class="string">'Real'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Predict'</span>)</span><br><span class="line"><span class="comment">#显示图形</span></span><br><span class="line">plt.show()</span><br><span class="line">print(<span class="string">'模型的准确率：\n'</span>,metrics.accuracy_score(y_test,gnb_pred))</span><br><span class="line">print(<span class="string">'模型的评估报告：\n'</span>,metrics.classification_report(y_test,gnb_pred))</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算正例的预测概率，用于生成ROC曲线的数据</span></span><br><span class="line">y_score = gnb.predict_proba(x_test)[:,<span class="number">1</span>]</span><br><span class="line">fpr,tpr,threshold = metrics.roc_curve(y_test,y_score)</span><br><span class="line"><span class="comment">#计算AUC的值</span></span><br><span class="line">roc_auc = metrics.auc(fpr,tpr)</span><br><span class="line"><span class="comment">#绘制面积图</span></span><br><span class="line">plt.stackplot(fpr,tpr,color = <span class="string">'steelblue'</span>,alpha = <span class="number">0.5</span>,edgecolor = <span class="string">'black'</span>)</span><br><span class="line"><span class="comment">#添加边际线</span></span><br><span class="line">plt.plot(fpr,tpr,color= <span class="string">'black'</span>,lw =<span class="number">1</span>)</span><br><span class="line"><span class="comment">#添加对角线</span></span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>],color = <span class="string">'red'</span>,linestyle = <span class="string">'--'</span>)</span><br><span class="line"><span class="comment">#添加文本信息</span></span><br><span class="line">plt.text(<span class="number">0.5</span>,<span class="number">0.3</span>,<span class="string">'ROC curve(area = %0.2f)'</span>% roc_auc)</span><br><span class="line"><span class="comment">#添加x轴与y轴标签</span></span><br><span class="line">plt.xlabel(<span class="string">'1-Specificity'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Sensitivity'</span>)</span><br><span class="line"><span class="comment">#显示图形</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">Sample code number             <span class="literal">False</span></span><br><span class="line">Clump Thickness                <span class="literal">False</span></span><br><span class="line">Uniformity of Cell Size        <span class="literal">False</span></span><br><span class="line">Uniformity of Cell Shape       <span class="literal">False</span></span><br><span class="line">Marginal Adhesion              <span class="literal">False</span></span><br><span class="line">Single Epithelial Cell Size    <span class="literal">False</span></span><br><span class="line">Bare Nuclei                    <span class="literal">False</span></span><br><span class="line">Bland Chromatin                <span class="literal">False</span></span><br><span class="line">Normal Nucleoli                <span class="literal">False</span></span><br><span class="line">Mitoses                        <span class="literal">False</span></span><br><span class="line">Class                          <span class="literal">False</span></span><br><span class="line">dtype: bool</span><br><span class="line">-----------------------------------</span><br><span class="line"><span class="number">0</span>    <span class="number">444</span></span><br><span class="line"><span class="number">1</span>    <span class="number">239</span></span><br><span class="line">Name: Class, dtype: int64</span><br><span class="line">-----------------------------------</span><br><span class="line"><span class="number">0</span>    <span class="number">123</span></span><br><span class="line"><span class="number">1</span>     <span class="number">82</span></span><br><span class="line">dtype: int64</span><br><span class="line">-----------------------------------</span><br><span class="line">模型的准确率：</span><br><span class="line"> <span class="number">0.9707317073170731</span></span><br><span class="line">模型的评估报告：</span><br><span class="line">               precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           <span class="number">0</span>       <span class="number">0.99</span>      <span class="number">0.96</span>      <span class="number">0.98</span>       <span class="number">127</span></span><br><span class="line">           <span class="number">1</span>       <span class="number">0.94</span>      <span class="number">0.99</span>      <span class="number">0.96</span>        <span class="number">78</span></span><br><span class="line"></span><br><span class="line">    accuracy                           <span class="number">0.97</span>       <span class="number">205</span></span><br><span class="line">   macro avg       <span class="number">0.97</span>      <span class="number">0.97</span>      <span class="number">0.97</span>       <span class="number">205</span></span><br><span class="line">weighted avg       <span class="number">0.97</span>      <span class="number">0.97</span>      <span class="number">0.97</span>       <span class="number">205</span></span><br></pre></td></tr></table></figure></div><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/12.png" alt="12"></p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/13.png" alt="13"></p><h5 id="2-多项式贝叶斯分类器-1"><a href="#2-多项式贝叶斯分类器-1" class="headerlink" title="2.多项式贝叶斯分类器"></a>2.多项式贝叶斯分类器</h5><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection,naive_bayes,metrics</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">data=pd.read_csv(<span class="string">r'mushrooms.csv'</span>)</span><br><span class="line">print(data.head())</span><br><span class="line"><span class="comment">#使用factorize函数将字符型数据做因子化处理，将其转换为整数型数据</span></span><br><span class="line"><span class="comment">#factorize函数返回的是两个元素的元组，第一个元素为转换成的数值，第二个元素为数值对应的字符水平</span></span><br><span class="line">columns=data.columns[<span class="number">1</span>:]</span><br><span class="line"><span class="keyword">for</span> column <span class="keyword">in</span> columns:</span><br><span class="line">    data[column]=pd.factorize(data[column])[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#拆分为训练集和测试集</span></span><br><span class="line">x_train,x_test,y_train,y_test=model_selection.train_test_split(data[columns],data.type,test_size=<span class="number">0.25</span>,random_state=<span class="number">1234</span>)</span><br><span class="line"><span class="comment">#调用多项式朴素贝叶斯</span></span><br><span class="line">mnb=naive_bayes.MultinomialNB()</span><br><span class="line">mnb.fit(x_train,y_train)</span><br><span class="line">mnb_pred=mnb.predict(x_test)</span><br><span class="line"><span class="comment">#显示预测结果，各类别的预测数量</span></span><br><span class="line"><span class="comment">#模型检验</span></span><br><span class="line">print(<span class="string">'模型的准确率为：'</span>,metrics.accuracy_score(y_test,mnb_pred))</span><br><span class="line">print(<span class="string">'模型的评估报告：\n'</span>,metrics.classification_report(y_test,mnb_pred))</span><br><span class="line"><span class="comment">#绘制ROC曲线</span></span><br><span class="line">y_score=mnb.predict_proba(x_test)[:,<span class="number">1</span>]</span><br><span class="line">fpr,tpr,threshold=metrics.roc_curve(y_test.map(&#123;<span class="string">'e'</span>:<span class="number">0</span>,<span class="string">'p'</span>:<span class="number">1</span>&#125;),y_score)</span><br><span class="line">roc_auc=metrics.auc(fpr,tpr)</span><br><span class="line">plt.stackplot(fpr,tpr,color=<span class="string">'steelblue'</span>,alpha=<span class="number">0.5</span>,edgecolor=<span class="string">'black'</span>)</span><br><span class="line">plt.plot(fpr,tpr,color=<span class="string">'black'</span>,lw=<span class="number">1</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>],color=<span class="string">'red'</span>,linestyle=<span class="string">'--'</span>)</span><br><span class="line">plt.text(<span class="number">0.5</span>,<span class="number">0.3</span>,<span class="string">'ROC Curve (area=%0.2f)'</span> % roc_auc)</span><br><span class="line">plt.xlabel(<span class="string">'l-Specificity'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Sensitivity'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">  type cap-shape cap-surface  ... spore-<span class="keyword">print</span>-color population habitat</span><br><span class="line"><span class="number">0</span>    p         x           s  ...                 k          s       u</span><br><span class="line"><span class="number">1</span>    e         x           s  ...                 n          n       g</span><br><span class="line"><span class="number">2</span>    e         b           s  ...                 n          n       m</span><br><span class="line"><span class="number">3</span>    p         x           y  ...                 k          s       u</span><br><span class="line"><span class="number">4</span>    e         x           s  ...                 n          a       g</span><br><span class="line"></span><br><span class="line">[<span class="number">5</span> rows x <span class="number">23</span> columns]</span><br><span class="line">模型的准确率为： <span class="number">0.8877400295420975</span></span><br><span class="line">模型的评估报告：</span><br><span class="line">               precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           e       <span class="number">0.85</span>      <span class="number">0.95</span>      <span class="number">0.89</span>      <span class="number">1017</span></span><br><span class="line">           p       <span class="number">0.94</span>      <span class="number">0.83</span>      <span class="number">0.88</span>      <span class="number">1014</span></span><br><span class="line"></span><br><span class="line">    accuracy                           <span class="number">0.89</span>      <span class="number">2031</span></span><br><span class="line">   macro avg       <span class="number">0.89</span>      <span class="number">0.89</span>      <span class="number">0.89</span>      <span class="number">2031</span></span><br><span class="line">weighted avg       <span class="number">0.89</span>      <span class="number">0.89</span>      <span class="number">0.89</span>      <span class="number">2031</span></span><br></pre></td></tr></table></figure></div><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/Figure_1-1583391690020.png" alt="Figure_1"></p><h5 id="3-伯努利贝叶斯分类器-1"><a href="#3-伯努利贝叶斯分类器-1" class="headerlink" title="3.伯努利贝叶斯分类器"></a>3.伯努利贝叶斯分类器</h5><p>未完待续</p><h4 id="案例：新闻分类"><a href="#案例：新闻分类" class="headerlink" title="案例：新闻分类"></a>案例：新闻分类</h4><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#朴素贝叶斯对新闻数据集进行预测</span></span><br><span class="line"><span class="comment">#1）导入库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_20newsgroups</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="comment">#2）获取新闻的数据，20个类别</span></span><br><span class="line">news = fetch_20newsgroups(subset=<span class="string">'all'</span>)</span><br><span class="line"><span class="comment">#3）进行数据集分割</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(news.data, news.target, test_size=<span class="number">0.3</span>)</span><br><span class="line"><span class="comment">#4）对于文本数据，进行特征抽取</span></span><br><span class="line">tf = TfidfVectorizer()</span><br><span class="line">x_train = tf.fit_transform(x_train)</span><br><span class="line"><span class="comment">#这里打印出来的列表是：训练集当中的所有不同词的组成的一个列表</span></span><br><span class="line">print(tf.get_feature_names())</span><br><span class="line"><span class="comment"># print(x_train.toarray())</span></span><br><span class="line">x_test = tf.transform(x_test) <span class="comment"># 不需要fit_transform</span></span><br><span class="line"><span class="comment">#5）estimator估计器流程</span></span><br><span class="line">mnb = MultinomialNB(alpha=<span class="number">1.0</span>) <span class="comment">#默认alpha=1.0</span></span><br><span class="line">mnb.fit(x_train, y_train)</span><br><span class="line"><span class="comment">#6）进行预测（模型评估）</span></span><br><span class="line">y_predict = mnb.predict(x_test)</span><br><span class="line">print(<span class="string">'预测每篇文章的类别：\n'</span>, y_predict[:<span class="number">100</span>])</span><br><span class="line">print(<span class="string">'真实类别为：\n'</span>, y_test[:<span class="number">100</span>])</span><br><span class="line">print(<span class="string">'模型预测的准确率为：\n'</span>, mnb.score(x_test, y_test))</span><br><span class="line"><span class="comment">#print('模型预测的准确率为：\n',metrics.accuracy_score(y_test,y_predict))</span></span><br><span class="line"><span class="comment">#混淆矩阵</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">print(<span class="string">'模型的评估报告：\n'</span>,classification_report(y_test,y_predict))</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">[<span class="string">'00'</span>, <span class="string">'000'</span>, <span class="string">'0000'</span>, <span class="string">'00000'</span>, <span class="string">'000000'</span>, <span class="string">'00000000'</span>, <span class="string">'0000000004'</span>, <span class="string">'0000000005'</span>, <span class="string">'00000000b'</span>, <span class="string">'00000001'</span>, <span class="string">'00000001b'</span>, <span class="string">'00000010'</span>,  ···································································   <span class="string">'zzrk'</span>, <span class="string">'zzs'</span>, <span class="string">'zzt'</span>, <span class="string">'zzvsi'</span>, <span class="string">'zzx'</span>, <span class="string">'zzy_3w'</span>, <span class="string">'zzzzzz'</span>, <span class="string">'zzzzzzt'</span>, <span class="string">'³ation'</span>, <span class="string">'íålittin'</span>, <span class="string">'ñaustin'</span>, <span class="string">'ýé'</span>, <span class="string">'ÿhooked'</span>]</span><br><span class="line">预测每篇文章的类别：</span><br><span class="line"> [<span class="number">16</span>  <span class="number">7</span>  <span class="number">2</span>  <span class="number">4</span> <span class="number">10</span>  <span class="number">3</span> <span class="number">18</span>  <span class="number">7</span>  <span class="number">8</span> <span class="number">12</span>  <span class="number">0</span> <span class="number">13</span> <span class="number">11</span> <span class="number">11</span>  <span class="number">0</span> <span class="number">15</span> <span class="number">18</span> <span class="number">10</span> <span class="number">12</span>  <span class="number">8</span> <span class="number">12</span>  <span class="number">2</span> <span class="number">15</span>  <span class="number">7</span></span><br><span class="line">  <span class="number">9</span> <span class="number">12</span> <span class="number">15</span> <span class="number">16</span>  <span class="number">9</span>  <span class="number">0</span>  <span class="number">3</span> <span class="number">15</span>  <span class="number">8</span>  <span class="number">3</span> <span class="number">14</span> <span class="number">17</span>  <span class="number">1</span>  <span class="number">0</span> <span class="number">15</span> <span class="number">16</span>  <span class="number">9</span>  <span class="number">2</span>  <span class="number">3</span>  <span class="number">6</span>  <span class="number">5</span>  <span class="number">4</span>  <span class="number">6</span> <span class="number">14</span></span><br><span class="line">  <span class="number">8</span>  <span class="number">9</span> <span class="number">13</span>  <span class="number">9</span> <span class="number">11</span> <span class="number">12</span> <span class="number">10</span> <span class="number">10</span>  <span class="number">3</span> <span class="number">11</span> <span class="number">11</span>  <span class="number">0</span>  <span class="number">6</span> <span class="number">12</span> <span class="number">15</span>  <span class="number">3</span> <span class="number">15</span>  <span class="number">6</span>  <span class="number">5</span>  <span class="number">1</span>  <span class="number">9</span> <span class="number">14</span> <span class="number">10</span>  <span class="number">3</span></span><br><span class="line">  <span class="number">7</span> <span class="number">11</span>  <span class="number">0</span>  <span class="number">3</span>  <span class="number">7</span> <span class="number">16</span> <span class="number">13</span>  <span class="number">9</span>  <span class="number">5</span> <span class="number">15</span>  <span class="number">1</span> <span class="number">13</span> <span class="number">15</span> <span class="number">16</span>  <span class="number">7</span>  <span class="number">4</span>  <span class="number">1</span> <span class="number">16</span> <span class="number">16</span> <span class="number">18</span> <span class="number">14</span> <span class="number">15</span>  <span class="number">7</span> <span class="number">16</span></span><br><span class="line"> <span class="number">15</span> <span class="number">14</span>  <span class="number">0</span> <span class="number">14</span>]</span><br><span class="line">真实类别为：</span><br><span class="line"> [<span class="number">19</span>  <span class="number">7</span>  <span class="number">2</span>  <span class="number">4</span> <span class="number">10</span>  <span class="number">3</span> <span class="number">18</span>  <span class="number">3</span>  <span class="number">8</span> <span class="number">12</span>  <span class="number">0</span> <span class="number">13</span> <span class="number">11</span> <span class="number">11</span>  <span class="number">0</span>  <span class="number">0</span> <span class="number">18</span> <span class="number">10</span> <span class="number">12</span> <span class="number">15</span> <span class="number">12</span>  <span class="number">2</span> <span class="number">15</span>  <span class="number">7</span></span><br><span class="line">  <span class="number">9</span> <span class="number">12</span> <span class="number">15</span> <span class="number">16</span>  <span class="number">9</span>  <span class="number">0</span>  <span class="number">3</span> <span class="number">15</span>  <span class="number">8</span>  <span class="number">3</span> <span class="number">14</span> <span class="number">17</span>  <span class="number">1</span>  <span class="number">0</span> <span class="number">15</span> <span class="number">16</span>  <span class="number">9</span>  <span class="number">2</span>  <span class="number">3</span>  <span class="number">8</span>  <span class="number">5</span>  <span class="number">4</span>  <span class="number">6</span> <span class="number">14</span></span><br><span class="line">  <span class="number">8</span>  <span class="number">9</span> <span class="number">13</span>  <span class="number">9</span> <span class="number">11</span> <span class="number">12</span> <span class="number">10</span> <span class="number">10</span>  <span class="number">3</span> <span class="number">11</span> <span class="number">11</span>  <span class="number">0</span>  <span class="number">6</span> <span class="number">12</span>  <span class="number">0</span>  <span class="number">3</span>  <span class="number">0</span>  <span class="number">6</span>  <span class="number">5</span>  <span class="number">1</span>  <span class="number">9</span> <span class="number">14</span> <span class="number">12</span>  <span class="number">6</span></span><br><span class="line">  <span class="number">8</span> <span class="number">12</span>  <span class="number">0</span>  <span class="number">3</span>  <span class="number">7</span> <span class="number">18</span> <span class="number">13</span>  <span class="number">9</span>  <span class="number">5</span> <span class="number">15</span>  <span class="number">1</span> <span class="number">13</span> <span class="number">15</span> <span class="number">16</span>  <span class="number">7</span>  <span class="number">4</span>  <span class="number">1</span> <span class="number">16</span> <span class="number">18</span> <span class="number">18</span> <span class="number">14</span> <span class="number">15</span>  <span class="number">7</span> <span class="number">13</span></span><br><span class="line"> <span class="number">15</span>  <span class="number">1</span>  <span class="number">0</span> <span class="number">14</span>]</span><br><span class="line">模型预测的准确率为：</span><br><span class="line"> <span class="number">0.8593915811814644</span></span><br><span class="line">    模型的评估报告：</span><br><span class="line">               precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           <span class="number">0</span>       <span class="number">0.89</span>      <span class="number">0.76</span>      <span class="number">0.82</span>       <span class="number">235</span></span><br><span class="line">           <span class="number">1</span>       <span class="number">0.93</span>      <span class="number">0.72</span>      <span class="number">0.81</span>       <span class="number">320</span></span><br><span class="line"> ···································································</span><br><span class="line">          <span class="number">18</span>       <span class="number">0.99</span>      <span class="number">0.63</span>      <span class="number">0.77</span>       <span class="number">235</span></span><br><span class="line">          <span class="number">19</span>       <span class="number">1.00</span>      <span class="number">0.21</span>      <span class="number">0.35</span>       <span class="number">177</span></span><br><span class="line"></span><br><span class="line">    accuracy                           <span class="number">0.86</span>      <span class="number">5654</span></span><br><span class="line">   macro avg       <span class="number">0.88</span>      <span class="number">0.84</span>      <span class="number">0.84</span>      <span class="number">5654</span></span><br><span class="line">weighted avg       <span class="number">0.88</span>      <span class="number">0.86</span>      <span class="number">0.85</span>      <span class="number">5654</span></span><br></pre></td></tr></table></figure></div><h4 id="朴素贝叶斯总结"><a href="#朴素贝叶斯总结" class="headerlink" title="朴素贝叶斯总结"></a>朴素贝叶斯总结</h4><ul><li>优点：<ul><li>朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。</li><li>对缺失数据不太敏感，算法也比较简单，常用于文本分类。</li><li>分类准确度高，速度快</li></ul></li><li>缺点：<ul><li>由于使用了样本属性独立性的假设，所以如果特征属性有关联时其效果不好</li></ul></li></ul><h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><h4 id="认识决策树"><a href="#认识决策树" class="headerlink" title="认识决策树"></a>认识决策树</h4><p>​ 如何高效的进行决策？<br>​ 特征的先后顺序</p><h4 id="决策树分类原理详解"><a href="#决策树分类原理详解" class="headerlink" title="决策树分类原理详解"></a>决策树分类原理详解</h4><p>​ 已知 四个特征值 预测 是否贷款给某个人<br>​ 先看房子，再工作 -&gt; 是否贷款 只看了两个特征<br>​ 年龄，信贷情况，工作 看了三个特征</p><h5 id="信息论基础"><a href="#信息论基础" class="headerlink" title="信息论基础"></a>信息论基础</h5><p>1）<strong>信息</strong>：消除随机不确定性的东西<br>小明：“我今年18岁” - 信息<br>小华： ”小明明年19岁” - 不是信息(当小明告诉我他今年18岁，这就消除了对小明年龄的不确定性)<br>2）<strong>信息的衡量标准</strong> - <strong><span style="color:red">熵</span></strong><br>熵：表示随机变量不确定性的度量 熵单位为比特（bit）</p><p>（解释：说白了就是物体内部的混乱程度，比如杂货市场里面什么都有那肯定混乱，专卖店里面只卖一个牌子那就稳定多了）<br>公式：</p><script type="math/tex;mode=display">H（D）=-\sum_{i=1}^{n} p(x i) * \log _{2} p(x i)</script><p>熵：不确定性越大，得到的熵值也就越大</p><p>3）<strong>决策树的划分依据之一</strong>———<strong><span style="color:red">信息增益</span></strong></p><p>特征A对训练数据集D的信息增益$g(D,A)$,定义为集合D的熵$H(D)$与特征A给定条件下D的信息条件熵$H(D|A)$之差，即公式为：<script type="math/tex">g(D,A)=H(D)-H(D|A)</script></p><p>公式的详细解释：</p><p>熵的计算：<script type="math/tex">H(D)=-\sum_{k=1}^{K} \frac{\left|C_{k}\right|}{|D|} \log_{2} \frac{\left|C_{k}\right|}{|D|}</script></p><p>条件熵的计算公式：<script type="math/tex">H(D | A)=\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} H\left(D_{i}\right)=-\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} \sum_{k=1}^{K} \frac{\left|D_{i k}\right|}{\left|D_{i}\right|} \log_{2} \frac{\left|D_{i k}\right|}{\left|D_{i}\right|}</script></p><p>注：$C_{k}$表示属于某个类别的样本数</p><p>注：信息增益表示得知特征X的信息而信息的不确定性减少的程度使得类Y的信息熵减少的程度</p><p><strong>例子</strong></p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/银行贷款数据.png" alt="银行贷款数据"></p><p>根据某人年龄、工作、房子和信贷情况，判断是否贷款？</p><p>在历史数据中（15次贷款）有6次没贷款，9次贷款，所以此时的熵应为：</p><script type="math/tex;mode=display">H(D)=-(\frac{6}{15}*log_{2}\frac{6}{15}+\frac{9}{15}*log_{2}\frac{9}{15})=0.971</script><p>$H(青年)=-(\frac{2}{5}<em>log_{2}\frac{2}{5}+\frac{3}{5}</em>log_{2}\frac{3}{5})=0.971$</p><p>$H(中年)=-(\frac{2}{5}<em>log_{2}\frac{2}{5}+\frac{3}{5}</em>log_{2}\frac{3}{5})=0.971$</p><p>$H(老年)=-(\frac{1}{5}<em>log_{2}\frac{1}{5}+\frac{4}{5}</em>log_{2}\frac{4}{5})=0.722$</p><p>$H(D|年龄)=\frac{5}{15}H(青年)+\frac{5}{15}H(中年)+\frac{5}{15}H(老年)=0.888$</p><p>$g(D,年龄)=H(D)-H(D|年龄)=0.083$ 注：别人计算为0.313</p><p>我们以A1、A2、A3、A4代表年龄、有工作、有自己的房子和贷款情况。最终计算的结果g(D, A1) = 0.313, g(D, A2) = 0.324, g(D, A3) = 0.420,g(D, A4) = 0.363。所以我们选择A3 作为划分的第一个特征。这样我们就可以一棵树慢慢建立</p><h4 id="决策树的三种算法实现"><a href="#决策树的三种算法实现" class="headerlink" title="决策树的三种算法实现"></a>决策树的三种算法实现</h4><p>当然决策树的原理不止信息增益这一种，还有其他方法。但是原理都类似，我们就不去举例计算。</p><ul><li><p>ID3</p><p>信息增益 最大的准则</p></li><li><p>C4.5</p><p>信息增益比 最大的准则</p></li><li><p>CART<br>分类树: 基尼系数 最小的准则 在sklearn中可以选择划分的默认原则<br>优势：划分更加细致（从后面例子的树显示来理解）</p></li></ul><h4 id="决策树算法API"><a href="#决策树算法API" class="headerlink" title="决策树算法API"></a>决策树算法API</h4><p>class sklearn.tree.DecisionTreeClassifier(criterion=’gini’, max_depth=None,random_state=None)<br>决策树分类器</p><ul><li><p>criterion:默认是’gini’系数，也可以选择信息增益的熵’entropy’</p></li><li><p>max_depth:树的深度大小</p></li><li><p>random_state:随机数种子</p></li><li>其中会有些超参数：max_depth:树的深度大小</li></ul><p>其它超参数我们会结合随机森林讲解</p><h4 id="案例1：鸢尾花种类预测"><a href="#案例1：鸢尾花种类预测" class="headerlink" title="案例1：鸢尾花种类预测"></a>案例1：鸢尾花种类预测</h4><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#决策树对鸢尾花进行分类</span></span><br><span class="line"><span class="comment">#1)导入库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="comment">#2)获取数据</span></span><br><span class="line">x,y = datasets.load_iris(<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#3）划分数据集</span></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size  = <span class="number">0.2</span>)</span><br><span class="line"><span class="comment">#决策树不需要特征工程：标准化</span></span><br><span class="line"><span class="comment">#4)决策树算法预估器(训练数据)</span></span><br><span class="line">estimator=DecisionTreeClassifier(criterion=<span class="string">'entropy'</span>)</span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line"><span class="comment">#5)模型评估</span></span><br><span class="line"><span class="comment">#方法1：直接比对真实值和预测值</span></span><br><span class="line">y_predict=estimator.predict(x_test)</span><br><span class="line">print(<span class="string">'y_predict:\n'</span>,y_predict)</span><br><span class="line">print(<span class="string">'直接比对真实值和预测值：\n'</span>,y_test  y_predict)</span><br><span class="line"><span class="comment">#方法2：计算准确率</span></span><br><span class="line">score=estimator.score(x_test,y_test)</span><br><span class="line">print(<span class="string">'准确率为：\n'</span>,score)</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">y_predict:</span><br><span class="line"> [<span class="number">1</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span>]</span><br><span class="line">直接比对真实值和预测值：</span><br><span class="line"> [ <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span> <span class="literal">False</span>  <span class="literal">True</span>  <span class="literal">True</span> <span class="literal">False</span>  <span class="literal">True</span></span><br><span class="line">  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span> <span class="literal">False</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span></span><br><span class="line">  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>  <span class="literal">True</span>]</span><br><span class="line">准确率为：</span><br><span class="line"> <span class="number">0.9</span></span><br></pre></td></tr></table></figure></div><p>注：比对kNN算法准确率低；由于鸢尾花数据少，而kNN算法使用场景为小数据场景</p><h4 id="决策树可视化"><a href="#决策树可视化" class="headerlink" title="决策树可视化"></a>决策树可视化</h4><p>1、sklearn.tree.export_graphviz() 该函数能够导出DOT格式</p><p>tree.export_graphviz(estimator,out_file=’tree.dot’,feature_names=[‘’,’’])</p><p>2、工具:(能够将dot文件转换为pdf、png)</p><p>安装graphviz</p><p>ubuntu:sudo apt-get install graphviz Mac:brew install graphviz</p><p>3、运行命令</p><p>然后我们运行这个命令</p><p>dot -Tpng tree.dot -o tree.png</p><p>以上文鸢尾花数据为例：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> export_graphviz</span><br><span class="line">export_graphviz(estimator,out_file=<span class="string">'iris_tree.dot'</span>,feature_names=iris.feature_names)</span><br></pre></td></tr></table></figure></div><p>导出文档iris_tree.dot，打开文档全选复制，粘贴到<a href="http://www.webgraphviz.com/网页版上可以实现可视化。无需安装软件。" target="_blank" rel="noopener external nofollow noreferrer">http://www.webgraphviz.com/网页版上可以实现可视化。无需安装软件。</a></p><h4 id="案例：泰坦尼克号乘客生存预测"><a href="#案例：泰坦尼克号乘客生存预测" class="headerlink" title="案例：泰坦尼克号乘客生存预测"></a>案例：泰坦尼克号乘客生存预测</h4><p>泰坦尼克号数据<br>在泰坦尼克号和titanic2数据帧描述泰坦尼克号上的个别乘客的生存状态。这里使用的数据集是由各种研究人员开始的。其中包括许多研究人员创建的旅客名单，由Michael A. Findlay编辑。我们提取的数据集中的特征是票的类别，存活，乘坐班，年龄，登陆，home.dest，房间，票，船和性别。</p><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#决策树进行乘客生存预测</span></span><br><span class="line"><span class="comment">#1、导入库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier,export_graphviz</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="comment">#2、获取数据</span></span><br><span class="line">titan = pd.read_csv(<span class="string">"http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt"</span>)</span><br><span class="line"><span class="comment">#3、数据的处理</span></span><br><span class="line">x = titan[[<span class="string">'pclass'</span>, <span class="string">'age'</span>, <span class="string">'sex'</span>]]</span><br><span class="line">y = titan[<span class="string">'survived'</span>]</span><br><span class="line"><span class="comment"># ①缺失值处理，将特征当中有类别的这些特征进行字典特征抽取</span></span><br><span class="line">x[<span class="string">'age'</span>].fillna(x[<span class="string">'age'</span>].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># ②对于x转换成字典数据</span></span><br><span class="line">x=x.to_dict(orient=<span class="string">"records"</span>) <span class="comment"># [&#123;"pclass": "1st", "age": 29.00, "sex": "female"&#125;, &#123;&#125;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#4、划分数据集</span></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size  = <span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#5、字典特征抽取</span></span><br><span class="line">transfer = DictVectorizer()</span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test=transfer.transform(x_test) <span class="comment">#不需要调用fit_transform</span></span><br><span class="line">print(transfer.get_feature_names())</span><br><span class="line">print(<span class="string">'-----------------------------------------------------'</span>)</span><br><span class="line"><span class="comment">#print(x)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#决策树不需要特征工程：标准化</span></span><br><span class="line"><span class="comment">#6、决策树算法预估器(训练数据)</span></span><br><span class="line">estimator=DecisionTreeClassifier(criterion=<span class="string">'entropy'</span>)</span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line"><span class="comment">#7、模型评估</span></span><br><span class="line"><span class="comment">#方法1：直接比对真实值和预测值</span></span><br><span class="line">y_predict=estimator.predict(x_test)</span><br><span class="line">print(<span class="string">'y_predict:\n'</span>,y_predict)</span><br><span class="line">print(<span class="string">'-----------------------------------------------------'</span>)</span><br><span class="line">print(<span class="string">'直接比对真实值和预测值：\n'</span>,y_test  y_predict)</span><br><span class="line">print(<span class="string">'-----------------------------------------------------'</span>)</span><br><span class="line"><span class="comment">#方法2：计算准确率</span></span><br><span class="line">score=estimator.score(x_test,y_test)</span><br><span class="line">print(<span class="string">'准确率为：\n'</span>,score)</span><br><span class="line"><span class="comment">#8、可视化导出titan_tree.dot文档</span></span><br><span class="line">export_graphviz(estimator,out_file=<span class="string">'titan_tree.dot'</span>,feature_names=transfer.get_feature_names())</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">[<span class="string">'age'</span>, <span class="string">'pclass=1st'</span>, <span class="string">'pclass=2nd'</span>, <span class="string">'pclass=3rd'</span>, <span class="string">'sex=female'</span>, <span class="string">'sex=male'</span>]</span><br><span class="line">-----------------------------------------------------</span><br><span class="line">y_predict:</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span></span><br><span class="line"> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span></span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line">-----------------------------------------------------</span><br><span class="line">直接比对真实值和预测值：</span><br><span class="line"> <span class="number">199</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">1308</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">814</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">393</span>     <span class="literal">False</span></span><br><span class="line"><span class="number">560</span>      <span class="literal">True</span></span><br><span class="line">        ...  </span><br><span class="line"><span class="number">955</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">147</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">30</span>       <span class="literal">True</span></span><br><span class="line"><span class="number">923</span>     <span class="literal">False</span></span><br><span class="line"><span class="number">404</span>      <span class="literal">True</span></span><br><span class="line">Name: survived, Length: <span class="number">263</span>, dtype: bool</span><br><span class="line">-----------------------------------------------------</span><br><span class="line">准确率为：</span><br><span class="line"> <span class="number">0.779467680608365</span></span><br></pre></td></tr></table></figure></div><h4 id="决策树总结"><a href="#决策树总结" class="headerlink" title="决策树总结"></a>决策树总结</h4><p>优点：可视化 - 可解释能力强<br>缺点：容易产生过拟合</p><p>改进：</p><ul><li>减枝cart算法(决策树API当中已经实现，随机森林参数调优有相关介绍)</li><li><strong>随机森林</strong></li></ul><h3 id="集成学习方法之随机森林"><a href="#集成学习方法之随机森林" class="headerlink" title="集成学习方法之随机森林"></a>集成学习方法之随机森林</h3><h4 id="什么是集成学习方法"><a href="#什么是集成学习方法" class="headerlink" title="什么是集成学习方法"></a>什么是集成学习方法</h4><p>集成学习通过建立几个模型组合的来解决单一预测问题。它的工作原理是<strong>生成多个分类器/模型</strong>，各自独立地学习和作出预测。<strong>这些预测最后结合成组合预测，因此优于任何一个单分类的做出预测。</strong></p><h4 id="什么是随机森林"><a href="#什么是随机森林" class="headerlink" title="什么是随机森林"></a>什么是随机森林</h4><p>在机器学习中，<strong>随机森林是一个包含多个决策树的分类器</strong>，并且其输出的类别是由个别树输出的类别的众数而定。</p><h4 id="随机森林原理过程"><a href="#随机森林原理过程" class="headerlink" title="随机森林原理过程"></a>随机森林原理过程</h4><p>训练集：特征值 +目标值 N个样本 M个特征</p><h6 id="两个随机"><a href="#两个随机" class="headerlink" title="两个随机"></a>两个随机</h6><p>训练集随机 - N个样本中随机有放回的抽样N个<br>bootstrap(随机有放回抽样)<br>[1, 2, 3, 4, 5]经过随机有放回抽样得到新的树的训练 [2, 2, 3, 1, 5]</p><p>特征随机 - 从M个特征中随机抽取m个特征<br>​ 要求：M &gt;&gt; m 效果：降维</p><h4 id="随机森林算法API"><a href="#随机森林算法API" class="headerlink" title="随机森林算法API"></a>随机森林算法API</h4><p>class sklearn.ensemble.RandomForestClassifier(n_estimators=10, criterion=’gini’, max_depth=None, bootstrap=True, random_state=None, min_samples_split=2)</p><p><strong>随机森林分类器</strong></p><ul><li><p>n_estimators：integer，optional（default = 10）森林里的树木数量120,200,300,500,800,1200</p></li><li><p>criterian：string，可选（default =“gini”）分割特征的测量方法</p></li><li><p>max_depth：integer或None，可选（默认=无）树的最大深度 5,8,15,25,30</p></li><li><p>max_features=”auto”,每个决策树的最大特征数量</p><p>​ If “auto”, then max_features=sqrt(n_features). 对M求平方根<br>​ If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).<br>​ If “log2”, then max_features=log2(n_features).<br>​ If None, then max_features=n_features.</p></li><li><p>bootstrap：boolean，optional（default = True） 是否在构建树时使用放回抽样</p></li><li>min_samples_split:节点划分最少样本数</li><li>min_samples_leaf:叶子节点的最小样本数</li></ul><p><strong>超参数</strong>：n_estimator, max_depth, min_samples_split,min_samples_leaf</p><h4 id="案例：泰坦尼克号乘客生存预测-1"><a href="#案例：泰坦尼克号乘客生存预测-1" class="headerlink" title="案例：泰坦尼克号乘客生存预测"></a>案例：泰坦尼克号乘客生存预测</h4><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#复制上文中决策树代码比对决策树与随机森林效果</span></span><br><span class="line"><span class="comment">#随机森林进行乘客生存预测</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line">estimator= RandomForestClassifier()</span><br><span class="line"><span class="comment"># grid网格，search搜索，cv：cross_validation</span></span><br><span class="line"><span class="comment"># 搜索算法最合适的参数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="comment">#网格搜索GridSearchCV进行最佳参数的查找</span></span><br><span class="line">params =&#123;<span class="string">"n_estimators"</span>: [<span class="number">120</span>,<span class="number">200</span>,<span class="number">300</span>,<span class="number">500</span>,<span class="number">800</span>,<span class="number">1200</span>], <span class="string">"max_depth"</span>: [<span class="number">5</span>, <span class="number">8</span>, <span class="number">15</span>, <span class="number">25</span>, <span class="number">30</span>]&#125;</span><br><span class="line"><span class="comment"># cross_val_score类似</span></span><br><span class="line">estimator = GridSearchCV(estimator,param_grid=params,cv = <span class="number">6</span>)</span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"><span class="comment">#模型评估</span></span><br><span class="line"><span class="comment">#方法1：直接比对真实值和预测值</span></span><br><span class="line">y_predict=estimator.predict(x_test)</span><br><span class="line">print(<span class="string">'---------------以下为随机森林预测效果-----------------'</span>)</span><br><span class="line">print(<span class="string">'y_predict:\n'</span>,y_predict)</span><br><span class="line">print(<span class="string">'随机森林预测的直接比对真实值和预测值：\n'</span>,y_test  y_predict)</span><br><span class="line">print(<span class="string">'-----------------------------------------------------'</span>)</span><br><span class="line"><span class="comment">#方法2：计算准确率</span></span><br><span class="line">score=estimator.score(x_test,y_test)</span><br><span class="line">print(<span class="string">'随机森林预测的准确率为：\n'</span>,score)</span><br><span class="line">print(<span class="string">'-----------------------------------------------------'</span>)</span><br><span class="line"><span class="comment">#查看了GridSearchCV最佳的参数组合</span></span><br><span class="line"><span class="comment">#最佳参数：best_params_</span></span><br><span class="line">print(<span class="string">'最佳参数：\n'</span>,estimator.best_params_)</span><br><span class="line"><span class="comment">#最佳结果：best_score_</span></span><br><span class="line">print(<span class="string">'最佳结果：\n'</span>,estimator.best_score_)</span><br><span class="line"><span class="comment">#最佳估计器：best_estimator_</span></span><br><span class="line">print(<span class="string">'最佳估计器：\n'</span>,estimator.best_estimator_)</span><br><span class="line"><span class="comment">#交叉验证结果：cv_results_</span></span><br><span class="line"><span class="comment">#print('交叉验证结果：\n',estimator.cv_results_)</span></span><br></pre></td></tr></table></figure></div><p>输出结果：注：随机森林输出结果等待时间长</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#决策树输出结果：</span></span><br><span class="line">[<span class="string">'age'</span>, <span class="string">'pclass=1st'</span>, <span class="string">'pclass=2nd'</span>, <span class="string">'pclass=3rd'</span>, <span class="string">'sex=female'</span>, <span class="string">'sex=male'</span>]</span><br><span class="line">-----------------------------------------------------</span><br><span class="line">y_predict:</span><br><span class="line"> [<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span></span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span></span><br><span class="line"> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span></span><br><span class="line"> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">-----------------------------------------------------</span><br><span class="line">直接比对真实值和预测值：</span><br><span class="line"> <span class="number">379</span>     <span class="literal">False</span></span><br><span class="line"><span class="number">1099</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">970</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">482</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">573</span>      <span class="literal">True</span></span><br><span class="line">        ...  </span><br><span class="line"><span class="number">80</span>       <span class="literal">True</span></span><br><span class="line"><span class="number">295</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">4</span>        <span class="literal">True</span></span><br><span class="line"><span class="number">1173</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">684</span>      <span class="literal">True</span></span><br><span class="line">Name: survived, Length: <span class="number">263</span>, dtype: bool</span><br><span class="line">-----------------------------------------------------</span><br><span class="line">准确率为：</span><br><span class="line"> <span class="number">0.7490494296577946</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#随机森林输出结果：</span></span><br><span class="line">---------------以下为随机森林预测效果-----------------</span><br><span class="line">y_predict:</span><br><span class="line"> [<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span></span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span></span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span></span><br><span class="line"> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line">随机森林预测的直接比对真实值和预测值：</span><br><span class="line"> <span class="number">379</span>     <span class="literal">False</span></span><br><span class="line"><span class="number">1099</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">970</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">482</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">573</span>      <span class="literal">True</span></span><br><span class="line">        ...  </span><br><span class="line"><span class="number">80</span>       <span class="literal">True</span></span><br><span class="line"><span class="number">295</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">4</span>        <span class="literal">True</span></span><br><span class="line"><span class="number">1173</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">684</span>      <span class="literal">True</span></span><br><span class="line">Name: survived, Length: <span class="number">263</span>, dtype: bool</span><br><span class="line">-----------------------------------------------------</span><br><span class="line">随机森林预测的准确率为：</span><br><span class="line"> <span class="number">0.7908745247148289</span></span><br><span class="line">-----------------------------------------------------</span><br><span class="line">最佳参数：</span><br><span class="line"> &#123;<span class="string">'max_depth'</span>: <span class="number">5</span>, <span class="string">'n_estimators'</span>: <span class="number">300</span>&#125;</span><br><span class="line">最佳结果：</span><br><span class="line"> <span class="number">0.8295238095238096</span></span><br><span class="line">最佳估计器：</span><br><span class="line"> RandomForestClassifier(bootstrap=<span class="literal">True</span>, class_weight=<span class="literal">None</span>, criterion=<span class="string">'gini'</span>,</span><br><span class="line">                       max_depth=<span class="number">5</span>, max_features=<span class="string">'auto'</span>, max_leaf_nodes=<span class="literal">None</span>,</span><br><span class="line">                       min_impurity_decrease=<span class="number">0.0</span>, min_impurity_split=<span class="literal">None</span>,</span><br><span class="line">                       min_samples_leaf=<span class="number">1</span>, min_samples_split=<span class="number">2</span>,</span><br><span class="line">                       min_weight_fraction_leaf=<span class="number">0.0</span>, n_estimators=<span class="number">300</span>,</span><br><span class="line">                       n_jobs=<span class="literal">None</span>, oob_score=<span class="literal">False</span>, random_state=<span class="literal">None</span>,</span><br><span class="line">                       verbose=<span class="number">0</span>, warm_start=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></div><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul><li>在当前所有算法中，具有极好的准确率</li><li>能够有效地运行在大数据集上，处理具有高维特征的输入样本，而且不需要降维</li><li>能够评估各个特征在分类问题上的重要性</li></ul><h2 id="回归算法"><a href="#回归算法" class="headerlink" title="回归算法"></a>回归算法</h2><p>回归问题：目标值 - 连续型的数据</p><h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><h4 id="什么是线性回归"><a href="#什么是线性回归" class="headerlink" title="什么是线性回归"></a>什么是线性回归</h4><p>线性回归(Linear regression)是利用<strong>回归方程(函数)</strong>对一个或<strong>多个自变量(<span style="color:red">特征值</span>)和因变量(<span style="color:red">目标值</span>)之间</strong>关系进行建模的一种分析方式。</p><p>特点：只有一个自变量的情况称为单变量回归（如：$y=kx+b$），大于一个自变量情况的叫做多元回归。</p><p>通用公式：$h_w(x)=w_1x_1+w_2x_2+w_3x_3…+b=w^Tx+b$</p><p>其中$w$权重，$b$偏置</p><p>$w$和$x$可以理解为矩阵：$\mathbf{w}=\left(\begin{array}{c}b \ w_{1} \ w_{2}\end{array}\right)$,$\mathbf{x}=\left(\begin{array}{c}1 \ x_{1} \ x_{2}\end{array}\right)$</p><p>线性回归当中的关系有两种，一种是线性关系，另一种是非线性关系。</p><p><strong>例子：</strong></p><h6 id="线性关系"><a href="#线性关系" class="headerlink" title="线性关系"></a>线性关系</h6><p>注：如果在单特征与目标值的关系呈直线关系，或者两个特征与目标值呈现平面的关系</p><p>数据：工资和年龄（2个特征）</p><p>目标：预测银行会贷款给我多少钱（标签）</p><p>考虑：工资和年龄都会影响最终银行贷款的结果那么它们各自有多大的影响呢？（参数）</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/捕获.JPG" alt="捕获"></p><p>$X1,X2$就是我们的两个特征（年龄，工资）$ Y$是银行最终会借给我们多少钱</p><p>找到最合适的一条线（想象一个高维）来最好的拟合我们的数据点</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/image-20200302161335608.png" alt="image-20200302161335608"></p><p>假设$w_1$是年龄的参数，$w_2$是工资的参数</p><p>拟合的平面：$h_w(x)=w_1x_1+w_2x_2$</p><p>整合：$h_w(x)=w^Tx$</p><h6 id="非线性关系"><a href="#非线性关系" class="headerlink" title="非线性关系"></a>非线性关系</h6><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/非线性关系.png" alt="非线性关系"></p><p>如果是非线性关系，那么回归方程可以理解为：$w_1x_1+w_2x_2^2+w_3x_3^2$</p><h4 id="线性回归原理"><a href="#线性回归原理" class="headerlink" title="线性回归原理"></a>线性回归原理</h4><h6 id="1、误差"><a href="#1、误差" class="headerlink" title="1、误差"></a><strong>1、误差</strong></h6><p>真实值和预测值之间肯定是要存在差异的（用$ε$来表示该误差）</p><p>对于每个样本：$<br>y^{(i)}=w^{T} x^{(i)}+\varepsilon^{(i)}<br>$</p><p>误差$\varepsilon^{(i)}$是独立同分布，并且服从均值为0方差为$θ^2$的高斯分布(正态分布)</p><blockquote><p><strong>独立</strong>：张三和李四一起来贷款，他俩没关系</p><p><strong>同分布</strong>：他俩都来得是我们假定的这家银行</p><p><strong>高斯分布</strong>：银行可能会多给，也可能会少给，但是绝大多数情况下这个浮动不会太大，极小情况下浮动会比较大，符合正常情况</p></blockquote><p>预测值与误差：$y^{(i)}=w^{T} x^{(i)}+\varepsilon^{(i)}$ $(1)$</p><p>由于误差服从高斯分布：$p(\varepsilon^{(i)})=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{(\varepsilon^{(i)})^{2}}{2 \sigma^{2}}\right)$ $(2)$</p><p>将$(1)$式代入$(2)$式：$<br>p(y^{(i)}|x^{(i)};w)=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{(y^{(i)}-w^Tx^{(i)})^{2}}{2 \sigma^{2}}\right)<br>$</p><p>似然函数：$L(w)=\prod_{i=1}^{m} p\left(y^{(i)} | x^{(i)} ; w\right)=\prod_{i=1}^{m} \frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{\left(y^{(i)}-w^{T} x^{(i)}\right)^{2}}{2 \sigma^{2}}\right)$</p><p>解释：什么样的参数跟我们的数据组合后恰好是真实值</p><p>对数似然：$logL(w)=log\prod_{i=1}^{m} \frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{\left(y^{(i)}-w^{T} x^{(i)}\right)^{2}}{2 \sigma^{2}}\right)$</p><p>解释：乘法难解，加法就容易了，对数里面乘法可以转换成加法</p><p>展开化简：$\sum_{i=1}^{m} \log \frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{\left(y^{(i)}-w^{T} x^{(i)}\right)^{2}}{2 \sigma^{2}}\right)$<br>$=m \log \frac{1}{\sqrt{2 \pi} \sigma}-\frac{1}{\sigma^{2}} \cdot \frac{1}{2} \sum_{i=1}^{m}\left(y^{(i)}-w^{T} x^{(i)}\right)^{2}$</p><p>目标：让似然函数（对数变换后也一样）越大越好</p><h6 id="2、损失函数（Loss-Function）"><a href="#2、损失函数（Loss-Function）" class="headerlink" title="2、损失函数（Loss Function）"></a><strong><span style="color:red">2、损失函数</span>（Loss Function）</strong></h6><p>$J(w)=\frac{1}{2} \sum_{i=1}^{m}\left(y^{(i)}-w^{T} x^{(i)}\right)^{2}=\frac{1}{2} \sum_{i=1}^{m}\left(h_w(x^{(i)})-y^{(i)}\right)^{2}$</p><p>这里的这个损失函数就是著名的<strong>最小二乘损失函数</strong></p><h6 id="3、优化算法"><a href="#3、优化算法" class="headerlink" title="3、优化算法"></a>3、优化算法</h6><p><strong>如何去求模型当中的W，使得损失最小？（目的是找到最小损失对应的W值）</strong></p><p>线性回归经常使用的两种优化算法:</p><p>1)正规方程——天才（直接求解$w$）</p><p>目标函数：$J(w)=\frac{1}{2} \sum_{i=1}^{m}\left(h_w(x^{(i)})-y^{(i)}\right)^{2}=\frac{1}{2}\left(Xw-y\right)^T\left(Xw-y\right)$</p><p>求偏导：</p><script type="math/tex;mode=display">\begin{aligned}
&\nabla_{w} J(w)=\nabla_{w}\left(\frac{1}{2}(X w-y)^{r}(X w-y)\right)=\nabla_{w}\left(\frac{1}{2}\left(w^{T} X^{T}-y^{T}\right)(X w-y)\right)\\
&=\nabla_{w}\left(\frac{1}{2}\left(w^{T} X^{T} X w-w^{T} X^{T} y-y^{T} X w+y^{T} y\right)\right)\\
&=\frac{1}{2}\left(2 X^{T} X w-X^{T} y-\left(y^{T} X\right)^{\bar{T}}\right)=X^{T} X w-X^{T} y
\end{aligned}</script><p>令偏导等于0得：$w=\left(X^TX\right)^{-1}X^Ty$</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/损失行数求解1.png" alt="损失行数求解1"></p><p>理解：X为特征值矩阵，y为目标值矩阵。直接求到最好的结果</p><p>缺点：当特征过多过复杂时，求解速度太慢并且得不到结果</p><p>2）<strong>梯度下降(Gradient Descent)</strong>——勤奋努力的普通人（一步一步的求$w$）</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/梯度下降公式.png" alt="梯度下降公式"></p><p>理解：α为学习速率，需要手动指定（超参数），α旁边的整体表示方向</p><p>沿着这个函数下降的方向找，最后就能找到山谷的最低点，然后更新W值</p><p>使用：面对训练数据规模十分庞大的任务 ，能够找到较好的结果</p><p><strong>我们通过两个图更好理解梯度下降的过程:</strong></p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/单变量的梯度下降.png" alt="单变量的梯度下降"></p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/多变量的梯度下降.png" alt="多变量的梯度下降"></p><h6 id="4、优化动态图演示"><a href="#4、优化动态图演示" class="headerlink" title="4、优化动态图演示"></a>4、优化动态图演示</h6><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/线性回归优化动态图.gif" alt="线性回归优化动态图"></p><h4 id="线性回归算法API"><a href="#线性回归算法API" class="headerlink" title="线性回归算法API"></a>线性回归算法API</h4><p><strong>方法一</strong></p><p>sklearn.linear_model.LinearRegression(fit_intercept=True)</p><ul><li><p>通过正规方程优化</p></li><li><p>fit_intercept：是否计算偏置</p></li><li><p>LinearRegression.coef_：回归系数_</p></li><li><p>LinearRegression.intercept_：偏置_</p></li></ul><p><strong>方法二</strong></p><p>sklearn.linear_model.SGDRegressor(loss=”squared_loss”, fit_intercept=True, learning_rate =’invscaling’, eta0=0.01)</p><ul><li>SGDRegressor类实现了随机梯度下降学习，它支持不同的loss函数和正则化惩罚项来拟合线性回归模型。</li><li>loss:损失类型 loss=”squared_loss”: 普通最小二乘法</li><li>fit_intercept：是否计算偏置</li><li>learning_rate : string, optional</li></ul><p>​ 学习率填充</p><p>​ ‘constant’: eta = eta0</p><p>​ ‘optimal’: eta = 1.0 / (alpha * (t + t0)) [default]</p><p>​ ‘invscaling’: eta = eta0 / pow(t, power_t) power_t=0.25:存在父类当中</p><p>对于一个常数值的学习率来说，可以使用learning_rate=’constant’ ，并使用eta0来指定学习率。</p><ul><li><p>SGDRegressor.coef_：回归系数_</p></li><li><p>_SGDRegressor.intercept_：偏置</p></li></ul><blockquote><p>注：sklearn提供给我们两种实现的API， 可以根据选择使用</p></blockquote><h4 id="波士顿房价预测"><a href="#波士顿房价预测" class="headerlink" title="波士顿房价预测"></a>波士顿房价预测</h4><p>代码：（补充完善<a href="https://blog.csdn.net/weixin_41890393/article/details/83589860）" target="_blank" rel="noopener external nofollow noreferrer">https://blog.csdn.net/weixin_41890393/article/details/83589860）</a></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#正规方程的优化方法对波士顿房价进行预测</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="comment">#1)获取数据</span></span><br><span class="line">x,y= datasets.load_boston(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#平滑处理预测值y</span></span><br><span class="line"><span class="comment">#平滑处理y值，x不处理。（x代表特征，y代表预测值）</span></span><br><span class="line"><span class="comment">#y=np.log(y)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2）划分数据集</span></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=<span class="number">22</span>)</span><br><span class="line"><span class="comment">#3)特征工程：标准化 不适合用标准化数据 一般用平滑处理</span></span><br><span class="line"><span class="comment">#transfer=StandardScaler()</span></span><br><span class="line"><span class="comment">#x_train=transfer.fit_transform(x_train)</span></span><br><span class="line"><span class="comment">#x_test=transfer.transform(x_test)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#4)正规方程的优化算法预估器</span></span><br><span class="line">estimator=LinearRegression()</span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line"><span class="comment">#5)得出模型</span></span><br><span class="line">print(<span class="string">'正规方程权重系数为:\n'</span>,estimator.coef_)</span><br><span class="line">print(<span class="string">'正规方程偏置为:\n'</span>,estimator.intercept_)</span><br><span class="line"><span class="comment">#6）模型评估</span></span><br><span class="line">y_predict=estimator.predict(x_test)</span><br><span class="line">print(<span class="string">'预测房价:\n'</span>,y_predict)</span><br><span class="line">print(<span class="string">'正规方程—均方误差MSE为:'</span>, metrics.mean_squared_error(y_test, y_predict))</span><br><span class="line"><span class="comment">#7）交叉验证</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_predict</span><br><span class="line">predicted = cross_val_predict(estimator,x,y,cv=<span class="number">10</span>)</span><br><span class="line">print(<span class="string">"MSE:"</span>, metrics.mean_squared_error(y, predicted))</span><br><span class="line"><span class="comment">#6）可视化</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># scatter</span></span><br><span class="line">plt.scatter(y, predicted)</span><br><span class="line"><span class="comment"># plot</span></span><br><span class="line">plt.plot([y.min(), y.max()], [y.min(), y.max()], <span class="string">'k--'</span>, lw=<span class="number">4</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Measured"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Predicted"</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#展示结果</span></span><br><span class="line"><span class="comment">#创建画布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">8</span>),dpi=<span class="number">80</span>)</span><br><span class="line"><span class="comment">#绘图</span></span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>]=<span class="string">'SimHei'</span></span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>]=<span class="literal">False</span></span><br><span class="line">x=range(len(y_predict))</span><br><span class="line">y1=y_predict</span><br><span class="line">y2=y_test</span><br><span class="line"><span class="comment">#折线图</span></span><br><span class="line">plt.plot(x,y1,linestyle=<span class="string">'-'</span>)</span><br><span class="line">plt.plot(x,y2,linestyle=<span class="string">'-.'</span>)</span><br><span class="line"><span class="comment">#增加图例</span></span><br><span class="line">plt.legend([<span class="string">'房价预测值'</span>,<span class="string">'房价真实值'</span>])</span><br><span class="line">plt.title(<span class="string">'波士顿房价走势图'</span>)</span><br><span class="line"><span class="comment">#展示</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div><p>输出结果：（注：特征有几个权重就有几个）</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">正规方程权重系数为:</span><br><span class="line"> [<span class="number">-0.64817766</span>  <span class="number">1.14673408</span> <span class="number">-0.05949444</span>  <span class="number">0.74216553</span> <span class="number">-1.95515269</span>  <span class="number">2.70902585</span></span><br><span class="line"> <span class="number">-0.07737374</span> <span class="number">-3.29889391</span>  <span class="number">2.50267196</span> <span class="number">-1.85679269</span> <span class="number">-1.75044624</span>  <span class="number">0.87341624</span></span><br><span class="line"> <span class="number">-3.91336869</span>]</span><br><span class="line">正规方程偏置为:</span><br><span class="line"> <span class="number">22.62137203166228</span></span><br><span class="line">预测房价:</span><br><span class="line"> [<span class="number">28.22944896</span> <span class="number">31.5122308</span>  <span class="number">21.11612841</span> <span class="number">32.6663189</span>  <span class="number">20.0023467</span>  <span class="number">19.07315705</span></span><br><span class="line">...........................................................</span><br><span class="line"> <span class="number">28.58237108</span>]</span><br><span class="line">正规方程—均方误差MSE为: <span class="number">20.6275137630954</span></span><br><span class="line">MSE: <span class="number">34.53965953999329</span></span><br></pre></td></tr></table></figure></div><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/Figure_1-1583217802407.png" alt="Figure_1"></p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/Figure_19.png" alt="Figure_19"></p><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#梯度下降的优化方法对波士顿房价进行预测</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="comment">#1)获取数据</span></span><br><span class="line">x,y= datasets.load_boston(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#2）划分数据集</span></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=<span class="number">22</span>)</span><br><span class="line"><span class="comment">#3)特征工程：标准化 </span></span><br><span class="line">transfer=StandardScaler()</span><br><span class="line">x_train=transfer.fit_transform(x_train)</span><br><span class="line">x_test=transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#4)梯度下降的优化算法预估器</span></span><br><span class="line">estimator=SGDRegressor(learning_rate=<span class="string">'constant'</span>, eta0=<span class="number">0.01</span>,max_iter=<span class="number">10000</span>)<span class="comment">#调参数</span></span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line"><span class="comment">#5)得出模型</span></span><br><span class="line">print(<span class="string">'梯度下降权重系数为:\n'</span>,estimator.coef_)</span><br><span class="line">print(<span class="string">'梯度下降截距为:\n'</span>,estimator.intercept_)</span><br><span class="line"><span class="comment">#6）模型评估</span></span><br><span class="line">y_predict=estimator.predict(x_test)</span><br><span class="line">print(<span class="string">'预测房价:\n'</span>,y_predict)</span><br><span class="line">print(<span class="string">'梯度下降—均方误差MSE为:'</span>, metrics.mean_squared_error(y_test, y_predict))</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">梯度下降权重系数为:</span><br><span class="line"> [<span class="number">-0.529811</span>    <span class="number">0.93849958</span> <span class="number">-0.43482307</span>  <span class="number">0.77305338</span> <span class="number">-1.71206925</span>  <span class="number">2.82393382</span></span><br><span class="line"> <span class="number">-0.16256326</span> <span class="number">-3.09703859</span>  <span class="number">1.63812767</span> <span class="number">-0.93714655</span> <span class="number">-1.72483573</span>  <span class="number">0.88640923</span></span><br><span class="line"> <span class="number">-3.90806571</span>]</span><br><span class="line">梯度下降截距为:</span><br><span class="line"> [<span class="number">22.61725005</span>]</span><br><span class="line">预测房价:</span><br><span class="line"> [<span class="number">28.29992805</span> <span class="number">31.66102185</span> <span class="number">21.46408381</span> <span class="number">32.63060514</span> <span class="number">20.23508805</span> <span class="number">18.98298548</span></span><br><span class="line">...........................................................</span><br><span class="line"> <span class="number">28.33964857</span>]</span><br><span class="line">梯度下降—均方误差MSE为: <span class="number">21.004247881383602</span></span><br></pre></td></tr></table></figure></div><h4 id="正规方程和梯度下降对比"><a href="#正规方程和梯度下降对比" class="headerlink" title="正规方程和梯度下降对比"></a>正规方程和梯度下降对比</h4><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/正规方程和梯度下降对比.png" alt="正规方程和梯度下降对比"></p><p><strong>文字对比</strong></p><div class="table-container"><table><thead><tr><th style="text-align:center">梯度下降</th><th style="text-align:center"><strong>正规方程</strong></th></tr></thead><tbody><tr><td style="text-align:center">需要选择学习率</td><td style="text-align:center">不需要</td></tr><tr><td style="text-align:center">需要迭代求解</td><td style="text-align:center">一次运算得出</td></tr><tr><td style="text-align:center">特征数量较大可以使用</td><td style="text-align:center">需要计算方程，时间复杂度高O(n3)</td></tr></tbody></table></div><p>选择：</p><ul><li>小规模数据：<ul><li><strong>LinearRegression(不能解决拟合问题)</strong></li><li>岭回归</li></ul></li><li>大规模数据：SGDRegressor</li></ul><h4 id="拓展-关于优化方法BGD、SGD、MBGD、SAG"><a href="#拓展-关于优化方法BGD、SGD、MBGD、SAG" class="headerlink" title="拓展-关于优化方法BGD、SGD、MBGD、SAG"></a>拓展-关于优化方法BGD、SGD、MBGD、SAG</h4><p>目标函数：$J(w)=\frac{1}{2m} \sum_{i=1}^{m}\left(y^{(i)}-h_w(x^{(i)})\right)^{2}$</p><p>① 批量梯度下降<strong>（batch gradient descent）</strong>：（容易得到最优解，但是由于每次考虑所有样本，速度很慢）</p><p>$\frac{\partial J(w)}{\partial w_{j}}=-\frac{1}{m} \sum_{i=1}^{m}\left(y^{(i)}-h_{w}\left(x^{(i)}\right)\right) x_{j}^{(i)}$</p><p>$w_{j}^{\prime}=w_{j}+\frac{α}{m} \sum_{i=1}^{m}\left(y^{(i)}-h_{w}\left(x^{(i)}\right)\right) x_{j}^{(i)}$</p><p>批量梯度下降的算法执行过程如下图：</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/031938497051596.png" alt="031938497051596"></p><p>② <span style="color:red">随机梯度下降</span><strong>（Stochastic Gradient Descent, SGD）</strong>：（每次找一个样本，迭代速度快，但不一定每次都朝着收敛的方向，而是震荡的方式趋向极小点）</p><p>$w_{j}^{\prime}=w_{j}+α\left(y^{(i)}-h_{w}\left(x^{(i)}\right)\right) x_{j}^{(i)}$</p><ul><li>SGD的优点是：<ul><li>高效</li><li>容易实现</li></ul></li><li>SGD的缺点是：<ul><li>SGD需要许多超参数：比如正则项参数、迭代数。</li><li>SGD对于特征标准化是敏感的。</li></ul></li></ul><p>③ 小批量梯度下降法<strong>（Mini-batch gradient descent）</strong>：（每次更新选择一小部分数据来算，实用！</p><p>$w_{j}^{\prime}=w_{j}+α\frac{1}{10} \sum_{k=i}^{i+9}\left(y^{(k)}-h_{w}\left(x^{(k)}\right)\right) x_{j}^{(k)}$</p><p>④随机平均梯度法(Stochasitc Average Gradient)：（由于收敛的速度太慢，有人提出SAG等基于梯度下降的算法）</p><blockquote><p>Scikit-learn：SGDRegressor、岭回归、逻辑回归等当中都会有SAG优化</p></blockquote><h3 id="欠拟合与过拟合"><a href="#欠拟合与过拟合" class="headerlink" title="欠拟合与过拟合"></a>欠拟合与过拟合</h3><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/20190720210756791.png" alt="在这里插入图片描述"></p><ul><li>欠拟合（模型过于简单）</li></ul><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/20190720205912608.png" alt="在这里插入图片描述"></p><ul><li>过拟合（模型过于复杂）</li></ul><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/20190720210220248.png" alt="在这里插入图片描述"></p><p><strong>解决办法</strong></p><p>欠拟合解决办法</p><ul><li><p>增加新的特征，可以考虑加入进特征组合、高次特征，来增大假设空间</p></li><li><p>采用非线性模型，比如核SVM 、决策树、DNN等模型</p></li><li><p>Boosting，Boosting 往往会有较小的 Bias，比如 Gradient Boosting 等</p></li><li><p>如果已正则化，尝试减少正则化程度$λ$</p></li></ul><p>过拟合解决办法</p><ul><li><p>交叉检验，通过交叉检验得到较优的模型参数</p></li><li><p>特征选择，减少特征数或使用较少的特征组合，对于按区间离散化的特征，增大划分的区间</p></li><li><p>正则化，常用的有 L1、L2 正则</p></li><li><p>如果已正则化，尝试增大正则化程度λ</p></li><li><p>增加训练数据可以有限的避免过拟合</p></li><li><p>Bagging，将多个弱学习器Bagging 一下效果会好很多，比如随机森林等</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/20190720212516689.png" alt="在这里插入图片描述"></p><p><strong>正则化类别</strong></p></li></ul><ol><li>L1正则化<br>作用：可以使其中一些W的值直接为0，删除这个特征的影响。<br>LOSSO回归</li><li>L2正则化<br>作用：可以使得其中一些W的值都很小，都接近于0，削弱某个特征的影响。<br>优点：越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象。<br>Ridge回归（岭回归）。<br>加入L2正则化后的损失函数：</li></ol><p>$J(w)=\frac{1}{2m} \sum_{i=1}^{m}\left(y^{(i)}-h_w(x^{(i)})\right)^{2}+λ\sum_{j=1}^{n}w_j^2$</p><p>其中m为样本数，n为特征数</p><h3 id="岭回归"><a href="#岭回归" class="headerlink" title="岭回归"></a>岭回归</h3><p>岭回归，其实也是一种线性回归。只不过在算法建立回归方程时候，加上正则化（L2）的限制，从而达到解决过拟合的效果。</p><h4 id="参数推导"><a href="#参数推导" class="headerlink" title="参数推导"></a>参数推导</h4><p>线性回归模型的目标函数:$J(β)=\sum\left(y-Xβ\right)^{2}$</p><p>为了保证回归系数$β$可求，岭回归模型在目标函数上加了一个L2范数的惩罚项</p><p>$J(β)=\sum\left(y-Xβ\right)^{2}+λ||β||_2^2=\sum\left(y-Xβ\right)^{2}+\sumλβ^2$</p><p>其中$λ$为非负数，$λ$越大，则为了使$J(β)$最小，回归系数$β$就越小。<br><strong>推导过程：</strong></p><p>$\begin{array}{c}<br>J(\beta)=(y-X \beta)^{T}(y-X \beta)+\lambda \beta^{T} \beta \\<br>=y^{T} y-y^{T} X \beta-\beta^{T} X^{T} y+\beta^{T} X^{T} X \beta+\lambda \beta^{T} \beta \\<br>令 \frac{\partial J(\beta)}{\partial \beta}=0 \\<br>\Rightarrow 0-X^{T} y-X^{T} y+2 X^{T} X \beta+2 \lambda \beta=0 \\<br>\Rightarrow \beta=\left(X^{T} X+\lambda I\right)^{-1} X^{T} y<br>\end{array}$</p><p>L2范数惩罚项的加入使得$(X^{T}X+λI)$满秩，保证了可逆，但是也由于惩罚项的加$λ$，使得回归系数$β$的估计不再是无偏估计。所以岭回归是以放弃无偏性、降低精度为代价解决病态矩阵问题的回归方法。<br>单位矩阵$I$的对角线上全是1，像一条山岭一样，这也是岭回归名称的由来。</p><h4 id="λ-的选择"><a href="#λ-的选择" class="headerlink" title="$λ$的选择"></a>$λ$的选择</h4><p>模型的方差：回归系数的方差<br>模型的偏差：预测值和真实值的差异<br>随着模型复杂度的提升，在训练集上的效果就越好，即模型的偏差就越小；但是同时模型的方差就越大。对于岭回归的$λ$而言，随着$λ$的增大，$(X^{T}X+λI)$就越大，$(X^{T}X+λI)^{-1}$就越小，模型的方差就越小；而$λ$越大使得$β$的估计值更加偏离真实值，模型的偏差就越大。所以岭回归的关键是找到一个合理的$λ$值来平衡模型的方差和偏差。<br>根据凸优化，可以将岭回归模型的目标函数$J(β)$最小化问题等价于$\left\{\begin{array}{l}\operatorname{argmin}\left\{\Sigma\left(y-X \beta^{2}\right)\right\} \ \Sigma \beta^{2} \leq t\end{array}\right.$</p><p>其中$t$为一个常数。以最简单的二维为例，即$β(β_1,β_2)$其几何图形是:</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/20181103202221367.jpg" alt="20181103202221367"></p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/20181103202237148.jpg" alt="20181103202237148"></p><p>抛物面代表的是$\sum(y-X\beta)^2$的部分，圆柱体代表的是$β_1^{1}+β_2^{2}≤t$的部分。最小二乘解是抛物面的中心，岭回归解是抛物面与圆柱体的交点。岭回归的惩罚项$∑λβ^2$是关于回归系数$β$的二次函数，对目标函数求偏导时会保留$β$，抛物面与圆柱体很难相交于轴上使某个变量的回归系数为0，因此岭回归不能实现变量的剔除。</p><p><strong>（1）岭迹法确定$λ$值</strong><br>由$β=(X^TX+λI)^{−1}X^Ty$ 可知$β$是$λ$的函数，当$λ∈[0,∞)$时，在平面直角坐标系中的$β−λ$曲线称为岭迹曲线。当$β$趋于稳定的点就是所要寻找的$λ$值。<br>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">data=pd.read_csv(<span class="string">'diabetes.csv'</span>)</span><br><span class="line">x=data.iloc[:,<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">y=data[<span class="string">'Outcome'</span>]</span><br><span class="line"><span class="comment">#拆分为训练集和测试集</span></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">1234</span>)</span><br><span class="line"><span class="comment">#构造不同的lambda值</span></span><br><span class="line">Lambdas=np.logspace(<span class="number">-5</span>,<span class="number">2</span>,<span class="number">200</span>)</span><br><span class="line"><span class="comment">#存放偏回归系数</span></span><br><span class="line">ridge_cofficients=[]</span><br><span class="line"><span class="keyword">for</span> Lambda <span class="keyword">in</span> Lambdas:</span><br><span class="line">    ridge=Ridge(alpha=Lambda,normalize=<span class="literal">True</span>)</span><br><span class="line">    ridge.fit(x_train,y_train)</span><br><span class="line">    ridge_cofficients.append(ridge.coef_)</span><br><span class="line"></span><br><span class="line"><span class="comment">#绘制岭迹曲线</span></span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>]=[<span class="string">'Microsoft YaHei'</span>]</span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>]=<span class="literal">False</span></span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line">plt.plot(Lambdas,ridge_cofficients)</span><br><span class="line"><span class="comment">#x轴做对数处理</span></span><br><span class="line">plt.xscale(<span class="string">'log'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Log(Lambda)'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Cofficients'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/Figure_1-1583378255882.png" alt="Figure_1"></p><ul><li>正则化力度λ越大，权重系数w越小</li><li>正则化力度λ越小，权重系数w越大</li></ul><p>书上说在0.01附近大多数回归系数就趋于稳定，这哪看得出？所以定性的方法一般不太靠谱，还是用定量的方法吧！<br><strong>（2）交叉验证法确定$λ$值</strong></p><p>交叉验证法的思想是，将数据集拆分为$k$个数据组(每组样本量大体相当)，从$k$组中挑选$k-1$组用于模型的训练，剩下的1组用于模型的测试，则会有$k-1$个训练集和测试集配对，每一种训练集和测试集下都会有对应的一个模型及模型评分（如均方误差），进而可以得到一个平均评分。对于$λ$值则选择平均评分最优的$λ$值。RidgeCV(alphas=(0.1, 1.0, 10.0), fit_intercept=True, normalize=False, scoring=None, cv=None, gcv_mode=None, store_cv_values=False)•</p><ul><li>lambdas：用于指定多个$λ$值的元组或数组对象，默认包含0.1,1,10三种值。</li><li><p>fit_intercept：bool类型，是否需要拟合截距项，默认为True。</p></li><li><p>normalize：bool类型，建模时是否对数据集做标准化处理，默认为False。</p></li><li>scoring：指定用于模型评估的度量方法。</li><li>cv：指定交叉验证的重数。gcv_mode：指定广义交叉验证的方法。</li><li>store_cv_values：bool类型，是否保存每个λ\lambdaλ下交叉验证的评估信息，默认为False，只有cv为None时有效。</li></ul><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> RidgeCV</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">data=pd.read_csv(<span class="string">'diabetes.csv'</span>)</span><br><span class="line">x=data.iloc[:,<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">y=data[<span class="string">'Outcome'</span>]</span><br><span class="line"><span class="comment">#拆分为训练集和测试集</span></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">1234</span>)</span><br><span class="line"><span class="comment">#构造不同的lambda值</span></span><br><span class="line">Lambdas=np.logspace(<span class="number">-5</span>,<span class="number">2</span>,<span class="number">200</span>)</span><br><span class="line"><span class="comment">#设置交叉验证的参数，使用均方误差评估</span></span><br><span class="line">ridge_cv=RidgeCV(alphas=Lambdas,normalize=<span class="literal">True</span>,scoring=<span class="string">'neg_mean_squared_error'</span>,cv=<span class="number">10</span>)</span><br><span class="line">ridge_cv.fit(x_train,y_train)</span><br><span class="line">print(ridge_cv.alpha_)</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="number">0.038720387818125535</span></span><br></pre></td></tr></table></figure></div><h4 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h4><p>Ridge(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver=‘auto’, random_state=None)</p><ul><li><p>具有l2正则化的线性回归</p></li><li><p>alpha：正则化力度，也叫 λ，默认为1。λ取值：0.1~1 ~10</p></li><li><p>fit_intercept：bool类型，是否需要拟合截距项，默认为True。</p></li><li><p>normalize：bool类型，建模时是否对数据集做标准化处理，默认为False。</p><p>normalize=False:可以在fit之前调用preprocessing.StandardScaler标准化数据</p></li><li><p>copy_X：bool类型，是否复制自变量X的数值，默认为True。</p></li><li><p>max_iter：指定模型的最大迭代次数。</p></li><li><p>solver：指定模型求解最优化问题的算法，默认为’auto’。</p><p>sag:如果数据集、特征都比较大，选择该随机梯度下降优化</p></li><li><p>random_state：指定随机生成器的种子。</p></li><li><p>Ridge.coef_:回归权重_</p></li><li><p>Ridge.intercept_:回归偏置</p><blockquote><p>All last four solvers support both dense and sparse data. However,only ‘sag’ supports sparse input when ‘fit_intercept’is True.</p></blockquote><p>Ridge方法相当于SGDRegressor(penalty=’l2’, loss=”squared_loss”),只不过SGDRegressor实现了一个普通的随机梯度下降学习，推荐使用Ridge(实现了SAG)</p><ul><li><p>sklearn.linear_model.RidgeCV(_BaseRidgeCV, RegressorMixin)_</p></li><li><p>具有l2正则化的线性回归，可以进行交叉验证</p></li><li><p>_coef_:回归系数</p></li></ul><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_BaseRidgeCV</span><span class="params">(LinearModel)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, alphas=<span class="params">(<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">10.0</span>)</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 fit_intercept=True, normalize=False, scoring=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 cv=None, gcv_mode=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 store_cv_values=False)</span>:</span></span><br></pre></td></tr></table></figure></div></li></ul><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge,RidgeCV</span><br><span class="line">data=pd.read_csv(<span class="string">'diabetes.csv'</span>)</span><br><span class="line">x=data.iloc[:,<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">y=data[<span class="string">'Outcome'</span>]</span><br><span class="line"><span class="comment">#拆分为训练集和测试集</span></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">1234</span>)</span><br><span class="line"><span class="comment">#构造不同的lambda值</span></span><br><span class="line">Lambdas=np.logspace(<span class="number">-5</span>,<span class="number">2</span>,<span class="number">200</span>)</span><br><span class="line"><span class="comment">#设置交叉验证的参数，使用均方误差评估</span></span><br><span class="line">ridge_cv=RidgeCV(alphas=Lambdas,normalize=<span class="literal">True</span>,scoring=<span class="string">'neg_mean_squared_error'</span>,cv=<span class="number">10</span>)</span><br><span class="line">ridge_cv.fit(x_train,y_train)</span><br><span class="line">print(ridge_cv.alpha_)</span><br><span class="line"><span class="comment">#基于最佳lambda值建模</span></span><br><span class="line">ridge=Ridge(alpha=ridge_cv.alpha_,normalize=<span class="literal">True</span>)</span><br><span class="line">ridge.fit(x_train,y_train)</span><br><span class="line"><span class="comment">#打印回归系数</span></span><br><span class="line">print(pd.Series(index=[<span class="string">'Intercept'</span>]+x_train.columns.tolist(),</span><br><span class="line">                data=[ridge.intercept_]+ridge.coef_.tolist()))</span><br><span class="line"><span class="comment">#模型评估</span></span><br><span class="line">ridge_pred=ridge.predict(x_test)</span><br><span class="line"><span class="comment">#均方误差</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line">MSE=mean_squared_error(y_test,ridge_pred)</span><br><span class="line">print(MSE)</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="number">0.038720387818125535</span></span><br><span class="line">Intercept                  <span class="number">-0.829372</span></span><br><span class="line">Glucose                     <span class="number">0.005658</span></span><br><span class="line">BloodPressure              <span class="number">-0.002019</span></span><br><span class="line">SkinThickness              <span class="number">-0.000805</span></span><br><span class="line">Insulin                    <span class="number">-0.000016</span></span><br><span class="line">BMI                         <span class="number">0.012776</span></span><br><span class="line">DiabetesPedigreeFunction    <span class="number">0.158436</span></span><br><span class="line">Age                         <span class="number">0.004989</span></span><br><span class="line">dtype: float64</span><br><span class="line"><span class="number">0.16870817670347735</span></span><br></pre></td></tr></table></figure></div><h3 id="LASSO回归"><a href="#LASSO回归" class="headerlink" title="LASSO回归"></a>LASSO回归</h3><h4 id="参数推导-1"><a href="#参数推导-1" class="headerlink" title="参数推导"></a>参数推导</h4><p>岭回归无法剔除变量，而LASSO回归模型，将惩罚项由L2范数变为L1范数，可以将一些不重要的回归系数缩减为0，达到剔除变量的目的。</p><p>$J(β)=\sum\left(y-Xβ\right)^{2}+λ||β||_1=\sum\left(y-Xβ\right)^{2}+\sumλ|β|=ESS（β）+λl_1(β)$</p><h4 id="λ-的选择-1"><a href="#λ-的选择-1" class="headerlink" title="$λ$的选择"></a>$λ$的选择</h4><p>直接使用交叉验证法</p><p>LassoCV(eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, normalize=False, precompute=‘auto’, max_iter=1000, tol=0.0001, copy_X=True, cv=None, verbose=False, n_jobs=1, positive=False, random_state=None, selection=‘cyclic’)</p><ul><li>eps：指代λ\lambdaλ最小值与最大值的商，默认为0.001。</li><li>n_alphas：指定λ\lambdaλ的个数，默认为100个。</li><li>alphas：指定具体的λ\lambdaλ列表用于模型的运算。</li><li>fit_intercept：bool类型，是否需要拟合截距项，默认为True。</li><li>normalize：bool类型，建模时是否对数据集做标准化处理，默认为False。</li><li>precompute：bool类型，是否在建模前计算Gram矩阵提升运算速度，默认为False。</li><li>max_iter：指定模型的最大迭代次数。</li><li>tol：指定模型收敛的阈值，默认为0.0001。</li><li>copy_X：bool类型，是否复制自变量X的数值，默认为True。</li><li>cv：指定交叉验证的重数。</li><li>verbose：bool类型，是否返回模型运行的详细信息，默认为False。</li><li>n_jobs：指定使用的CPU数量，默认为1，如果为-1表示所有CPU用于交叉验证的运算。</li><li>positive：bool类型，是否将回归系数强制为正数，默认为False。</li><li>random_state：指定随机生成器的种子。</li><li>selection：指定每次迭代选择的回归系数，如果为’random’，表示每次迭代中将随机更新回归系数；如果为’cyclic’，则每次迭代时回归系数的更新都基于上一次运算。</li></ul><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LassoCV</span><br><span class="line">data=pd.read_csv(<span class="string">'diabetes.csv'</span>)</span><br><span class="line">x=data.iloc[:,<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">y=data[<span class="string">'Outcome'</span>]</span><br><span class="line"><span class="comment">#拆分为训练集和测试集</span></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">1234</span>)</span><br><span class="line"><span class="comment">#构造不同的lambda值</span></span><br><span class="line">Lambdas=np.logspace(<span class="number">-5</span>,<span class="number">2</span>,<span class="number">200</span>)</span><br><span class="line"><span class="comment">#设置交叉验证的参数，使用均方误差评估</span></span><br><span class="line">lasso_cv=LassoCV(alphas=Lambdas,normalize=<span class="literal">True</span>,cv=<span class="number">10</span>,max_iter=<span class="number">10000</span>)</span><br><span class="line">lasso_cv.fit(x_train,y_train)</span><br><span class="line">print(lasso_cv.alpha_)</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="number">0.00011357333583431052</span></span><br></pre></td></tr></table></figure></div><h4 id="代码实现-2"><a href="#代码实现-2" class="headerlink" title="代码实现"></a>代码实现</h4><p>Lasso(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, random_state=None, selection=‘cyclic’)</p><ul><li>alphas：指定λ\lambdaλ值，默认为1。</li><li>fit_intercept：bool类型，是否需要拟合截距项，默认为True。</li><li>normalize：bool类型，建模时是否对数据集做标准化处理，默认为False。</li><li>precompute：bool类型，是否在建模前计算Gram矩阵提升运算速度，默认为False。</li><li>copy_X：bool类型，是否复制自变量X的数值，默认为True。</li><li>max_iter：指定模型的最大迭代次数。</li><li>tol：指定模型收敛的阈值，默认为0.0001。</li><li>warm_start：bool类型，是否将前一次训练结果用作后一次的训练，默认为False。</li><li>positive：bool类型，是否将回归系数强制为正数，默认为False。</li><li>random_state：指定随机生成器的种子。</li><li>selection：指定每次迭代选择的回归系数，如果为’random’，表示每次迭代中将随机更新回归系数；如果为’cyclic’，则每次迭代时回归系数的更新都基于上一次运算。</li></ul><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso,LassoCV</span><br><span class="line">data=pd.read_csv(<span class="string">'diabetes.csv'</span>)</span><br><span class="line">x=data.iloc[:,<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">y=data[<span class="string">'Outcome'</span>]</span><br><span class="line"><span class="comment">#拆分为训练集和测试集</span></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">1234</span>)</span><br><span class="line"><span class="comment">#构造不同的lambda值</span></span><br><span class="line">Lambdas=np.logspace(<span class="number">-5</span>,<span class="number">2</span>,<span class="number">200</span>)</span><br><span class="line"><span class="comment">#设置交叉验证的参数，使用均方误差评估</span></span><br><span class="line">lasso_cv=LassoCV(alphas=Lambdas,normalize=<span class="literal">True</span>,cv=<span class="number">10</span>,max_iter=<span class="number">10000</span>)</span><br><span class="line">lasso_cv.fit(x_train,y_train)</span><br><span class="line"><span class="comment">#基于最佳lambda值建模</span></span><br><span class="line">lasso=Lasso(alpha=lasso_cv.alpha_,normalize=<span class="literal">True</span>,max_iter=<span class="number">10000</span>)</span><br><span class="line">lasso.fit(x_train,y_train)</span><br><span class="line"><span class="comment">#打印回归系数</span></span><br><span class="line">print(pd.Series(index=[<span class="string">'Intercept'</span>]+x_train.columns.tolist(),</span><br><span class="line">                data=[lasso.intercept_]+lasso.coef_.tolist()))</span><br><span class="line"><span class="comment">#模型评估</span></span><br><span class="line">lasso_pred=lasso.predict(x_test)</span><br><span class="line"><span class="comment">#均方误差</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line">MSE=mean_squared_error(y_test,lasso_pred)</span><br><span class="line">print(MSE)</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">Intercept                  <span class="number">-0.842415</span></span><br><span class="line">Glucose                     <span class="number">0.005801</span></span><br><span class="line">BloodPressure              <span class="number">-0.001983</span></span><br><span class="line">SkinThickness              <span class="number">-0.000667</span></span><br><span class="line">Insulin                    <span class="number">-0.000011</span></span><br><span class="line">BMI                         <span class="number">0.012670</span></span><br><span class="line">DiabetesPedigreeFunction    <span class="number">0.153236</span></span><br><span class="line">Age                         <span class="number">0.004865</span></span><br><span class="line">dtype: float64</span><br><span class="line"><span class="number">0.16876008361250405</span></span><br></pre></td></tr></table></figure></div><p>相对于岭回归而言，可以看到LASSO回归剔除了两个变量，降低了模型的复杂度，同时减少了均方误差，提高了模型的拟合效果。</p><h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><p>逻辑回归（Logistic Regression）是机器学习中的一种分类模型，逻辑回归是一种分类算法，虽然名字中带有回归，但是它与回归之间有一定的联系。由于算法的简单和高效，在实际中应用非常广泛。</p><h4 id="逻辑回归的应用场景"><a href="#逻辑回归的应用场景" class="headerlink" title="逻辑回归的应用场景"></a>逻辑回归的应用场景</h4><ul><li>广告点击率</li><li>是否为垃圾邮件</li><li>是否患病</li><li>金融诈骗</li><li>虚假账号</li></ul><p>目的：分类还是回归？经典的二分类算法！</p><p>逻辑回归的决策边界：可以是非线性的</p><h4 id="逻辑回归的原理"><a href="#逻辑回归的原理" class="headerlink" title="逻辑回归的原理"></a>逻辑回归的原理</h4><p><strong>输入</strong></p><p>$h_w(x)=w_1x_1+w_2x_2+w_3x_3…+b=w^Tx+b$</p><p><strong>Sigmoid函数</strong></p><p>公式：$g(z)=\frac{1}{1+e^{-z}}$</p><p>自变量取值为任意实数，值域[0,1]</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/image-20200304105302691.png" alt="image-20200304105302691"></p><blockquote><p>解释：将任意的输入映射到了[0,1]区间，我们在线性回归中可以得到一个预测值，再将该值映射到Sigmoid 函数中这样就完成了由值到概率的转换，也就是分类任务</p></blockquote><p>预测函数：</p><script type="math/tex;mode=display">h_w(x)=g(w^Tx)=\frac{1}{1+e^{-w^Tx}}</script><p>分类任务：</p><p>$P(y=1|x;w)=h_w(x)$ ; $P(y=0|x;w)=1-h_w(x)$</p><p>整合得： $P(y|x;w)=(h_w(x))^y(1-h_w(x))^{1-y}$</p><blockquote><p>解释：对于二分类任务（0，1），整合后y取0只保留$(1-h_w(x))^{1-y}$，y取1只保留$(h_w(x))^y$</p></blockquote><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/逻辑回归运算过程.png" alt="逻辑回归运算过程"></p><h4 id="损失以及优化"><a href="#损失以及优化" class="headerlink" title="损失以及优化"></a>损失以及优化</h4><h5 id="1、损失"><a href="#1、损失" class="headerlink" title="1、损失"></a>1、损失</h5><p>逻辑回归的损失，称之为<strong>对数似然损失</strong>，公式如下：</p><ul><li>分开类别：</li></ul><script type="math/tex;mode=display">\operatorname{cost}\left(h_{\theta}(x), y\right)=\left\{\begin{array}{ll}
-\log \left(h_{\theta}(x)\right) & \text { if } y=1 \\
-\log \left(1-h_{\theta}(x)\right) & \text { if } y=0
\end{array}\right.</script><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/单个损失解释.png" alt="单个损失解释"></p><p>综合完整损失函数：$$<br>\operatorname{cost}\left(h_{\theta}(x), y\right)=\sum_{i=1}^{m}-y_{i} \log \left(h_{\theta}(x)\right)-\left(1-y_{i}\right) \log \left(1-h_{\theta}(x)\right)</p><p>$$</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/损失计算过程.png" alt="损失计算过程"></p><h5 id="2、优化"><a href="#2、优化" class="headerlink" title="2、优化"></a>2、优化</h5><p>同样使用梯度下降优化算法，去减少损失函数的值。这样去更新逻辑回归前面对应算法的权重参数，<strong>提升原本属于1类别的概率，降低原本是0类别的概率。</strong></p><h4 id="逻辑回归算法API"><a href="#逻辑回归算法API" class="headerlink" title="逻辑回归算法API"></a>逻辑回归算法API</h4><p>sklearn.linear_model.LogisticRegression(solver=’liblinear’, penalty=‘l2’, C = 1.0)</p><ul><li><p>solver:优化求解方式</p><p>默认开源的liblinear库实现，内部使用了坐标轴下降法来迭代优化损失函数</p></li><li><p>sag：根据数据集自动选择，随机平均梯度下降</p></li><li><p>penalty：正则化的种类</p></li><li><p>C：正则化力度</p></li></ul><blockquote><p><strong>默认将类别数量少的当做正例</strong></p></blockquote><p>LogisticRegression方法相当于 SGDClassifier(loss=”log”, penalty=” “),SGDClassifier实现了一个普通的随机梯度下降学习，也支持平均随机梯度下降法（ASGD），可以通过设置average=True。而使用LogisticRegression(实现了SAG)良／恶性乳腺癌肿瘤预测</p><h4 id="案例：癌症分类预测"><a href="#案例：癌症分类预测" class="headerlink" title="案例：癌症分类预测"></a>案例：癌症分类预测</h4><p>良/恶性乳腺癌肿瘤预测</p><p><strong>数据描述:</strong></p><p>（1）699条样本，共11列数据，第一列用语检索的id，后9列分别是与肿瘤</p><p>相关的医学特征，最后一列表示肿瘤类型的数值。</p><p>（2）包含16个缺失值，用”?”标出。</p><p>原始数据的下载地址：<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/" target="_blank" rel="noopener external nofollow noreferrer">https://archive.ics.uci.edu/ml/machine-learning-databases/</a></p><p><strong>分析:</strong></p><ul><li>缺失值处理</li><li>标准化处理</li><li>逻辑回归预测</li></ul><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#逻辑回归进行癌症预测</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="comment"># 1、读取数据</span></span><br><span class="line">column_name = [<span class="string">'Sample code number'</span>, <span class="string">'Clump Thickness'</span>, <span class="string">'Uniformity of Cell Size'</span>, <span class="string">'Uniformity of Cell Shape'</span>,</span><br><span class="line">                   <span class="string">'Marginal Adhesion'</span>, <span class="string">'Single Epithelial Cell Size'</span>, <span class="string">'Bare Nuclei'</span>, <span class="string">'Bland Chromatin'</span>,</span><br><span class="line">                   <span class="string">'Normal Nucleoli'</span>, <span class="string">'Mitoses'</span>, <span class="string">'Class'</span>]</span><br><span class="line">data = pd.read_csv(<span class="string">"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data"</span>,</span><br><span class="line">                       names=column_name)</span><br><span class="line"><span class="comment"># 2、数据处理—处理缺失值</span></span><br><span class="line">data = data.replace(to_replace=<span class="string">'?'</span>, value=np.nan)   <span class="comment">#1)替换np.nan</span></span><br><span class="line">data = data.dropna()    <span class="comment">#2)删除缺失值</span></span><br><span class="line">print(data.isnull().any()) <span class="comment">#确认不存在缺失值</span></span><br><span class="line"><span class="comment"># 取出特征值</span></span><br><span class="line">x = data[column_name[<span class="number">1</span>:<span class="number">10</span>]]  <span class="comment">#x=data.iloc[:,1:-1]</span></span><br><span class="line">y = data[column_name[<span class="number">10</span>]]   <span class="comment">#y=data['Class']</span></span><br><span class="line"><span class="comment">#3、分割数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.3</span>)</span><br><span class="line"><span class="comment">#4、特征工程—标准化</span></span><br><span class="line">std = StandardScaler()</span><br><span class="line">x_train = std.fit_transform(x_train)</span><br><span class="line">x_test = std.transform(x_test)</span><br><span class="line"><span class="comment"># 5、使用逻辑回归</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(x_train, y_train)</span><br><span class="line"><span class="comment">#逻辑回归的模型参数：回归系数和偏置</span></span><br><span class="line">print(<span class="string">"权重：\n"</span>, lr.coef_)</span><br><span class="line">print(<span class="string">"偏置：\n"</span>, lr.intercept_)</span><br><span class="line"><span class="comment">#6、模型评估</span></span><br><span class="line"><span class="comment">#方法1：直接比对真实值和预测值</span></span><br><span class="line">y_predict=lr.predict(x_test)</span><br><span class="line">print(<span class="string">'y_predict:\n'</span>,y_predict)</span><br><span class="line">print(<span class="string">'直接比对真实值和预测值：\n'</span>,y_test  y_predict)</span><br><span class="line"><span class="comment">#方法2：计算准确率</span></span><br><span class="line">score=lr.score(x_test,y_test)</span><br><span class="line">print(<span class="string">'准确率为：\n'</span>,score)</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">Sample code number             <span class="literal">False</span></span><br><span class="line">Clump Thickness                <span class="literal">False</span></span><br><span class="line">Uniformity of Cell Size        <span class="literal">False</span></span><br><span class="line">Uniformity of Cell Shape       <span class="literal">False</span></span><br><span class="line">Marginal Adhesion              <span class="literal">False</span></span><br><span class="line">Single Epithelial Cell Size    <span class="literal">False</span></span><br><span class="line">Bare Nuclei                    <span class="literal">False</span></span><br><span class="line">Bland Chromatin                <span class="literal">False</span></span><br><span class="line">Normal Nucleoli                <span class="literal">False</span></span><br><span class="line">Mitoses                        <span class="literal">False</span></span><br><span class="line">Class                          <span class="literal">False</span></span><br><span class="line">dtype: bool</span><br><span class="line">权重：</span><br><span class="line"> [[<span class="number">1.4449604</span>  <span class="number">0.10902357</span> <span class="number">0.64529009</span> <span class="number">1.02979746</span> <span class="number">0.2544256</span>  <span class="number">1.55064687</span></span><br><span class="line">  <span class="number">0.92516667</span> <span class="number">0.62683691</span> <span class="number">0.54739363</span>]]</span><br><span class="line">偏置：</span><br><span class="line"> [<span class="number">-1.08426503</span>]</span><br><span class="line">y_predict: <span class="comment">#注：2——良性  4——恶性</span></span><br><span class="line"> [<span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span></span><br><span class="line"> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span></span><br><span class="line"> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span></span><br><span class="line"> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span></span><br><span class="line"> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span></span><br><span class="line"> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">4</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span>]</span><br><span class="line">直接比对真实值和预测值：</span><br><span class="line"> <span class="number">221</span>    <span class="literal">True</span></span><br><span class="line"><span class="number">266</span>    <span class="literal">True</span></span><br><span class="line"><span class="number">4</span>      <span class="literal">True</span></span><br><span class="line"><span class="number">183</span>    <span class="literal">True</span></span><br><span class="line"><span class="number">341</span>    <span class="literal">True</span></span><br><span class="line">       ... </span><br><span class="line"><span class="number">55</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">132</span>    <span class="literal">True</span></span><br><span class="line"><span class="number">15</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">597</span>    <span class="literal">True</span></span><br><span class="line"><span class="number">479</span>    <span class="literal">True</span></span><br><span class="line">Name: Class, Length: <span class="number">205</span>, dtype: bool</span><br><span class="line">准确率为：</span><br><span class="line"> <span class="number">0.9707317073170731</span></span><br></pre></td></tr></table></figure></div><p>在很多分类场景当中我们不一定只关注预测的准确率！！！！！</p><p>比如以这个癌症举例子！！！我们并不关注预测的准确率，而是关注在所有的样本当中，癌症患者有没有被全部预测（检测）出来。</p><h3 id="分类模型的评估"><a href="#分类模型的评估" class="headerlink" title="分类模型的评估"></a>分类模型的评估</h3><p>准确率、精确率、召回率、f1_score，混淆矩阵，ks，ks曲线，ROC曲线，psi等。</p><h4 id="准确率、精确率、召回率、f1-score"><a href="#准确率、精确率、召回率、f1-score" class="headerlink" title="准确率、精确率、召回率、f1_score"></a>准确率、精确率、召回率、f1_score</h4><p><strong>准确率</strong>（Accuracy）的定义是：对于给定的测试集，分类模型正确分类的样本数与总样本数之比；</p><p>代码示例：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#1、准确率</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">y_pred = [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>,<span class="number">9</span>,<span class="number">9</span>,<span class="number">8</span>,<span class="number">5</span>,<span class="number">8</span>]</span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>,<span class="number">2</span>,<span class="number">6</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">9</span>]</span><br><span class="line"></span><br><span class="line">accuracy_score(y_true, y_pred)</span><br><span class="line">Out[<span class="number">127</span>]: <span class="number">0.33333333333333331</span></span><br><span class="line">    </span><br><span class="line">accuracy_score(y_true, y_pred, normalize=<span class="literal">False</span>)  <span class="comment"># 类似海明距离，每个类别求准确后，再求微平均</span></span><br><span class="line">Out[<span class="number">128</span>]: <span class="number">3</span></span><br></pre></td></tr></table></figure></div><p><strong>精确率</strong>(Precision)：预测结果为正例样本中真实为正例的比例（了解）</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/精确率.png" alt="精确率"></p><p><strong>召回率</strong>(Recall)：真实为正例的样本中预测结果为正例的比例（查的全，对正样本的区分能力）</p><p>召回率：查得全不全 应用：质量检测 次品</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/召回率.png" alt="召回率"></p><p>那么怎么更好理解这个两个概念</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/精确率与召回率理解.png" alt="精确率与召回率理解"></p><p><strong>F1_score</strong>：反映了模型的稳健型</p><p>在理想情况下，我们希望模型的精确率越高越好，同时召回率也越高越高，但是，现实情况往往事与愿违，在现实情况下，精确率和召回率像是坐在跷跷板上一样，往往出现一个值升高，另一个值降低，那么，有没有一个指标来综合考虑精确率和召回率了，这个指标就是F值。F值的计算公式为：</p><p>$F=\frac{(a^2+1)<em>P</em>R}{a^2*(P+R)}$ 式中：$P：Precision$，$R：Recall$，$a$：权重因子。</p><p>当$a=1$时，$F$值便是$F1$值，代表精确率和召回率的权重是一样的，是最常用的一种评价指标。</p><p>$F 1=\frac{2 T P}{2 T P+F N+F P}=\frac{2 \cdot \text { Precision } \cdot \text { Recall}}{\text { Precision }+\text { Recall}}$</p><h4 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h4><p>在分类任务下，预测结果(Predicted Condition)与正确标记(True Condition)之间存在四种不同的组合，构成混淆矩阵(适用于多分类)</p><p>混淆矩阵一级指标（最底层的）：</p><p>真实值是positive，模型认为是positive的数量（True Positive=TP）；</p><p>真实值是positive，模型认为是negative的数量（False Negative=FN）：这就是统计学上的第一类错误（Type I Error）；</p><p>真实值是negative，模型认为是positive的数量（False Positive=FP）：这就是统计学上的第二类错误（Type II Error）；</p><p>真实值是negative，模型认为是negative的数量（True Negative=TN）</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/20180531113257203.png" alt="img"></p><p>示例及实现代码</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 假如有一个模型在测试集上得到的预测结果为：</span></span><br><span class="line">y_true=[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>]<span class="comment"># 实际的类别  </span></span><br><span class="line">y_pred=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>]<span class="comment"># 模型预测的类别  </span></span><br><span class="line"><span class="comment">#使用sklearn模块计算混淆矩阵</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">confusion_mat=confusion_matrix(y_true,y_pred)</span><br><span class="line">print(confusion_mat) <span class="comment">#看看混淆矩阵长啥样 </span></span><br><span class="line"> </span><br><span class="line">[[<span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span>]]</span><br></pre></td></tr></table></figure></div><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/20190611144159116.png" alt="img"></p><p>混淆矩阵可视化</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_confusion_matrix</span><span class="params">(confusion_mat)</span>:</span>  <span class="comment">#将混淆矩阵画图并显示出来''' </span></span><br><span class="line">	plt.title(<span class="string">'Confusion matrix'</span>)</span><br><span class="line">	plt.imshow(confusion_mat,interpolation=<span class="string">'nearest'</span>,cmap=plt.cm.gray)</span><br><span class="line">	plt.colorbar()</span><br><span class="line">	tick_marks=np.arange(confusion_mat.shape[<span class="number">0</span>])</span><br><span class="line">	plt.xticks(tick_marks,tick_marks)</span><br><span class="line">	plt.yticks(tick_marks,tick_marks)</span><br><span class="line">	plt.ylabel(<span class="string">'True label'</span>)</span><br><span class="line">	plt.xlabel(<span class="string">'Predicted label'</span>)</span><br><span class="line">	plt.show()</span><br><span class="line">plot_confusion_matrix(confusion_mat)</span><br></pre></td></tr></table></figure></div><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/Figure_111.png" alt="Figure_111"></p><p><strong>分类评估报告API</strong></p><p>sklearn.metrics.classification_report(y_true, y_pred, labels=[], target_names=None )</p><ul><li>y_true：真实目标值</li><li>y_pred：估计器预测目标值</li><li>labels:指定类别对应的数字</li><li>target_names：目标类别名称</li><li>return：每个类别精确率与召回率</li></ul><p>上文逻辑回归进行癌症预测代码+下文代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">report=classification_report(y_test, lr.predict(x_test), labels=[<span class="number">2</span>, <span class="number">4</span>], target_names=[<span class="string">'良性'</span>, <span class="string">'恶性'</span>])</span><br><span class="line">print(<span class="string">"精确率和召回率为："</span>,report)</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">精确率和召回率为：               precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">                       良性       <span class="number">0.98</span>      <span class="number">0.98</span>      <span class="number">0.98</span>       <span class="number">132</span></span><br><span class="line">                       恶性       <span class="number">0.96</span>      <span class="number">0.97</span>      <span class="number">0.97</span>        <span class="number">73</span></span><br><span class="line"></span><br><span class="line">    accuracy                           <span class="number">0.98</span>       <span class="number">205</span></span><br><span class="line">   macro avg       <span class="number">0.97</span>      <span class="number">0.97</span>      <span class="number">0.97</span>       <span class="number">205</span></span><br><span class="line">weighted avg       <span class="number">0.98</span>      <span class="number">0.98</span>      <span class="number">0.98</span>       <span class="number">205</span></span><br></pre></td></tr></table></figure></div><p>二级指标</p><p>混淆矩阵里面统计的是个数，有时候面对大量的数据，光凭算个数，很难衡量模型的优劣。因此混淆矩阵在基本的统计结果上又延伸了如下4个指标，我称他们是二级指标（通过最底层指标加减乘除得到的）：</p><p>准确率（Accuracy）—— 针对整个模型</p><p>精确率（Precision）</p><p>灵敏度（Sensitivity）：就是召回率（Recall）</p><p>特异度（Specificity）</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/20180531115939413.png" alt="img"></p><p><strong>例：</strong></p><p>假设这样一个情况，如果99个样本癌症，1个样本非癌症，不管怎样我全都预测正例(默认癌症为正例),准确率就为99%但是这样效果并不好，这就是样本不均衡下的评估问题</p><p>解：准确率：99% 召回率：99/99=100% 精确率：99%</p><p>F1—score：2*99%/199%=99.497%</p><p>AUC：0.5 —不好的模型 AUC下文介绍</p><ul><li><p>TPR=100%</p></li><li><p>FPR=1/1=100%</p></li></ul><p>问题：如何衡量样本不均衡下的评估？</p><h4 id="ROC曲线和AUC计算"><a href="#ROC曲线和AUC计算" class="headerlink" title="ROC曲线和AUC计算"></a>ROC曲线和AUC计算</h4><p>计算ROC值</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line">y_true = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">y_scores = np.array([<span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.35</span>, <span class="number">0.8</span>])</span><br><span class="line">print(roc_auc_score(y_true, y_scores))</span><br><span class="line"></span><br><span class="line"><span class="number">0.75</span></span><br></pre></td></tr></table></figure></div><ul><li>TPR = TP / (TP + FN)<ul><li>所有真实类别为1的样本中，预测类别为1的比例</li></ul></li><li>FPR = FP / (FP + FN)<ul><li>所有真实类别为0的样本中，预测类别为1的比例</li></ul></li></ul><p><strong>ROC曲线</strong></p><ul><li>ROC曲线的横轴就是FPR，纵轴就是TPR，当二者相等时，表示的意义则是：对于不论真实类别是1还是0的样本，分类器预测为1的概率是相等的，此时AUC为0.5</li></ul><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/ROC.png" alt="ROC"></p><p><strong>AUC指标</strong></p><p>AUC(AUC值是一个概率值)的概率意义是随机取一对正负样本，正样本得分大于负样本的概率<br>AUC的最小值为0.5，最大值为1，取值越高越好<br>AUC=1，完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。<br>0.5&lt;AUC&lt;1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。</p><blockquote><p>AUC就是ROC 曲线下的面积，通常情况下数值介于0.5-1之间，可以评价分类器的好坏，数值越大说明越好。</p></blockquote><p><strong>AUC计算API</strong></p><p>from sklearn.metrics import roc_auc_score</p><p>sklearn.metrics.roc_auc_score(y_true, y_score)</p><ul><li>计算ROC曲线面积，即AUC值</li><li>y_true:每个样本的真实类别，必须为0(反例),1(正例)标记</li><li>y_score:每个样本预测的概率值</li></ul><p>代码（接上文代码）：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">print(y_test.head())</span><br><span class="line"><span class="comment">#y_true:每个样本的真实类别，必须为0（反例），1（正例）标记</span></span><br><span class="line"><span class="comment">#将y_test 转换成0和1</span></span><br><span class="line">y_test = np.where(y_test &gt; <span class="number">2.5</span>, <span class="number">1</span>, <span class="number">0</span>) <span class="comment">#y_test数值大于2.5设置为1，不大于设置为0</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line">print(<span class="string">"AUC指标："</span>, roc_auc_score(y_test, lr.predict(x_test)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ROC曲线</span></span><br><span class="line"><span class="comment"># y_score为模型预测正例的概率</span></span><br><span class="line">y_score = lr.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line"><span class="comment"># 计算不同阈值下，fpr和tpr的组合之，fpr表示1-Specificity，tpr表示Sensitivity</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">fpr, tpr, threshold = metrics.roc_curve(y_test, y_score)</span><br><span class="line"><span class="comment"># 计算AUC</span></span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line"><span class="comment"># 绘制面积图</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.stackplot(fpr, tpr, color=<span class="string">'steelblue'</span>, alpha=<span class="number">0.5</span>, edgecolor=<span class="string">'black'</span>)</span><br><span class="line"><span class="comment"># 添加ROC曲线的轮廓</span></span><br><span class="line">plt.plot(fpr, tpr, color=<span class="string">'black'</span>, lw=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 添加对角线作为参考线</span></span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">'red'</span>, linestyle=<span class="string">'--'</span>)</span><br><span class="line">plt.text(<span class="number">0.5</span>, <span class="number">0.3</span>, <span class="string">'ROC curve (area=%0.2f)'</span> % roc_auc)</span><br><span class="line">plt.xlabel(<span class="string">'1-Specificity'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Sensitivity'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="number">53</span>     <span class="number">4</span></span><br><span class="line"><span class="number">503</span>    <span class="number">2</span></span><br><span class="line"><span class="number">434</span>    <span class="number">2</span></span><br><span class="line"><span class="number">495</span>    <span class="number">2</span></span><br><span class="line"><span class="number">595</span>    <span class="number">2</span></span><br><span class="line">Name: Class, dtype: int64</span><br><span class="line">AUC指标： <span class="number">0.9556899934597778</span></span><br></pre></td></tr></table></figure></div><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/Figure_11.png" alt="Figure_11"></p><p><strong>总结</strong></p><ul><li>AUC只能用来评价二分类</li><li>AUC非常适合评价样本不平衡中的分类器性能</li></ul><h4 id="LIft和gain"><a href="#LIft和gain" class="headerlink" title="LIft和gain"></a>LIft和gain</h4><p>Lift图衡量的是，与不利用模型相比，模型的预测能力“变好”了多少，lift(提升指数)越大，模型的运行效果越好。<br>Gain图是描述整体精准度的指标。<br>计算公式如下：</p><p>$Lift=\frac{\frac{TP}{TP+FP}}{\frac{P}{P+N}}$</p><p>$Gain=\frac{TP}{TP+FP}$</p><p>作图步骤：<br>（1） 根据学习器的预测结果（注意，是正例的概率值，非0/1变量）对样本进行排序（从大到小）——-这就是截断点依次选取的顺序；<br>（2） 按顺序选取截断点，并计算Lift和Gain —-也可以只选取n个截断点，分别在1/n，2/n，3/n等位置</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/20180309191310524.png" alt="20180309191310524"></p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/20180309191506788.png" alt="20180309191506788"></p><h3 id="回归模型的评估"><a href="#回归模型的评估" class="headerlink" title="回归模型的评估"></a>回归模型的评估</h3><p>主要有以下方法：</p><div class="table-container"><table><thead><tr><th style="text-align:center"><strong>指标</strong></th><th><strong>描述</strong></th><th style="text-align:left"><strong>metrics方法</strong></th></tr></thead><tbody><tr><td style="text-align:center">Mean Absolute Error (MAE)</td><td>平均绝对误差</td><td style="text-align:left">from sklearn.metrics import mean_absolute_error</td></tr><tr><td style="text-align:center">Mean Square Error(MSE)</td><td>平均方差</td><td style="text-align:left">from sklearn.metrics import mean_squared_error</td></tr><tr><td style="text-align:center">R-Squared</td><td>R平方值</td><td style="text-align:left">from sklearn.metrics import r2_score</td></tr></tbody></table></div><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#sklearn的调用</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line"> </span><br><span class="line">mean_absolute_error(y_test,y_predict)</span><br><span class="line">mean_squared_error(y_test,y_predict)</span><br><span class="line">r2_score(y_test,y_predict)</span><br></pre></td></tr></table></figure></div><p>（一）<strong>平均绝对误差（Mean Absolute Error，MAE）</strong></p><p>平均绝对误差就是指预测值与真实值之间平均相差多大 ：</p><p>$MAE=\frac{1}{m}\sum_{i=1}^{m}|f_i-y_i|$</p><p>平均绝对误差能更好地反映预测值误差的实际情况.</p><p>（二）<strong>均方误差（Mean Squared Error，MSE）</strong></p><p>观测值与真值偏差的平方和与观测次数的比值：</p><p>$MSE=\frac{1}{m}\sum_{i=1}^{m}(f_i-y_i)^2$</p><p>这也是线性回归中最常用的损失函数，线性回归过程中尽量让该损失函数最小。那么模型之间的对比也可以用它来比较。MSE可以评价数据的变化程度，MSE的值越小，说明预测模型描述实验数据具有更好的精确度。</p><p>（三）<strong>R-square(决定系数)</strong></p><p>$R^2=1-\frac{\sum(Y_actual-Y_predict)^2}{\sum(Y_actual-Y_mean)^2}$</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#以线性回归为例</span></span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(x_train,y_train)</span><br><span class="line">y_ = lr.predict(X_test)</span><br><span class="line"><span class="comment"># R2 决定系数</span></span><br><span class="line">lr.score(X_test,y_test)   <span class="comment">#与用from sklearn.metrics import r2_score相同</span></span><br></pre></td></tr></table></figure></div><p>数学理解： 分母理解为原始数据的离散程度，分子为预测数据和原始数据的误差，二者相除可以消除原始数据离散程度的影响</p><p>其实“决定系数”是通过数据的变化来表征一个拟合的好坏。</p><p>理论上取值范围$ （-∞，1] $, 正常取值范围为[0 1] ———实际操作中通常会选择拟合较好的曲线计算R²，因此很少出现$-∞$</p><p>越接近1，表明方程的变量对y的解释能力越强，这个模型对数据拟合的也较好</p><p>越接近0，表明模型拟合的越差</p><p>经验值：&gt;0.4， 拟合效果好</p><p>缺点：数据集的样本越大，R²越大，因此，不同数据集的模型结果比较会有一定的误差</p><p>（四）<strong>Adjusted R-Square (校正决定系数）</strong></p><p>$R^2_adjusted=1-\frac{(1-R^2)(n-1)}{n-p-1}$</p><p>$n$为样本数量，$p$为特征数量</p><ul><li>消除了样本数量和特征数量的影响</li></ul><p>（五）<strong>交叉验证（Cross-Validation）</strong></p><p>交叉验证，有的时候也称作循环估计（Rotation Estimation），是一种统计学上将数据样本切割成较小子集的实用方法，该理论是由Seymour Geisser提出的。在给定的建模样本中，拿出大部分样本进行建模型，留小部分样本用刚建立的模型进行预报，并求这小部分样本的预报误差，记录它们的平方加和。这个过程一直进行，直到所有的样本都被预报了一次而且仅被预报一次。把每个样本的预报误差平方加和，称为PRESS(predicted Error Sum of Squares)。<br>交叉验证的基本思想是把在某种意义下将原始数据(dataset)进行分组,一部分做为训练集(train set)，另一部分做为验证集(validation set or test set)。首先用训练集对分类器进行训练，再利用验证集来测试训练得到的模型(model)，以此来做为评价分类器的性能指标。<br>无论分类还是回归模型，都可以利用交叉验证，进行模型评估，示例代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> cross_val_score</span><br><span class="line">print(cross_val_score(knn, X_train, y_train, cv=<span class="number">4</span>))</span><br><span class="line">print(cross_cal_score(lr, X, y, cv=<span class="number">2</span>))</span><br></pre></td></tr></table></figure></div><h3 id="模型保存和加载"><a href="#模型保存和加载" class="headerlink" title="模型保存和加载"></a>模型保存和加载</h3><p>当训练或者计算好一个模型之后，那么如果别人需要我们提供结果预测，就需要保存模型（主要是保存算法的参数）</p><h4 id="sklearn模型的保存和加载API"><a href="#sklearn模型的保存和加载API" class="headerlink" title="sklearn模型的保存和加载API"></a>sklearn模型的保存和加载API</h4><p>from sklearn.externals import joblib</p><ul><li><p>保存：joblib.dump(rf, ‘test.pkl’)</p></li><li><p>加载：estimator = joblib.load(‘test.pkl’)</p></li></ul><h4 id="线性回归的模型保存加载案例"><a href="#线性回归的模型保存加载案例" class="headerlink" title="线性回归的模型保存加载案例"></a>线性回归的模型保存加载案例</h4><p><strong>保存</strong></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#使用线性模型进行预测</span></span><br><span class="line"><span class="comment">#使用正规方程求解</span></span><br><span class="line">lr = LinearRegression()</span><br><span class="line"><span class="comment">#此时在干什么？</span></span><br><span class="line">lr.fit(x_train, y_train)</span><br><span class="line"><span class="comment">#保存训练完结束的模型</span></span><br><span class="line">joblib.dump(lr, <span class="string">"test.pkl"</span>)</span><br></pre></td></tr></table></figure></div><p><strong>加载</strong></p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#使用线性模型进行预测</span></span><br><span class="line"><span class="comment">#使用正规方程求解</span></span><br><span class="line"><span class="comment">#lr = LinearRegression()</span></span><br><span class="line"><span class="comment">#此时在干什么？</span></span><br><span class="line"><span class="comment">#lr.fit(x_train, y_train)</span></span><br><span class="line"><span class="comment">#保存训练完结束的模型</span></span><br><span class="line"><span class="comment">#joblib.dump(lr, "test.pkl")</span></span><br><span class="line"><span class="comment">#当上步模型已经保存好了就不需要训练fit和保存模型了</span></span><br><span class="line"><span class="comment">#通过已有的模型去预测房价</span></span><br><span class="line">model = joblib.load(<span class="string">"test.pkl"</span>)</span><br><span class="line">print(<span class="string">"从文件加载进来的模型预测房价的结果："</span>, std_y.inverse_transform(model.predict(x_test)))</span><br></pre></td></tr></table></figure></div><h2 id="无监督学习-K-means算法"><a href="#无监督学习-K-means算法" class="headerlink" title="无监督学习-K-means算法"></a>无监督学习-K-means算法</h2><h3 id="什么是无监督学习"><a href="#什么是无监督学习" class="headerlink" title="什么是无监督学习"></a>什么是无监督学习</h3><p>没有目标值—无监督学习</p><p><strong>例：</strong></p><ul><li><p>一家广告平台需要根据相似的人口学特征和购买习惯将美国人口分成不同的小组，以便广告客户可以通过有关联的广告接触到他们的目标客户。</p></li><li><p>Airbnb 需要将自己的房屋清单分组成不同的社区，以便用户能更轻松地查阅这些清单。</p></li><li>一个数据科学团队需要降低一个大型数据集的维度的数量，以便简化建模和降低文件大小。</li></ul><p>我们可以怎样最有用地对其进行归纳和分组？我们可以怎样以一种压缩格式有效地表征数据？这都是无监督学习的目标，之所以称之为无监督，是因为这是从无标签的数据开始学习的。</p><h3 id="无监督学习包含算法"><a href="#无监督学习包含算法" class="headerlink" title="无监督学习包含算法"></a>无监督学习包含算法</h3><ul><li>聚类<ul><li>K-means(K均值聚类)</li></ul></li><li>降维<ul><li>PCA</li></ul></li></ul><h3 id="K-means原理"><a href="#K-means原理" class="headerlink" title="K-means原理"></a>K-means原理</h3><p>我们先来看一下一个K-means的聚类效果图</p><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/K-means如何聚类效果.png" alt="K-means如何聚类效果"></p><h4 id="5-3-1-K-means聚类步骤"><a href="#5-3-1-K-means聚类步骤" class="headerlink" title="5.3.1. K-means聚类步骤"></a>5.3.1. K-means聚类步骤</h4><p>1、随机设置K个特征空间内的点作为初始的聚类中心</p><p>2、对于其他每个点计算到K个中心的距离，未知的点选择最近的一个聚类中心点作为标记类别</p><p>3、接着对着标记的聚类中心之后，重新计算出每个聚类的新中心点（平均值）</p><p>4、如果计算得出的新中心点与原中心点一样，那么结束，否则重新进行第二步过程</p><p>K—超参数 根据以下确定： 1）看需求；2）调节超参数</p><p>我们以一张图来解释效果<br><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/K-means过程分析.png" alt="K-means过程分析"></p><h3 id="K-means算法API"><a href="#K-means算法API" class="headerlink" title="K-means算法API"></a>K-means算法API</h3><p>sklearn.cluster.KMeans(n_clusters=8,init=‘k-means++’)</p><ul><li><p>k-means聚类</p></li><li><p>n_clusters:开始的聚类中心数量</p></li><li><p>init:初始化方法，默认为’k-means ++’</p></li><li><p>labels_:默认标记的类型，可以和真实值比较（不是值比较）</p></li></ul><h3 id="案例：k-means对Instacart-Market用户聚类"><a href="#案例：k-means对Instacart-Market用户聚类" class="headerlink" title="案例：k-means对Instacart Market用户聚类"></a>案例：k-means对Instacart Market用户聚类</h3><p><strong>分析</strong></p><ul><li>1、PCA降维数据</li><li>2、k-means聚类</li><li>3、聚类结果显示</li></ul><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 1、获取数据</span></span><br><span class="line">order_products = pd.read_csv(<span class="string">"./instacart/order_products__prior.csv"</span>)</span><br><span class="line">products = pd.read_csv(<span class="string">"./instacart/products.csv"</span>)</span><br><span class="line">orders = pd.read_csv(<span class="string">"./instacart/orders.csv"</span>)</span><br><span class="line">aisles = pd.read_csv(<span class="string">"./instacart/aisles.csv"</span>)</span><br><span class="line"><span class="comment"># 2、合并表</span></span><br><span class="line"><span class="comment"># order_products__prior.csv：订单与商品信息</span></span><br><span class="line"><span class="comment"># 字段：order_id, product_id, add_to_cart_order, reordered</span></span><br><span class="line"><span class="comment"># products.csv：商品信息</span></span><br><span class="line"><span class="comment"># 字段：product_id, product_name, aisle_id, department_id</span></span><br><span class="line"><span class="comment"># orders.csv：用户的订单信息</span></span><br><span class="line"><span class="comment"># 字段：order_id,user_id,eval_set,order_number,….</span></span><br><span class="line"><span class="comment"># aisles.csv：商品所属具体物品类别</span></span><br><span class="line"><span class="comment"># 字段： aisle_id, aisle</span></span><br><span class="line"><span class="comment"># 合并aisles和products aisle和product_id</span></span><br><span class="line">tab1 = pd.merge(aisles, products, on=[<span class="string">"aisle_id"</span>, <span class="string">"aisle_id"</span>])</span><br><span class="line">tab2 = pd.merge(tab1, order_products, on=[<span class="string">"product_id"</span>, <span class="string">"product_id"</span>])</span><br><span class="line">tab3 = pd.merge(tab2, orders, on=[<span class="string">"order_id"</span>, <span class="string">"order_id"</span>])</span><br><span class="line"><span class="comment">#print(tab3.head())</span></span><br><span class="line"><span class="comment"># 3、找到user_id和aisle之间的关系</span></span><br><span class="line">table = pd.crosstab(tab3[<span class="string">"user_id"</span>], tab3[<span class="string">"aisle"</span>])</span><br><span class="line">data = table[:<span class="number">10000</span>]  <span class="comment">#缩小数据</span></span><br><span class="line"><span class="comment"># 4、PCA降维</span></span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="comment"># 1）实例化一个转换器类</span></span><br><span class="line">transfer = PCA(n_components=<span class="number">0.95</span>)</span><br><span class="line"><span class="comment"># 2）调用fit_transform</span></span><br><span class="line">data_new = transfer.fit_transform(data)</span><br><span class="line">print(data_new.shape)</span><br><span class="line"><span class="comment">#5、预估器流程</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">estimator=KMeans(n_clusters=<span class="number">3</span>)</span><br><span class="line"><span class="comment">#KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,</span></span><br><span class="line"><span class="comment">#       n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',</span></span><br><span class="line"><span class="comment">#       random_state=None, tol=0.0001, verbose=0)</span></span><br><span class="line">estimator.fit(data_new)</span><br><span class="line">y_predict=estimator.predict(data_new)</span><br><span class="line">print(y_predict[:<span class="number">300</span>])</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">(<span class="number">10000</span>, <span class="number">42</span>)</span><br><span class="line">[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span></span><br><span class="line"> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span></span><br><span class="line"> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span></span><br><span class="line"> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span></span><br><span class="line"> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span></span><br><span class="line"> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span></span><br><span class="line"> <span class="number">2</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span></span><br><span class="line"> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span></span><br><span class="line"> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span>]</span><br></pre></td></tr></table></figure></div><p>问题：如何去评估聚类的效果呢？</p><h3 id="Kmeans性能评估指标"><a href="#Kmeans性能评估指标" class="headerlink" title="Kmeans性能评估指标"></a>Kmeans性能评估指标</h3><h4 id="轮廓系数"><a href="#轮廓系数" class="headerlink" title="轮廓系数"></a>轮廓系数</h4><p>$SC_i=\frac{b_i-a_i}{max(b_i,a_i)}$</p><blockquote><p>注：对于每个点 $i$为已聚类数据中的样本 ，$b_i$ 为 $i$ 到其它族群的所有样本的距离最小值，$a_i $为 $i$ 到本身簇的距离平均值。最终计算出所有的样本点的轮廓系数平均值</p></blockquote><h4 id="轮廓系数值分析"><a href="#轮廓系数值分析" class="headerlink" title="轮廓系数值分析"></a>轮廓系数值分析</h4><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/轮廓系数分析.png" alt="img"></p><p>分析过程（我们以一个蓝1点为例）</p><p>1、计算出蓝1离本身族群所有点的距离的平均值a_i</p><p>2、蓝1到其它两个族群的距离计算出平均值红平均，绿平均，取最小的那个距离作为b_i</p><p>根据公式：极端值考虑：如果b_i &gt;&gt;a_i: 那么公式结果趋近于1；如果a_i&gt;&gt;&gt;b_i: 那么公式结果趋近于-1</p><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>如果$b_i&gt;&gt;a_i$:趋近于1效果越好，$ b_i&lt;&lt;a_i$:趋近于-1，效果不好。轮廓系数的值是介于 [-1,1] ，越趋近于1代表内聚度和分离度都相对较优。</p><h4 id="轮廓系数API"><a href="#轮廓系数API" class="headerlink" title="轮廓系数API"></a>轮廓系数API</h4><p>sklearn.metrics.silhouette_score(X, labels)</p><ul><li>计算所有样本的平均轮廓系数</li><li>X：特征值</li><li>labels：被聚类标记的目标值</li></ul><h4 id="用户聚类结果评估"><a href="#用户聚类结果评估" class="headerlink" title="用户聚类结果评估"></a>用户聚类结果评估</h4><p>代码接上文代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#6、模型评估—轮廓系数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score</span><br><span class="line">print(silhouette_score(data_new,y_predict))</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="ANGELSCRIPT"><figure class="iseeu highlight /angelscript"><table><tr><td class="code"><pre><span class="line"><span class="number">0.5396819903993842</span></span><br></pre></td></tr></table></figure></div><h3 id="K-means总结"><a href="#K-means总结" class="headerlink" title="K-means总结"></a>K-means总结</h3><ul><li>特点分析：采用迭代式算法，直观易懂并且非常实用</li><li>缺点：容易收敛到局部最优解(多次聚类)</li></ul><p>注：聚类一般做在分类之前</p><h2 id="SVM算法"><a href="#SVM算法" class="headerlink" title="SVM算法"></a>SVM算法</h2><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#SVC算法进行癌症预测</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="comment"># 1、读取数据</span></span><br><span class="line">column_name = [<span class="string">'Sample code number'</span>, <span class="string">'Clump Thickness'</span>, <span class="string">'Uniformity of Cell Size'</span>, <span class="string">'Uniformity of Cell Shape'</span>,</span><br><span class="line">                   <span class="string">'Marginal Adhesion'</span>, <span class="string">'Single Epithelial Cell Size'</span>, <span class="string">'Bare Nuclei'</span>, <span class="string">'Bland Chromatin'</span>,</span><br><span class="line">                   <span class="string">'Normal Nucleoli'</span>, <span class="string">'Mitoses'</span>, <span class="string">'Class'</span>]</span><br><span class="line">data = pd.read_csv(<span class="string">"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data"</span>,</span><br><span class="line">                       names=column_name)</span><br><span class="line"><span class="comment"># 2、数据处理—处理缺失值</span></span><br><span class="line">data = data.replace(to_replace=<span class="string">'?'</span>, value=np.nan)   <span class="comment">#1)替换np.nan</span></span><br><span class="line">data = data.dropna()    <span class="comment">#2)删除缺失值</span></span><br><span class="line">print(data.isnull().any()) <span class="comment">#确认不存在缺失值</span></span><br><span class="line"><span class="comment"># 取出特征值</span></span><br><span class="line">x = data[column_name[<span class="number">1</span>:<span class="number">10</span>]]  <span class="comment">#x=data.iloc[:,1:-1]</span></span><br><span class="line">y = data[column_name[<span class="number">10</span>]]   <span class="comment">#y=data['Class']</span></span><br><span class="line"><span class="comment">#3、分割数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.3</span>)</span><br><span class="line"><span class="comment">#4、特征工程—标准化</span></span><br><span class="line">std = StandardScaler()</span><br><span class="line">x_train = std.fit_transform(x_train)</span><br><span class="line">x_test = std.transform(x_test)</span><br><span class="line"><span class="comment"># 5、使用SVC算法</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm                                <span class="comment">#支持向量机#</span></span><br><span class="line">module = svm.SVC()</span><br><span class="line">module.fit(x_train, y_train)</span><br><span class="line"><span class="comment">#6、模型评估</span></span><br><span class="line"><span class="comment">#方法1：直接比对真实值和预测值</span></span><br><span class="line">y_predict=module.predict(x_test)</span><br><span class="line">print(<span class="string">'y_predict:\n'</span>,y_predict)</span><br><span class="line">print(<span class="string">'直接比对真实值和预测值：\n'</span>,y_test  y_predict)</span><br><span class="line"><span class="comment">#方法2：计算准确率</span></span><br><span class="line">score=module.score(x_test,y_test)</span><br><span class="line">print(<span class="string">'准确率为：\n'</span>,score)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">report=classification_report(y_test, module.predict(x_test), labels=[<span class="number">2</span>, <span class="number">4</span>], target_names=[<span class="string">'良性'</span>, <span class="string">'恶性'</span>])</span><br><span class="line">print(<span class="string">"精确率和召回率为："</span>,report)</span><br><span class="line">print(y_test.head())</span><br><span class="line"><span class="comment">#y_true:每个样本的真实类别，必须为0（反例），1（正例）标记</span></span><br><span class="line"><span class="comment">#将y_test 转换成0和1</span></span><br><span class="line">y_test = np.where(y_test &gt; <span class="number">2.5</span>, <span class="number">1</span>, <span class="number">0</span>) <span class="comment">#y_test数值大于2.5设置为1，不大于设置为0</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line">print(<span class="string">"AUC指标："</span>, roc_auc_score(y_test, module.predict(x_test)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ROC曲线</span></span><br><span class="line"><span class="comment"># y_score为模型预测正例的概率</span></span><br><span class="line"><span class="comment">###通过decision_function()计算得到的y_score的值，用在roc_curve()函数中</span></span><br><span class="line">y_score = module.fit(x_train, y_train).decision_function(x_test)</span><br><span class="line"><span class="comment"># 计算不同阈值下，fpr和tpr的组合之，fpr表示1-Specificity，tpr表示Sensitivity</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">fpr, tpr, threshold = metrics.roc_curve(y_test, y_score)</span><br><span class="line"><span class="comment"># 计算AUC</span></span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line"><span class="comment"># 绘制面积图</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.stackplot(fpr, tpr, color=<span class="string">'steelblue'</span>, alpha=<span class="number">0.5</span>, edgecolor=<span class="string">'black'</span>)</span><br><span class="line"><span class="comment"># 添加ROC曲线的轮廓</span></span><br><span class="line">plt.plot(fpr, tpr, color=<span class="string">'black'</span>, lw=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 添加对角线作为参考线</span></span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">'red'</span>, linestyle=<span class="string">'--'</span>)</span><br><span class="line">plt.text(<span class="number">0.5</span>, <span class="number">0.3</span>, <span class="string">'ROC curve (area=%0.2f)'</span> % roc_auc)</span><br><span class="line">plt.xlabel(<span class="string">'1-Specificity'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Sensitivity'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div><p>输出结果：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line">Sample code number             <span class="literal">False</span></span><br><span class="line">Clump Thickness                <span class="literal">False</span></span><br><span class="line">Uniformity of Cell Size        <span class="literal">False</span></span><br><span class="line">Uniformity of Cell Shape       <span class="literal">False</span></span><br><span class="line">Marginal Adhesion              <span class="literal">False</span></span><br><span class="line">Single Epithelial Cell Size    <span class="literal">False</span></span><br><span class="line">Bare Nuclei                    <span class="literal">False</span></span><br><span class="line">Bland Chromatin                <span class="literal">False</span></span><br><span class="line">Normal Nucleoli                <span class="literal">False</span></span><br><span class="line">Mitoses                        <span class="literal">False</span></span><br><span class="line">Class                          <span class="literal">False</span></span><br><span class="line">dtype: bool</span><br><span class="line">y_predict:</span><br><span class="line"> [<span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span></span><br><span class="line"> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span></span><br><span class="line"> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span></span><br><span class="line"> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span></span><br><span class="line"> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span></span><br><span class="line"> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">2</span> <span class="number">4</span> <span class="number">4</span> <span class="number">4</span> <span class="number">2</span>]</span><br><span class="line">直接比对真实值和预测值：</span><br><span class="line"> <span class="number">492</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">236</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">208</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">518</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">81</span>      <span class="literal">True</span></span><br><span class="line">       ...  </span><br><span class="line"><span class="number">653</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">434</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">196</span>    <span class="literal">False</span></span><br><span class="line"><span class="number">210</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">137</span>     <span class="literal">True</span></span><br><span class="line">Name: Class, Length: <span class="number">205</span>, dtype: bool</span><br><span class="line">准确率为：</span><br><span class="line"> <span class="number">0.9658536585365853</span></span><br><span class="line">精确率和召回率为：               precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">          良性       <span class="number">0.99</span>      <span class="number">0.96</span>      <span class="number">0.97</span>       <span class="number">139</span></span><br><span class="line">          恶性       <span class="number">0.92</span>      <span class="number">0.98</span>      <span class="number">0.95</span>        <span class="number">66</span></span><br><span class="line"></span><br><span class="line">    accuracy                           <span class="number">0.97</span>       <span class="number">205</span></span><br><span class="line">   macro avg       <span class="number">0.95</span>      <span class="number">0.97</span>      <span class="number">0.96</span>       <span class="number">205</span></span><br><span class="line">weighted avg       <span class="number">0.97</span>      <span class="number">0.97</span>      <span class="number">0.97</span>       <span class="number">205</span></span><br><span class="line"></span><br><span class="line"><span class="number">492</span>    <span class="number">2</span></span><br><span class="line"><span class="number">236</span>    <span class="number">4</span></span><br><span class="line"><span class="number">208</span>    <span class="number">2</span></span><br><span class="line"><span class="number">518</span>    <span class="number">2</span></span><br><span class="line"><span class="number">81</span>     <span class="number">2</span></span><br><span class="line">Name: Class, dtype: int64</span><br><span class="line">AUC指标： <span class="number">0.9708415086112929</span></span><br></pre></td></tr></table></figure></div><p><img src="https://gitee.com/sky_mirrors_the_clouds/cloudimg/raw/master/https://gitee.com/sky_mirrors_the_clouds/cloudimg/机器学习图库/Figure_15.png" alt="Figure_15"></p><h2 id="GBDT算法"><a href="#GBDT算法" class="headerlink" title="GBDT算法"></a>GBDT算法</h2><p>代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="PYTHON"><figure class="iseeu highlight /python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#GBDT进行癌症预测</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="comment"># 1、读取数据</span></span><br><span class="line">column_name = [<span class="string">'Sample code number'</span>, <span class="string">'Clump Thickness'</span>, <span class="string">'Uniformity of Cell Size'</span>, <span class="string">'Uniformity of Cell Shape'</span>,</span><br><span class="line">                   <span class="string">'Marginal Adhesion'</span>, <span class="string">'Single Epithelial Cell Size'</span>, <span class="string">'Bare Nuclei'</span>, <span class="string">'Bland Chromatin'</span>,</span><br><span class="line">                   <span class="string">'Normal Nucleoli'</span>, <span class="string">'Mitoses'</span>, <span class="string">'Class'</span>]</span><br><span class="line">data = pd.read_csv(<span class="string">"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data"</span>,</span><br><span class="line">                       names=column_name)</span><br><span class="line"><span class="comment"># 2、数据处理—处理缺失值</span></span><br><span class="line">data = data.replace(to_replace=<span class="string">'?'</span>, value=np.nan)   <span class="comment">#1)替换np.nan</span></span><br><span class="line">data = data.dropna()    <span class="comment">#2)删除缺失值</span></span><br><span class="line">print(data.isnull().any()) <span class="comment">#确认不存在缺失值</span></span><br><span class="line"><span class="comment"># 取出特征值</span></span><br><span class="line">x = data[column_name[<span class="number">1</span>:<span class="number">10</span>]]  <span class="comment">#x=data.iloc[:,1:-1]</span></span><br><span class="line">y = data[column_name[<span class="number">10</span>]]   <span class="comment">#y=data['Class']</span></span><br><span class="line"><span class="comment">#3、分割数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.3</span>)</span><br><span class="line"><span class="comment">#4、特征工程—标准化</span></span><br><span class="line">std = StandardScaler()</span><br><span class="line">x_train = std.fit_transform(x_train)</span><br><span class="line">x_test = std.transform(x_test)</span><br><span class="line"><span class="comment"># 5、使用GBDT</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier      <span class="comment">#Gradient Boosting 和 AdaBoost算法#</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingRegressor</span><br><span class="line">module = GradientBoostingClassifier(n_estimators=<span class="number">100</span>, learning_rate=<span class="number">0.1</span>, max_depth=<span class="number">1</span>, random_state=<span class="number">0</span>)</span><br><span class="line">module.fit(x_train, y_train)</span><br><span class="line"><span class="comment">#6、模型评估</span></span><br><span class="line"><span class="comment">#方法1：直接比对真实值和预测值</span></span><br><span class="line">y_predict=module.predict(x_test)</span><br><span class="line">print(<span class="string">'y_predict:\n'</span>,y_predict)</span><br><span class="line">print(<span class="string">'直接比对真实值和预测值：\n'</span>,y_test  y_predict)</span><br><span class="line"><span class="comment">#方法2：计算准确率</span></span><br><span class="line">score=module.score(x_test,y_test)</span><br><span class="line">print(<span class="string">'准确率为：\n'</span>,score)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">report=classification_report(y_test, module.predict(x_test), labels=[<span class="number">2</span>, <span class="number">4</span>], target_names=[<span class="string">'良性'</span>, <span class="string">'恶性'</span>])</span><br><span class="line">print(<span class="string">"精确率和召回率为："</span>,report)</span><br><span class="line">print(y_test.head())</span><br><span class="line"><span class="comment">#y_true:每个样本的真实类别，必须为0（反例），1（正例）标记</span></span><br><span class="line"><span class="comment">#将y_test 转换成0和1</span></span><br><span class="line">y_test = np.where(y_test &gt; <span class="number">2.5</span>, <span class="number">1</span>, <span class="number">0</span>) <span class="comment">#y_test数值大于2.5设置为1，不大于设置为0</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line">print(<span class="string">"AUC指标："</span>, roc_auc_score(y_test, module.predict(x_test)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ROC曲线</span></span><br><span class="line"><span class="comment"># y_score为模型预测正例的概率</span></span><br><span class="line">y_score = module.predict_proba(x_test)[:, <span class="number">1</span>]</span><br><span class="line"><span class="comment"># 计算不同阈值下，fpr和tpr的组合之，fpr表示1-Specificity，tpr表示Sensitivity</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">fpr, tpr, threshold = metrics.roc_curve(y_test, y_score)</span><br><span class="line"><span class="comment"># 计算AUC</span></span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line"><span class="comment"># 绘制面积图</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.stackplot(fpr, tpr, color=<span class="string">'steelblue'</span>, alpha=<span class="number">0.5</span>, edgecolor=<span class="string">'black'</span>)</span><br><span class="line"><span class="comment"># 添加ROC曲线的轮廓</span></span><br><span class="line">plt.plot(fpr, tpr, color=<span class="string">'black'</span>, lw=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 添加对角线作为参考线</span></span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">'red'</span>, linestyle=<span class="string">'--'</span>)</span><br><span class="line">plt.text(<span class="number">0.5</span>, <span class="number">0.3</span>, <span class="string">'ROC curve (area=%0.2f)'</span> % roc_auc)</span><br><span class="line">plt.xlabel(<span class="string">'1-Specificity'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Sensitivity'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div><!-- rebuild by neat -->]]></content>
      <categories>
        <category>机器学习</category>
        <category>分类算法</category>
        <category>回归算法</category>
        <category>聚类算法</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo搭建个人博客系列：主题美化篇</title>
    <url>/hexo-theme-beautify.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><!-- build time:Mon Apr 20 2020 13:02:10 GMT+0800 (GMT+08:00) --><p><img src="http://yearito-1256884783.image.myqcloud.com/thumbnails/coast.jpg!thumbnail" alt="题图" title="Photo by Marina Weishaupt"></p><p>本文介绍了在Next主题的基础上进一步对博客进行美化的方案，主要包括:</p><ul><li>在文章末尾添加结束标记</li><li>修改侧边栏的位置到左边</li><li>添加不同类型的动态背景效果</li><li>添加 live2d 看板娘</li><li>为布局元素添加边缘弹性摆动效果</li><li>个性化回到顶部按钮</li><li>添加不同类型的鼠标点击特效</li><li>评论区输入打字礼花特效</li></ul><p>读者可以根据需要选择其中喜欢的方案应用到站点博客中。</p><a id="more"></a><h1 id="修改博客字体"><a href="#修改博客字体" class="headerlink" title="修改博客字体"></a>修改博客字体</h1><p>在 <a href="https://www.google.com/fonts" target="_blank" rel="noopener external nofollow noreferrer">Google Fonts</a> 上找到心仪的字体，然后在主题配置文件中为不同的应用场景配置字体：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="YAML"><figure class="iseeu highlight /yaml"><figcaption><span>themes\next\_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">font:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 外链字体库地址，例如 //fonts.googleapis.com (默认值)</span></span><br><span class="line">  <span class="attr">host:</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 全局字体，应用在 body 元素上</span></span><br><span class="line">  <span class="attr">global:</span></span><br><span class="line">    <span class="attr">external:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">family:</span> <span class="string">Monda</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 标题字体 (h1, h2, h3, h4, h5, h6)</span></span><br><span class="line">  <span class="attr">headings:</span></span><br><span class="line">    <span class="attr">external:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">family:</span> <span class="string">Roboto</span> <span class="string">Slab</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 文章字体</span></span><br><span class="line">  <span class="attr">posts:</span></span><br><span class="line">    <span class="attr">external:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">family:</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Logo 字体</span></span><br><span class="line">  <span class="attr">logo:</span></span><br><span class="line">    <span class="attr">external:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">family:</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 代码字体，应用于 code 以及代码块</span></span><br><span class="line">  <span class="attr">codes:</span></span><br><span class="line">    <span class="attr">external:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">family:</span></span><br></pre></td></tr></table></figure></div><h1 id="文章页末美化"><a href="#文章页末美化" class="headerlink" title="文章页末美化"></a>文章页末美化</h1><h2 id="为标签添加图标"><a href="#为标签添加图标" class="headerlink" title="为标签添加图标"></a>为标签添加图标</h2><p>默认情况下标签前缀是 <code>#</code> 字符，用户可以通过修改主题源码将标签的字符前缀改为图标前缀，更改后效果如下：</p><p><img src="http://yearito-1256884783.image.myqcloud.com/hexo-theme-beautify/20181113045027074.png" alt="标签图标前缀" title="标签图标前缀"></p><p>在文章布局模板中找到文末标签相关代码段，将 <code>#</code> 换成 <code>&lt;i class=&quot;fa fa-tags&quot;&gt;&lt;/i&gt;</code> 即可：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="DIFF"><figure class="iseeu highlight /diff"><figcaption><span>themes\next\layout\_macro\post.swig</span></figcaption><table><tr><td class="code"><pre><span class="line">  &lt;footer class="post-footer"&gt;</span><br><span class="line">    &#123;% if post.tags and post.tags.length and not is_index %&#125;</span><br><span class="line">      &lt;div class="post-tags"&gt;</span><br><span class="line">        &#123;% for tag in post.tags %&#125;</span><br><span class="line"><span class="deletion">-          &lt;a href="&#123;&#123; url_for(tag.path) &#125;&#125;" rel="tag"&gt;# &#123;&#123; tag.name &#125;&#125;&lt;/a&gt;</span></span><br><span class="line"><span class="addition">+          &lt;a href="&#123;&#123; url_for(tag.path) &#125;&#125;" rel="tag"&gt;&lt;i class="fa fa-tags"&gt;&lt;/i&gt; &#123;&#123; tag.name &#125;&#125;&lt;/a&gt;</span></span><br><span class="line">        &#123;% endfor %&#125;</span><br><span class="line">      &lt;/div&gt;</span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">    ...</span><br><span class="line">  &lt;/footer&gt;</span><br></pre></td></tr></table></figure></div><p>Next中使用 <a href="https://fontawesome.com/v4.7.0/icons/" target="_blank" rel="noopener external nofollow noreferrer">FontAwesome</a> 作为图标库，用户可以在 FontAwesome 上找到心仪的图标来替换标签的字符前缀。</p><h2 id="添加结束标记"><a href="#添加结束标记" class="headerlink" title="添加结束标记"></a>添加结束标记</h2><div class="note info"><p>本章节参考 <a href="https://asdfv1929.github.io/2018/01/28/add-the-end/" target="_blank" rel="noopener external nofollow noreferrer">asdfv1929 | Hexo NexT主题内给每篇文章后添加结束标语</a></p></div><p>在文末添加结束标记，效果如下：</p><p><img src="http://yearito-1256884783.image.myqcloud.com/hexo-theme-beautify/20181113045252399.png" alt="文末结束标记" title="文末结束标记"></p><p>新建布局模板文件 post-end-tag.swig，添加如下代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="HTML"><figure class="iseeu highlight /html"><figcaption><span>themes\next\layout\_macro\post-end-tag.swig</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">  &#123;% if not is_index %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">"text-align:center;color:#bfbfbf;font-size:16px;"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">span</span>&gt;</span>-------- 本文结束 <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"fa fa-&#123;&#123; config.post_end_tag.icon &#125;&#125;"</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">span</span>&gt;</span> 感谢阅读 --------<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  &#123;% endif %&#125;</span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure></div><p>在文章布局模板中添加如下代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="DIFF"><figure class="iseeu highlight /diff"><figcaption><span>themes\next\layout\_macro\post</span></figcaption><table><tr><td class="code"><pre><span class="line">&#123;#####################&#125;</span><br><span class="line">&#123;### END POST BODY ###&#125;</span><br><span class="line">&#123;#####################&#125;</span><br><span class="line"></span><br><span class="line"><span class="addition">+ &#123;% if config.post_end_tag.enabled and not is_index %&#125;</span></span><br><span class="line"><span class="addition">+   &lt;div&gt;</span></span><br><span class="line"><span class="addition">+     &#123;% include 'post-end-tag.swig' %&#125;</span></span><br><span class="line"><span class="addition">+   &lt;/div&gt;</span></span><br><span class="line"><span class="addition">+ &#123;% endif %&#125;</span></span><br><span class="line"></span><br><span class="line">&#123;% if theme.wechat_subscriber.enabled and not is_index %&#125;</span><br><span class="line">  &lt;div&gt;</span><br><span class="line">    &#123;% include 'wechat-subscriber.swig' %&#125;</span><br><span class="line">  &lt;/div&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure></div><p>在站点配置文件末尾添加如下代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="YAML"><figure class="iseeu highlight /yaml"><figcaption><span>_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">post_end_tag:</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span>  <span class="comment"># 是否开启文末的本文结束标记</span></span><br><span class="line">  <span class="attr">icon:</span> <span class="string">paw</span> <span class="comment"># 结束标记之间的图标</span></span><br></pre></td></tr></table></figure></div><p>重启服务器后即可在文末看到结束标记。</p><h1 id="页面加载进度条"><a href="#页面加载进度条" class="headerlink" title="页面加载进度条"></a>页面加载进度条</h1><p>当网络不好的时候可能会在打开站点或跳转文章时出现短暂的白屏，此时如果能有加载进度提示将会提高用户操作体验。</p><p>在根目录下执行以下命令安装相关依赖：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="CRYSTAL"><figure class="iseeu highlight /crystal"><table><tr><td class="code"><pre><span class="line">$ git clone <span class="symbol">https:</span>/<span class="regexp">/github.com/theme</span>-<span class="keyword">next</span>/theme-<span class="keyword">next</span>-pace themes/<span class="keyword">next</span>/source/<span class="class"><span class="keyword">lib</span>/<span class="title">pace</span></span></span><br></pre></td></tr></table></figure></div><p>在主题配置文件中设置 <code>pace: true</code>。</p><p>默认提供了多种主题的进度条加载样式，有顶部提示的，有中间提示的，还有全页面遮挡提示的，个人认为默认的进度条效果就恰如其当，既能够在页面空白的时候起到加载作用，也不会因为太过花里胡哨而喧宾夺主，尤其是当你如果使用了不蒜子的站点访问统计的功能的时候，常常会遇到所有资源都加载完毕而不蒜子还在等待响应，如果这个时候在页面较显眼的位置出现一个停滞不前的进度条，很让人抓狂。</p><h1 id="侧边栏放左边"><a href="#侧边栏放左边" class="headerlink" title="侧边栏放左边"></a>侧边栏放左边</h1><p>受 <a href="https://www.ofind.cn/" target="_blank" rel="noopener external nofollow noreferrer">猪猪侠的博客</a> 所启发，萌生了想把主题侧边栏放在左侧的想法。</p><p>Next主题各系列中只有Pisces和Gemini支持通过主题配置文件来将侧边栏置于左侧或右侧，而Muse和Mist则需要深度修改源码才能实现改变侧边栏位置。</p><p>在自定义样式文件中添加如下规则：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="CSS"><figure class="iseeu highlight /css"><figcaption><span>themes\next\source\css\_custom\custom.styl</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.sidebar-toggle</span> &#123;</span><br><span class="line">  <span class="attribute">left</span>: <span class="number">30px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.sidebar</span> &#123;</span><br><span class="line">  <span class="attribute">left</span>: <span class="number">0px</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>修改动效脚本代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="DIFF"><figure class="iseeu highlight /diff"><figcaption><span>themes\next\source\js\src\motion.js</span></figcaption><table><tr><td class="code"><pre><span class="line">$(document)</span><br><span class="line">  .on('sidebar.isShowing', function() &#123;</span><br><span class="line">    NexT.utils.isDesktop() &amp;&amp; $('body').velocity('stop').velocity(</span><br><span class="line"><span class="deletion">-     &#123;paddingRight: SIDEBAR_WIDTH&#125;,</span></span><br><span class="line"><span class="addition">+     &#123;paddingLeft: SIDEBAR_WIDTH&#125;,</span></span><br><span class="line">      SIDEBAR_DISPLAY_DURATION</span><br><span class="line">    );</span><br><span class="line">  &#125;)</span><br><span class="line">  .on('sidebar.isHiding', function() &#123;</span><br><span class="line">  &#125;);</span><br><span class="line">  ...</span><br><span class="line">  hideSidebar: function() &#123;</span><br><span class="line"><span class="deletion">-   NexT.utils.isDesktop() &amp;&amp; $('body').velocity('stop').velocity(&#123;paddingRight: 0&#125;);</span></span><br><span class="line"><span class="addition">+   NexT.utils.isDesktop() &amp;&amp; $('body').velocity('stop').velocity(&#123;paddingLeft: 0&#125;);</span></span><br><span class="line">    this.sidebarEl.find('.motion-element').velocity('stop').css('display', 'none');</span><br><span class="line">    this.sidebarEl.velocity('stop').velocity(&#123;width: 0&#125;, &#123;display: 'none'&#125;);</span><br><span class="line"></span><br><span class="line">    sidebarToggleLines.init();</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>如此以来就可以将侧边栏放置在左边了，但当窗口宽度缩小到991px之后会出现样式错误：侧边栏收缩消失但是页面左侧仍留有空白间距，此时修改如下代码即可：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="DIFF"><figure class="iseeu highlight /diff"><figcaption><span>themes\next\source\css\_common\scaffolding\base.styl</span></figcaption><table><tr><td class="code"><pre><span class="line">body &#123;</span><br><span class="line">  position: relative; // Required by scrollspy</span><br><span class="line">  font-family: $font-family-base;</span><br><span class="line">  font-size: $font-size-base;</span><br><span class="line">  line-height: $line-height-base;</span><br><span class="line">  color: $text-color;</span><br><span class="line">  background: $body-bg-color;</span><br><span class="line"></span><br><span class="line"><span class="deletion">- +mobile() &#123; padding-left: 0 !important; &#125;</span></span><br><span class="line"><span class="deletion">- +tablet() &#123; padding-left: 0 !important; &#125;  </span></span><br><span class="line"><span class="addition">+ +mobile() &#123; padding-right: 0 !important; &#125;</span></span><br><span class="line"><span class="addition">+ +tablet() &#123; padding-right: 0 !important; &#125;</span></span><br><span class="line">  +desktop-large() &#123; font-size: $font-size-large; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h1 id="添加动态背景"><a href="#添加动态背景" class="headerlink" title="添加动态背景"></a>添加动态背景</h1><p>Next主题可以通过安装插件快速为站点添加不同效果的动态背景。</p><h2 id="粒子漂浮聚合"><a href="#粒子漂浮聚合" class="headerlink" title="粒子漂浮聚合"></a>粒子漂浮聚合</h2><p>应用效果如下图：</p><p><img src="http://yearito-1256884783.image.myqcloud.com/hexo-theme-beautify/20181115092103046.png" alt="canvas-nest 动态背景" title="canvas-nest 动态背景"></p><p>该功能由 <a href="https://github.com/theme-next/theme-next-canvas-nest" target="_blank" rel="noopener external nofollow noreferrer">theme-next-canvas-nest</a> 插件提供，在根目录下执行如下命令：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="CRYSTAL"><figure class="iseeu highlight /crystal"><table><tr><td class="code"><pre><span class="line">$ git clone <span class="symbol">https:</span>/<span class="regexp">/github.com/theme</span>-<span class="keyword">next</span>/theme-<span class="keyword">next</span>-canvas-nest themes/<span class="keyword">next</span>/source/<span class="class"><span class="keyword">lib</span>/<span class="title">canvas</span>-<span class="title">nest</span></span></span><br></pre></td></tr></table></figure></div><p>然后在主题配置文件中设置 <code>canvas_nest: true</code> 即可。</p><p>Next v6.5.0 及以上版本支持更多的自定义选项：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="YAML"><figure class="iseeu highlight /yaml"><figcaption><span>themes\next\_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">canvas_nest:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">onmobile:</span> <span class="literal">true</span> <span class="comment"># 是否在移动端显示</span></span><br><span class="line">  <span class="attr">color:</span> <span class="string">'0,0,255'</span> <span class="comment"># 动态背景中线条的 RGB 颜色</span></span><br><span class="line">  <span class="attr">opacity:</span> <span class="number">0.5</span> <span class="comment"># 动态背景中线条透明度</span></span><br><span class="line">  <span class="attr">zIndex:</span> <span class="number">-1</span> <span class="comment"># 动态背景的 z-index 属性值</span></span><br><span class="line">  <span class="attr">count:</span> <span class="number">99</span> <span class="comment"># 动态背景中线条数量</span></span><br></pre></td></tr></table></figure></div><h2 id="Three-三维动效"><a href="#Three-三维动效" class="headerlink" title="Three 三维动效"></a>Three 三维动效</h2><p><a href="https://github.com/theme-next/theme-next-three" target="_blank" rel="noopener external nofollow noreferrer">theme-next-three</a> 插件提供了三个类型的背景动效，应用效果如下：</p><div class="tabs" id="three-三维动效"><ul class="nav-tabs"><li class="tab active"><a href="#three-三维动效-1">three-waves</a></li><li class="tab"><a href="#three-三维动效-2">canvas-lines</a></li><li class="tab"><a href="#three-三维动效-3">canvas-sphere</a></li></ul><div class="tab-content"><div class="tab-pane active" id="three-三维动效-1"><p><img src="http://yearito-1256884783.image.myqcloud.com/hexo-theme-beautify/20181115091950761.png" alt></p></div><div class="tab-pane" id="three-三维动效-2"><p><img src="http://yearito-1256884783.image.myqcloud.com/hexo-theme-beautify/20181115091914602.png" alt></p></div><div class="tab-pane" id="three-三维动效-3"><p><img src="http://yearito-1256884783.image.myqcloud.com/hexo-theme-beautify/20181115091826700.png" alt></p></div></div></div><p>在根目录下执行如下命令安装相关依赖：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="CRYSTAL"><figure class="iseeu highlight /crystal"><table><tr><td class="code"><pre><span class="line">$ git clone <span class="symbol">https:</span>/<span class="regexp">/github.com/theme</span>-<span class="keyword">next</span>/theme-<span class="keyword">next</span>-three themes/<span class="keyword">next</span>/source/<span class="class"><span class="keyword">lib</span>/<span class="title">three</span></span></span><br></pre></td></tr></table></figure></div><p>然后在主题配置文件中设置开启对应的动效选项即可。</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="YAML"><figure class="iseeu highlight /yaml"><figcaption><span>themes\next\_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># JavaScript 3D library.</span></span><br><span class="line"><span class="comment"># Dependencies: https://github.com/theme-next/theme-next-three</span></span><br><span class="line"><span class="comment"># three_waves</span></span><br><span class="line"><span class="attr">three_waves:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># canvas_lines</span></span><br><span class="line"><span class="attr">canvas_lines:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># canvas_sphere</span></span><br><span class="line"><span class="attr">canvas_sphere:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></div><div class="note info"><p>个人认为在站点中添加动态背景并没有实际的意义，只会凭空增加页面内存占用及CPU消耗，所以本站没有添加任何动态背景。</p></div><h2 id="随机三角丝带"><a href="#随机三角丝带" class="headerlink" title="随机三角丝带"></a>随机三角丝带</h2><p><img src="http://yearito-1256884783.image.myqcloud.com/hexo-theme-beautify/evan-you.png" alt="随机三角丝带" title="随机三角丝带"></p><div class="note info"><p>该功能由 Vue 作者 <a href="http://evanyou.me/" target="_blank" rel="noopener external nofollow noreferrer">尤雨溪</a> 首创。本章节中核心代码来源于 <a href="https://diygod.me/" target="_blank" rel="noopener external nofollow noreferrer">DIYgod</a> 编写的 <a href="https://github.com/DIYgod/hexo-theme-sagiri" target="_blank" rel="noopener external nofollow noreferrer">sagiri</a> 主题。</p></div><p>点击下方按钮下载相应的脚本，并置于 themes\\next\\source\\js\ 目录下：</p><p><a class="btn" href="https://script-1256884783.file.myqcloud.com/evan-you.js" target="_blank" rel="noopener external nofollow noreferrer"><i class="fa fa-download fa-fw"></i>随机三角丝带</a></p><p>在主题自定义布局文件中添加以下代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="HTML"><figure class="iseeu highlight /html"><figcaption><span>themes\next\layout\_custom\custom.swig</span></figcaption><table><tr><td class="code"><pre><span class="line">&#123;# 随机三角丝带背景 #&#125;</span><br><span class="line">&#123;% if theme.evanyou %&#125;</span><br><span class="line">  <span class="tag">&lt;<span class="name">canvas</span> <span class="attr">id</span>=<span class="string">"evanyou"</span>&gt;</span><span class="tag">&lt;/<span class="name">canvas</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="css">    <span class="selector-id">#evanyou</span> &#123;</span></span><br><span class="line">      position: fixed;</span><br><span class="line">      width: 100%;</span><br><span class="line">      height: 100%;</span><br><span class="line">      top: 0;</span><br><span class="line">      left: 0;</span><br><span class="line">      z-index: -1;</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"/js/evan-you.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure></div><p>如果 custom.swig 文件不存在，需要手动新建并在布局页面中 body 末尾引入：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="DIFF"><figure class="iseeu highlight /diff"><figcaption><span>themes\next\layout\_layout.swig</span></figcaption><table><tr><td class="code"><pre><span class="line">      ...</span><br><span class="line">      &#123;% include '_third-party/exturl.swig' %&#125;</span><br><span class="line">      &#123;% include '_third-party/bookmark.swig' %&#125;</span><br><span class="line">      &#123;% include '_third-party/copy-code.swig' %&#125;</span><br><span class="line"></span><br><span class="line"><span class="addition">+     &#123;% include '_custom/custom.swig' %&#125;</span></span><br><span class="line">    &lt;/body&gt;</span><br><span class="line">  &lt;/html&gt;</span><br></pre></td></tr></table></figure></div><p>在主题配置文件中添加以下代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="YAML"><figure class="iseeu highlight /yaml"><figcaption><span>themes\next\_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># colorful trilateral riband background</span></span><br><span class="line"><span class="attr">evanyou:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></div><p>如果从本地加载JS脚本速度较慢，可以考虑将脚本放到CDN上再引入。</p><h1 id="添加看板娘"><a href="#添加看板娘" class="headerlink" title="添加看板娘"></a>添加看板娘</h1><div class="note info"><p>本章节部分内容参考 <a href="https://fjkang.github.io/2017/12/08/%E6%B7%BB%E5%8A%A0%E4%B8%80%E4%B8%AA%E8%90%8C%E7%89%A9/" target="_blank" rel="noopener external nofollow noreferrer">FJKang | 添加一个萌物</a></p></div><p>该功能由 <a href="https://github.com/EYHN/hexo-helper-live2d" target="_blank" rel="noopener external nofollow noreferrer">hexo-helper-live2d</a> 插件支持，效果如下图：</p><p><img src="http://yearito-1256884783.image.myqcloud.com/hexo-theme-beautify/live2d.gif" alt="live2d 看板娘" title="live2d 看板娘"></p><p>在站点根目录下执行以下命令安装依赖：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="SQL"><figure class="iseeu highlight /sql"><table><tr><td class="code"><pre><span class="line">$ npm <span class="keyword">install</span> <span class="comment">--save hexo-helper-live2d</span></span><br></pre></td></tr></table></figure></div><p>在站点配置文件中添加以下下配置项</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="YAML"><figure class="iseeu highlight /yaml"><figcaption><span>_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># Live2D</span></span><br><span class="line"><span class="comment"># https://github.com/EYHN/hexo-helper-live2d</span></span><br><span class="line"><span class="attr">live2d:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">pluginRootPath:</span> <span class="string">live2dw/</span></span><br><span class="line">  <span class="attr">pluginJsPath:</span> <span class="string">lib/</span></span><br><span class="line">  <span class="attr">pluginModelPath:</span> <span class="string">assets/</span> <span class="string">Relative)</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 脚本加载源</span></span><br><span class="line">  <span class="attr">scriptFrom:</span> <span class="string">local</span> <span class="comment"># 默认从本地加载脚本</span></span><br><span class="line">  <span class="comment"># scriptFrom: jsdelivr # 从 jsdelivr CDN 加载脚本</span></span><br><span class="line">  <span class="comment"># scriptFrom: unpkg # 从 unpkg CDN 加载脚本</span></span><br><span class="line">  <span class="comment"># scriptFrom: https://cdn.jsdelivr.net/npm/live2d-widget@3.x/lib/L2Dwidget.min.js # 从自定义地址加载脚本</span></span><br><span class="line">  <span class="attr">tagMode:</span> <span class="literal">false</span> <span class="comment"># 只在有 &#123;&#123; live2d() &#125;&#125; 标签的页面上加载 / 在所有页面上加载</span></span><br><span class="line">  <span class="attr">log:</span> <span class="literal">false</span> <span class="comment"># 是否在控制台打印日志</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 选择看板娘模型</span></span><br><span class="line">  <span class="attr">model:</span></span><br><span class="line">    <span class="attr">use:</span> <span class="string">live2d-widget-model-shizuku</span>  <span class="comment"># npm package的名字</span></span><br><span class="line">    <span class="comment"># use: wanko # /live2d_models/ 目录下的模型文件夹名称</span></span><br><span class="line">    <span class="comment"># use: ./wives/wanko # 站点根目录下的模型文件夹名称</span></span><br><span class="line">    <span class="comment"># use: https://cdn.jsdelivr.net/npm/live2d-widget-model-wanko@1.0.5/assets/wanko.model.json # 自定义网络数据源</span></span><br><span class="line">  <span class="attr">display:</span></span><br><span class="line">    <span class="attr">position:</span> <span class="string">left</span> <span class="comment"># 显示在左边还是右边</span></span><br><span class="line">    <span class="attr">width:</span> <span class="number">100</span> <span class="comment"># 宽度</span></span><br><span class="line">    <span class="attr">height:</span> <span class="number">180</span> <span class="comment"># 高度</span></span><br><span class="line">  <span class="attr">mobile:</span></span><br><span class="line">    <span class="attr">show:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">react:</span></span><br><span class="line">    <span class="attr">opacityDefault:</span> <span class="number">0.7</span> <span class="comment"># 默认透明度</span></span><br></pre></td></tr></table></figure></div><div class="note info"><p>更多配置参数请查看 <a href="https://l2dwidget.js.org/docs/class/src/index.js~L2Dwidget.html#instance-method-init" target="_blank" rel="noopener external nofollow noreferrer">L2Dwidget | live2d-widget.js</a></p></div><p>此时重启服务器暂时还看不到看板娘，需要手动下载或安装模型资源。可以从 <a href="https://huaji8.top/post/live2d-plugin-2.0/" target="_blank" rel="noopener external nofollow noreferrer">hexo live2d 模型预览</a> 里找到你喜欢的角色，然后根据 <a href="https://github.com/xiazeyu/live2d-widget-models" target="_blank" rel="noopener external nofollow noreferrer">live2d-widget-models</a> 中提供的方法来下载模型数据.</p><p>例如通过以下命令下载模型 shizuku：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="GAMS"><figure class="iseeu highlight /gams"><table><tr><td class="code"><pre><span class="line"><span class="symbol">$</span> npm install live2d-widget-<span class="keyword">model</span>-shizuku</span><br></pre></td></tr></table></figure></div><p>因为修改了站点配置文件，所以需要重启服务器才能预览模型效果。</p><p>如果设置了 <code>live2d.tagMode: true</code>，则可以在指定页面中插入以下标签：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="YAML"><figure class="iseeu highlight /yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&#123;&#123;</span> <span class="string">live2d()</span> <span class="string">&#125;&#125;</span></span><br></pre></td></tr></table></figure></div><p>只有拥有该标签的页面才会渲染live2d模型，这样以来就可以精确控制在哪些页面上显示看板娘了。</p><p>如果只想在一级菜单页面上显示看板娘，可以在Header模板中添加以下代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="DIFF"><figure class="iseeu highlight /diff"><figcaption><span>themes\next\layout\_partials\header\index.swig</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="addition">+ &#123;% if is_index %&#125;</span></span><br><span class="line"><span class="addition">+   &#123;&#123; live2d() &#125;&#125;</span></span><br><span class="line"><span class="addition">+ &#123;% endif %&#125;</span></span><br></pre></td></tr></table></figure></div><div class="note info"><p>个人认为在文章内出现看板娘将会影响读者注意力的集中，毕竟一篇博客里最重要的是内容，而不是这些花里胡哨转移注意力的东西。所以本站只在一级菜单页面添加了看板娘，文章页面则保持极致精简的阅读体验。</p></div><p>经过测试发现 <code>live2d.mobile.show: false</code> 并没有生效，暂时没有找到好的解决方法，参考 <a href="https://github.com/EYHN/hexo-helper-live2d/issues/12" target="_blank" rel="noopener external nofollow noreferrer">EYHN/hexo-helper-live2d Issues #12</a> 后发现可以在自定义样式文件中添加以下代码来解决：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="CSS"><figure class="iseeu highlight /css"><figcaption><span>themes/next/source/css/_custom/custom.styl</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="selector-id">#live2dcanvas</span> &#123;</span><br><span class="line">  +mobile() &#123;</span><br><span class="line">    <span class="selector-tag">display</span>: <span class="selector-tag">none</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  +<span class="selector-tag">tablet</span>() &#123;</span><br><span class="line">    <span class="attribute">display</span>: none;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><div class="note info"><p>不要乱点不该点的地方，会生气的。</p></div><h1 id="边缘摆动效果"><a href="#边缘摆动效果" class="headerlink" title="边缘摆动效果"></a>边缘摆动效果</h1><p><img src="http://yearito-1256884783.image.myqcloud.com/hexo-theme-beautify/wobblewindow.gif" alt="wobblewindow 边缘摆动" title="wobblewindow 边缘摆动"></p><p>在 <a href="https://www.ofind.cn/" target="_blank" rel="noopener external nofollow noreferrer">猪猪侠的博客</a> 里发现的这种特效，觉得挺有意思的，就从他Github上给扒过来了</p><p>点击下方按钮下载脚本，并置于 themes\\next\\source\\js\ 目录下：</p><p><a class="btn" href="https://script-1256884783.file.myqcloud.com/wobblewindow.js" target="_blank" rel="noopener external nofollow noreferrer"><i class="fa fa-download fa-fw"></i>wobblewindow.js</a></p><p>在主题自定义布局文件中添加以下代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="HTML"><figure class="iseeu highlight /html"><figcaption><span>themes\next\layout\_custom\custom.swig</span></figcaption><table><tr><td class="code"><pre><span class="line">&#123;# wobble窗口摆动特效 #&#125;</span><br><span class="line">&#123;% if theme.wobble %&#125;</span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"/js/wobblewindow.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="actionscript">    <span class="comment">//只在桌面版网页启用特效</span></span></span><br><span class="line"><span class="javascript">    <span class="keyword">if</span>( <span class="built_in">window</span>.innerWidth &gt; <span class="number">768</span>  )&#123;</span></span><br><span class="line"><span class="javascript">      $(<span class="built_in">document</span>).ready(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span></span><br><span class="line">        &#123;% if theme.wobble.header %&#125;</span><br><span class="line"><span class="javascript">          $(<span class="string">'#header'</span>).wobbleWindow(&#123;</span></span><br><span class="line"><span class="handlebars"><span class="xml">            radius: </span><span class="template-variable">&#123;&#123; theme.wobble.radius &#125;&#125;</span><span class="xml">,</span></span></span><br><span class="line"><span class="actionscript">            movementTop: <span class="literal">false</span>,</span></span><br><span class="line"><span class="actionscript">            movementLeft: <span class="literal">false</span>,</span></span><br><span class="line"><span class="actionscript">            movementRight: <span class="literal">false</span>,</span></span><br><span class="line"><span class="actionscript">            debug: <span class="literal">false</span>,</span></span><br><span class="line">          &#125;);</span><br><span class="line">        &#123;% endif %&#125;</span><br><span class="line"></span><br><span class="line">        &#123;% if theme.wobble.sidebar %&#125;</span><br><span class="line"><span class="javascript">          $(<span class="string">'#sidebar'</span>).wobbleWindow(&#123;</span></span><br><span class="line"><span class="handlebars"><span class="xml">            radius: </span><span class="template-variable">&#123;&#123; theme.wobble.radius &#125;&#125;</span><span class="xml">,</span></span></span><br><span class="line"><span class="actionscript">            movementLeft: <span class="literal">false</span>,</span></span><br><span class="line"><span class="actionscript">            movementTop: <span class="literal">false</span>,</span></span><br><span class="line"><span class="actionscript">            movementBottom: <span class="literal">false</span>,</span></span><br><span class="line"><span class="actionscript">            position: <span class="string">'fixed'</span>,</span></span><br><span class="line"><span class="actionscript">            debug: <span class="literal">false</span>,</span></span><br><span class="line">          &#125;);</span><br><span class="line">        &#123;% endif %&#125;</span><br><span class="line"></span><br><span class="line">        &#123;% if theme.wobble.footer %&#125;</span><br><span class="line"><span class="javascript">          $(<span class="string">'#footer'</span>).wobbleWindow(&#123;</span></span><br><span class="line"><span class="handlebars"><span class="xml">            radius: </span><span class="template-variable">&#123;&#123; theme.wobble.radius &#125;&#125;</span><span class="xml">,</span></span></span><br><span class="line"><span class="actionscript">            movementBottom: <span class="literal">false</span>,</span></span><br><span class="line"><span class="actionscript">            movementLeft: <span class="literal">false</span>,</span></span><br><span class="line"><span class="actionscript">            movementRight: <span class="literal">false</span>,</span></span><br><span class="line"><span class="handlebars"><span class="xml">            offsetX: </span><span class="template-variable">&#123;&#123; theme.wobble.offset &#125;&#125;</span><span class="xml">,</span></span></span><br><span class="line"><span class="actionscript">            position: <span class="string">'absolute'</span>,</span></span><br><span class="line"><span class="actionscript">            debug: <span class="literal">false</span>,</span></span><br><span class="line">          &#125;);</span><br><span class="line">        &#123;% endif %&#125;</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure></div><p>如果 custom.swig 文件不存在，需要手动新建并在布局页面中 body 末尾引入：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="DIFF"><figure class="iseeu highlight /diff"><figcaption><span>themes\next\layout\_layout.swig</span></figcaption><table><tr><td class="code"><pre><span class="line">      ...</span><br><span class="line">      &#123;% include '_third-party/exturl.swig' %&#125;</span><br><span class="line">      &#123;% include '_third-party/bookmark.swig' %&#125;</span><br><span class="line">      &#123;% include '_third-party/copy-code.swig' %&#125;</span><br><span class="line"></span><br><span class="line"><span class="addition">+     &#123;% include '_custom/custom.swig' %&#125;</span></span><br><span class="line">    &lt;/body&gt;</span><br><span class="line">  &lt;/html&gt;</span><br></pre></td></tr></table></figure></div><p>在自定义样式文件中添加以下样式：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="CSS"><figure class="iseeu highlight /css"><figcaption><span>themes\next\source\css\_custom\custom.styl</span></figcaption><table><tr><td class="code"><pre><span class="line">//窗口波动效果相关样式</span><br><span class="line">if hexo-config('wobble')  &#123;</span><br><span class="line">  <span class="selector-class">.sidebar</span> &#123;</span><br><span class="line">    <span class="attribute">box-shadow</span>: none;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="selector-class">.wobbleTransparentBK</span>&#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>) <span class="meta">!important</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="selector-class">.wobbleTransparentLine</span>&#123;</span><br><span class="line">    <span class="attribute">border-color</span>: <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>) <span class="meta">!important</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  //Next.Muse中为Header和Footer添加背景色</span><br><span class="line">  <span class="selector-id">#header</span>, <span class="selector-id">#footer</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="built_in">rgb</span>(<span class="number">245</span>, <span class="number">245</span>, <span class="number">245</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  //防止sidebar和footer同时开启动效时堆叠异常</span><br><span class="line">  <span class="selector-id">#sidebar</span>, <span class="selector-tag">header</span> &#123;</span><br><span class="line">    <span class="attribute">z-index</span>: <span class="number">1</span> <span class="meta">!important</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  //防止挡住页末文章的阅读全文按钮</span><br><span class="line">  <span class="selector-class">.main</span> &#123;</span><br><span class="line">    <span class="attribute">padding-bottom</span>: <span class="number">200px</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><div class="note warning"><p>Next.Muse主题方案中Header和Footer是没有背景色的，所以需要添加背景色后才能看出边缘摆动效果。另外，实现边缘摆动效果所需的 <code>z-index</code> 属性可能会导致元素堆叠异常，需要添加以上样式来矫正。</p></div><p>在主题配置文件中添加以下代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="YAML"><figure class="iseeu highlight /yaml"><figcaption><span>themes\next\_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># window woblle</span></span><br><span class="line"><span class="attr">wobble:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span>  <span class="comment"># 是否开启边缘波动效果</span></span><br><span class="line">  <span class="attr">radius:</span> <span class="number">50</span>  <span class="comment"># 波动半径</span></span><br><span class="line">  <span class="attr">sidebar:</span> <span class="literal">true</span>  <span class="comment"># 开启侧边栏边缘摆动</span></span><br><span class="line">  <span class="attr">header:</span> <span class="literal">true</span>  <span class="comment"># 开启头部边缘摆动</span></span><br><span class="line">  <span class="attr">footer:</span> <span class="literal">true</span>  <span class="comment"># 开启脚部边缘摆动</span></span><br></pre></td></tr></table></figure></div><p>用户可以根据需要在配置文件中为选择开启边缘摆动效果的布局元素。刷新浏览器，然后将鼠标移动到布局边缘上尽情的挑逗它吧。</p><p>如果从本地加载JS脚本速度较慢，可以考虑将脚本放到CDN上再引入。</p><h1 id="个性化回到顶部"><a href="#个性化回到顶部" class="headerlink" title="个性化回到顶部"></a>个性化回到顶部</h1><p>从 <a href="https://diygod.me/" target="_blank" rel="noopener external nofollow noreferrer">DIYgod的博客</a> 里扒来的，效果如下：</p><p><img src="http://yearito-1256884783.image.myqcloud.com/hexo-theme-beautify/back-to-top.gif" alt="回到顶部" title="回到顶部"></p><p>原理很简单，将 back-to-top 按钮添加图片背景，并添加CSS3动效即可。</p><p>首先，找到自己喜欢的图片素材放到 source\\images\ 目录下。</p><p>你可以点击下方按钮下载本站所使用的小猫上吊素材（<br>小猫咪这么可爱，当然要多放点孜然啦…）</p><p><a class="btn" href="/images/scroll.png" download><br><i class="fa fa-download fa-fw"></i><br>下载图片</a></p><p>然后在自定义样式文件中添加如下代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="CSS"><figure class="iseeu highlight /css"><figcaption><span>themes\next\source\css\_custom\custom.styl</span></figcaption><table><tr><td class="code"><pre><span class="line">//自定义回到顶部样式</span><br><span class="line"><span class="selector-class">.back-to-top</span> &#123;</span><br><span class="line">  <span class="attribute">right</span>: <span class="number">60px</span>;</span><br><span class="line">  width: 70px;  //图片素材宽度</span><br><span class="line">  height: 900px;  //图片素材高度</span><br><span class="line">  <span class="selector-tag">top</span>: <span class="selector-tag">-900px</span>;</span><br><span class="line">  <span class="selector-tag">bottom</span>: <span class="selector-tag">unset</span>;</span><br><span class="line">  <span class="selector-tag">transition</span>: <span class="selector-tag">all</span> <span class="selector-class">.5s</span> <span class="selector-tag">ease-in-out</span>;</span><br><span class="line">  background: url("/images/scroll.png");</span><br><span class="line"></span><br><span class="line">  //隐藏箭头图标</span><br><span class="line">  &gt; <span class="selector-tag">i</span> &#123;</span><br><span class="line">    <span class="attribute">display</span>: none;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  &amp;<span class="selector-class">.back-to-top-on</span> &#123;</span><br><span class="line">    <span class="attribute">bottom</span>: unset;</span><br><span class="line">    <span class="attribute">top</span>: <span class="number">100vh</span> &lt; (<span class="number">900px</span> + <span class="number">200px</span>) ? <span class="built_in">calc</span>( <span class="number">100vh</span> - <span class="number">900px</span> - <span class="number">200px</span> ) : <span class="number">0px</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>刷新浏览器即可预览效果。</p><h1 id="鼠标点击特效"><a href="#鼠标点击特效" class="headerlink" title="鼠标点击特效"></a>鼠标点击特效</h1><p>从各个站点里搜罗了以下四个比较常用的鼠标点击特效：</p><div class="tabs" id="鼠标点击特效"><ul class="nav-tabs"><li class="tab active"><a href="#鼠标点击特效-1">礼花特效</a></li><li class="tab"><a href="#鼠标点击特效-2">爆炸特效</a></li><li class="tab"><a href="#鼠标点击特效-3">浮出爱心</a></li><li class="tab"><a href="#鼠标点击特效-4">浮出文字</a></li></ul><div class="tab-content"><div class="tab-pane active" id="鼠标点击特效-1"><p><img src="http://yearito-1256884783.image.myqcloud.com/hexo-theme-beautify/cursor-fireworks.gif" alt></p></div><div class="tab-pane" id="鼠标点击特效-2"><p><img src="http://yearito-1256884783.image.myqcloud.com/hexo-theme-beautify/cursor-explosion.gif" alt></p></div><div class="tab-pane" id="鼠标点击特效-3"><p><img src="http://yearito-1256884783.image.myqcloud.com/hexo-theme-beautify/cursor-love.gif" alt></p></div><div class="tab-pane" id="鼠标点击特效-4"><p><img src="http://yearito-1256884783.image.myqcloud.com/hexo-theme-beautify/cursor-text.gif" alt></p></div></div></div><p>点击下方按钮下载相应的脚本，并置于 themes\\next\\source\\js\\cursor\ 目录下：</p><p><a class="btn" href="https://script-1256884783.file.myqcloud.com/cursor/fireworks.js" target="_blank" rel="noopener external nofollow noreferrer"><i class="fa fa-download fa-fw"></i>礼花特效</a> <a class="btn" href="https://script-1256884783.file.myqcloud.com/cursor/explosion.min.js" target="_blank" rel="noopener external nofollow noreferrer"><i class="fa fa-download fa-fw"></i>爆炸特效</a> <a class="btn" href="https://script-1256884783.file.myqcloud.com/cursor/love.min.js" target="_blank" rel="noopener external nofollow noreferrer"><i class="fa fa-download fa-fw"></i>浮出爱心</a> <a class="btn" href="https://script-1256884783.file.myqcloud.com/cursor/text.js" target="_blank" rel="noopener external nofollow noreferrer"><i class="fa fa-download fa-fw"></i>浮出文字</a></p><p>在主题自定义布局文件中添加以下代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="HTML"><figure class="iseeu highlight /html"><figcaption><span>themes\next\layout\_custom\custom.swig</span></figcaption><table><tr><td class="code"><pre><span class="line">&#123;# 鼠标点击特效 #&#125;</span><br><span class="line">&#123;% if theme.cursor_effect == "fireworks" %&#125;</span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">async</span> <span class="attr">src</span>=<span class="string">"/js/cursor/fireworks.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">&#123;% elseif theme.cursor_effect == "explosion" %&#125;</span><br><span class="line">  <span class="tag">&lt;<span class="name">canvas</span> <span class="attr">class</span>=<span class="string">"fireworks"</span> <span class="attr">style</span>=<span class="string">"position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;"</span> &gt;</span><span class="tag">&lt;/<span class="name">canvas</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"//cdn.bootcss.com/animejs/2.2.0/anime.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">async</span> <span class="attr">src</span>=<span class="string">"/js/cursor/explosion.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">&#123;% elseif theme.cursor_effect == "love" %&#125;</span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">async</span> <span class="attr">src</span>=<span class="string">"/js/cursor/love.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">&#123;% elseif theme.cursor_effect == "text" %&#125;</span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">async</span> <span class="attr">src</span>=<span class="string">"/js/cursor/text.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure></div><p>如果 custom.swig 文件不存在，需要手动新建并在布局页面中 body 末尾引入：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="DIFF"><figure class="iseeu highlight /diff"><figcaption><span>themes\next\layout\_layout.swig</span></figcaption><table><tr><td class="code"><pre><span class="line">      ...</span><br><span class="line">      &#123;% include '_third-party/exturl.swig' %&#125;</span><br><span class="line">      &#123;% include '_third-party/bookmark.swig' %&#125;</span><br><span class="line">      &#123;% include '_third-party/copy-code.swig' %&#125;</span><br><span class="line"></span><br><span class="line"><span class="addition">+     &#123;% include '_custom/custom.swig' %&#125;</span></span><br><span class="line">    &lt;/body&gt;</span><br><span class="line">  &lt;/html&gt;</span><br></pre></td></tr></table></figure></div><p>在主题配置文件中添加以下代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="YAML"><figure class="iseeu highlight /yaml"><figcaption><span>themes\next\_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># mouse click effect: fireworks | explosion | love | text</span></span><br><span class="line"><span class="attr">cursor_effect:</span> <span class="string">fireworks</span></span><br></pre></td></tr></table></figure></div><p>这样即可在配置文件中一键快速切换鼠标点击特效。</p><p>如果从本地加载JS脚本速度较慢，可以考虑将脚本放到CDN上再引入。</p><h1 id="打字特效"><a href="#打字特效" class="headerlink" title="打字特效"></a>打字特效</h1><div class="note info"><p>本章节参考 <a href="https://qianling.pw/hexo-optimization/" target="_blank" rel="noopener external nofollow noreferrer">千灵夙赋 | Hexo 优化汇总 #31</a>，原文出自 <a href="https://www.ilxtx.com/comment-input-effects.html" target="_blank" rel="noopener external nofollow noreferrer">龙笑天下 | 给 WordPress 博客网站添加评论输入打字礼花及震动特效</a></p></div><p><img src="http://yearito-1256884783.image.myqcloud.com/hexo-theme-beautify/typing-effect.gif" alt="打字特效" title="打字特效"></p><p>点击下方按钮下载相应的脚本，并置于 themes\\next\\source\\js\ 目录下：</p><p><a class="btn" href="https://script-1256884783.file.myqcloud.com/activate-power-mode.min.js" target="_blank" rel="noopener external nofollow noreferrer"><i class="fa fa-download fa-fw"></i>打字特效</a></p><p>在主题自定义布局文件中添加以下代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="HTML"><figure class="iseeu highlight /html"><figcaption><span>themes\next\layout\_custom\custom.swig</span></figcaption><table><tr><td class="code"><pre><span class="line">&#123;# 打字特效 #&#125;</span><br><span class="line">&#123;% if theme.typing_effect %&#125;</span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"/js/activate-power-mode.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="handlebars"><span class="xml">    POWERMODE.colorful = </span><span class="template-variable">&#123;&#123; theme.typing_effect.colorful &#125;&#125;</span><span class="xml">;</span></span></span><br><span class="line"><span class="handlebars"><span class="xml">    POWERMODE.shake = </span><span class="template-variable">&#123;&#123; theme.typing_effect.shake &#125;&#125;</span><span class="xml">;</span></span></span><br><span class="line"><span class="javascript">    <span class="built_in">document</span>.body.addEventListener(<span class="string">'input'</span>, POWERMODE);</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure></div><p>如果 custom.swig 文件不存在，需要手动新建并在布局页面中 body 末尾引入：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="DIFF"><figure class="iseeu highlight /diff"><figcaption><span>themes\next\layout\_layout.swig</span></figcaption><table><tr><td class="code"><pre><span class="line">      ...</span><br><span class="line">      &#123;% include '_third-party/exturl.swig' %&#125;</span><br><span class="line">      &#123;% include '_third-party/bookmark.swig' %&#125;</span><br><span class="line">      &#123;% include '_third-party/copy-code.swig' %&#125;</span><br><span class="line"></span><br><span class="line"><span class="addition">+     &#123;% include '_custom/custom.swig' %&#125;</span></span><br><span class="line">    &lt;/body&gt;</span><br><span class="line">  &lt;/html&gt;</span><br></pre></td></tr></table></figure></div><p>在主题配置文件中添加以下代码：</p><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="YAML"><figure class="iseeu highlight /yaml"><figcaption><span>themes\next\_config.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># typing effect</span></span><br><span class="line"><span class="attr">typing_effect:</span></span><br><span class="line">  <span class="attr">colorful:</span> <span class="literal">true</span>  <span class="comment"># 礼花特效</span></span><br><span class="line">  <span class="attr">shake:</span> <span class="literal">false</span>  <span class="comment"># 震动特效</span></span><br></pre></td></tr></table></figure></div><p>如果从本地加载JS脚本速度较慢，可以考虑将脚本放到CDN上再引入。</p><h1 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h1><p>本文记录了本站在Next的基础上的进阶美化方案，除了一些简单的样式修改外，还添加了一些由插件支持的高级动效，包括动态背景、看板娘、边缘摆动、鼠标点击和打字特效等。笔者认为，动效可以使得站点变有趣，但同时也会增加网页的资源消耗，以及影响用户的关注点，有时候会喧宾夺主适得其反，建议珍爱PC资源，合理使用动效。</p><!-- rebuild by neat -->]]></content>
      <categories>
        <category>技术</category>
        <category>博客</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/hello-world.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><!-- build time:Mon Apr 20 2020 13:02:10 GMT+0800 (GMT+08:00) --><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener external nofollow noreferrer">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener external nofollow noreferrer">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener external nofollow noreferrer">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener external nofollow noreferrer">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure></div><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener external nofollow noreferrer">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure></div><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener external nofollow noreferrer">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure></div><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener external nofollow noreferrer">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><div class="highlight-wrap"autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false"data-rel="BASH"><figure class="iseeu highlight /bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure></div><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener external nofollow noreferrer">Deployment</a></p><!-- rebuild by neat -->]]></content>
  </entry>
</search>
